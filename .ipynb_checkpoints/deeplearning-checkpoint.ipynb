{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w1_initial=np.random.normal(size=(28*28*1,10)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    def next_batch(batch_size , image , label):\n",
    "\n",
    "        a=np.random.randint(np.shape(image)[0] -batch_size)\n",
    "        batch_x = image[a:a+batch_size,:]\n",
    "        batch_y= label[a:a+batch_size,:]\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train_img=np.load('/home/user01/notebook/Mnist_Data/train_img.npy')\n",
    "train_lab=np.load('/home/user01/notebook/Mnist_Data/train_lab.npy')\n",
    "test_img=np.load('/home/user01/notebook/Mnist_Data/test_img.npy')\n",
    "test_lab=np.load('/home/user01/notebook/Mnist_Data/test_lab.npy')\n",
    "val_img=np.load('/home/user01/notebook/Mnist_Data/val_img.npy')\n",
    "val_lab=np.load('/home/user01/notebook/Mnist_Data/val_lab.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5000, 784)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print np.shape(train_img)\n",
    "np.shape(val_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f93d4303550>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFfCAYAAACfj30KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f93d4528810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img=np.reshape(val_img[0] ,newshape=[28,28])\n",
    "lab=val_lab[0]\n",
    "print lab\n",
    "\n",
    "plt.imshow(img, cmap='binary' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x_pre=tf.placeholder(tf.float32 , shape=[None,28,28,1])\n",
    "#x_ = tf.reshape(x_pre , shape=[-1,28*28*1])\n",
    "x_=tf.placeholder(tf.float32 , shape=[None,28*28*1])\n",
    "y_=tf.placeholder(tf.float32 , shape=[None , 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Layer1 without Batch Normalization  \n",
    "w1 = tf.Variable(w1_initial)\n",
    "mean_w1 = tf.reduce_mean(w1)\n",
    "b1=tf.Variable(tf.zeros([10]))\n",
    "z1=tf.matmul(x_,w1)\n",
    "l1=tf.nn.relu(z1)\n",
    "y=tf.nn.softmax(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy =tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "\n",
    "\n",
    "train_step =tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.arg_max(y,1) , tf.arg_max(y_ , 1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction , tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-59-246919090c9e>:4 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "zs , BNs , acc, acc_BNs = [],[],[],[]\n",
    "\n",
    "\n",
    "init=tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 training 0.133333            validation 0.0886\n",
      "\n",
      "step: 50 training 0.183333            validation 0.2328\n",
      "\n",
      "step: 100 training 0.25            validation 0.2562\n",
      "\n",
      "step: 150 training 0.25            validation 0.2706\n",
      "\n",
      "step: 200 training 0.266667            validation 0.3014\n",
      "\n",
      "step: 250 training 0.383333            validation 0.3202\n",
      "\n",
      "step: 300 training 0.433333            validation 0.347\n",
      "\n",
      "step: 350 training 0.416667            validation 0.3494\n",
      "\n",
      "step: 400 training 0.35            validation 0.3586\n",
      "\n",
      "step: 450 training 0.35            validation 0.3586\n",
      "\n",
      "step: 500 training 0.3            validation 0.3656\n",
      "\n",
      "step: 550 training 0.45            validation 0.3676\n",
      "\n",
      "step: 600 training 0.366667            validation 0.3726\n",
      "\n",
      "step: 650 training 0.466667            validation 0.3762\n",
      "\n",
      "step: 700 training 0.416667            validation 0.3778\n",
      "\n",
      "step: 750 training 0.4            validation 0.3744\n",
      "\n",
      "step: 800 training 0.45            validation 0.38\n",
      "\n",
      "step: 850 training 0.4            validation 0.3822\n",
      "\n",
      "step: 900 training 0.4            validation 0.3848\n",
      "\n",
      "step: 950 training 0.416667            validation 0.3914\n",
      "\n",
      "step: 1000 training 0.466667            validation 0.391\n",
      "\n",
      "step: 1050 training 0.433333            validation 0.399\n",
      "\n",
      "step: 1100 training 0.466667            validation 0.4112\n",
      "\n",
      "step: 1150 training 0.35            validation 0.4224\n",
      "\n",
      "step: 1200 training 0.35            validation 0.4268\n",
      "\n",
      "step: 1250 training 0.4            validation 0.4354\n",
      "\n",
      "step: 1300 training 0.5            validation 0.4432\n",
      "\n",
      "step: 1350 training 0.4            validation 0.4456\n",
      "\n",
      "step: 1400 training 0.416667            validation 0.4476\n",
      "\n",
      "step: 1450 training 0.433333            validation 0.4546\n",
      "\n",
      "step: 1500 training 0.5            validation 0.4578\n",
      "\n",
      "step: 1550 training 0.466667            validation 0.4542\n",
      "\n",
      "step: 1600 training 0.366667            validation 0.4604\n",
      "\n",
      "step: 1650 training 0.6            validation 0.4604\n",
      "\n",
      "step: 1700 training 0.55            validation 0.4618\n",
      "\n",
      "step: 1750 training 0.5            validation 0.4638\n",
      "\n",
      "step: 1800 training 0.516667            validation 0.4596\n",
      "\n",
      "step: 1850 training 0.6            validation 0.465\n",
      "\n",
      "step: 1900 training 0.5            validation 0.4648\n",
      "\n",
      "step: 1950 training 0.516667            validation 0.463\n",
      "\n",
      "step: 2000 training 0.45            validation 0.4636\n",
      "\n",
      "step: 2050 training 0.5            validation 0.4656\n",
      "\n",
      "step: 2100 training 0.483333            validation 0.4698\n",
      "\n",
      "step: 2150 training 0.433333            validation 0.4718\n",
      "\n",
      "step: 2200 training 0.45            validation 0.4692\n",
      "\n",
      "step: 2250 training 0.483333            validation 0.4736\n",
      "\n",
      "step: 2300 training 0.483333            validation 0.473\n",
      "\n",
      "step: 2350 training 0.466667            validation 0.4744\n",
      "\n",
      "step: 2400 training 0.466667            validation 0.4788\n",
      "\n",
      "step: 2450 training 0.516667            validation 0.4816\n",
      "\n",
      "step: 2500 training 0.466667            validation 0.4814\n",
      "\n",
      "step: 2550 training 0.45            validation 0.4858\n",
      "\n",
      "step: 2600 training 0.666667            validation 0.487\n",
      "\n",
      "step: 2650 training 0.366667            validation 0.4876\n",
      "\n",
      "step: 2700 training 0.55            validation 0.4896\n",
      "\n",
      "step: 2750 training 0.466667            validation 0.4892\n",
      "\n",
      "step: 2800 training 0.55            validation 0.49\n",
      "\n",
      "step: 2850 training 0.5            validation 0.4922\n",
      "\n",
      "step: 2900 training 0.4            validation 0.493\n",
      "\n",
      "step: 2950 training 0.483333            validation 0.494\n",
      "\n",
      "step: 3000 training 0.483333            validation 0.4962\n",
      "\n",
      "step: 3050 training 0.45            validation 0.4998\n",
      "\n",
      "step: 3100 training 0.483333            validation 0.4988\n",
      "\n",
      "step: 3150 training 0.433333            validation 0.4994\n",
      "\n",
      "step: 3200 training 0.433333            validation 0.5054\n",
      "\n",
      "step: 3250 training 0.5            validation 0.5024\n",
      "\n",
      "step: 3300 training 0.55            validation 0.5052\n",
      "\n",
      "step: 3350 training 0.5            validation 0.5024\n",
      "\n",
      "step: 3400 training 0.5            validation 0.5054\n",
      "\n",
      "step: 3450 training 0.483333            validation 0.5058\n",
      "\n",
      "step: 3500 training 0.55            validation 0.5118\n",
      "\n",
      "step: 3550 training 0.616667            validation 0.5172\n",
      "\n",
      "step: 3600 training 0.433333            validation 0.5178\n",
      "\n",
      "step: 3650 training 0.516667            validation 0.5204\n",
      "\n",
      "step: 3700 training 0.666667            validation 0.5256\n",
      "\n",
      "step: 3750 training 0.516667            validation 0.5256\n",
      "\n",
      "step: 3800 training 0.533333            validation 0.5232\n",
      "\n",
      "step: 3850 training 0.466667            validation 0.5224\n",
      "\n",
      "step: 3900 training 0.5            validation 0.5238\n",
      "\n",
      "step: 3950 training 0.35            validation 0.5282\n",
      "\n",
      "step: 4000 training 0.633333            validation 0.5306\n",
      "\n",
      "step: 4050 training 0.533333            validation 0.5282\n",
      "\n",
      "step: 4100 training 0.466667            validation 0.5332\n",
      "\n",
      "step: 4150 training 0.55            validation 0.5322\n",
      "\n",
      "step: 4200 training 0.566667            validation 0.5322\n",
      "\n",
      "step: 4250 training 0.55            validation 0.5324\n",
      "\n",
      "step: 4300 training 0.7            validation 0.5372\n",
      "\n",
      "step: 4350 training 0.533333            validation 0.5326\n",
      "\n",
      "step: 4400 training 0.45            validation 0.531\n",
      "\n",
      "step: 4450 training 0.55            validation 0.5394\n",
      "\n",
      "step: 4500 training 0.566667            validation 0.5366\n",
      "\n",
      "step: 4550 training 0.6            validation 0.5392\n",
      "\n",
      "step: 4600 training 0.6            validation 0.5378\n",
      "\n",
      "step: 4650 training 0.533333            validation 0.5352\n",
      "\n",
      "step: 4700 training 0.416667            validation 0.5342\n",
      "\n",
      "step: 4750 training 0.416667            validation 0.5346\n",
      "\n",
      "step: 4800 training 0.616667            validation 0.5348\n",
      "\n",
      "step: 4850 training 0.516667            validation 0.539\n",
      "\n",
      "step: 4900 training 0.533333            validation 0.5364\n",
      "\n",
      "step: 4950 training 0.516667            validation 0.535\n",
      "\n",
      "step: 5000 training 0.666667            validation 0.539\n",
      "\n",
      "step: 5050 training 0.7            validation 0.5388\n",
      "\n",
      "step: 5100 training 0.483333            validation 0.5392\n",
      "\n",
      "step: 5150 training 0.516667            validation 0.5374\n",
      "\n",
      "step: 5200 training 0.483333            validation 0.541\n",
      "\n",
      "step: 5250 training 0.483333            validation 0.5374\n",
      "\n",
      "step: 5300 training 0.566667            validation 0.5378\n",
      "\n",
      "step: 5350 training 0.583333            validation 0.5424\n",
      "\n",
      "step: 5400 training 0.533333            validation 0.5424\n",
      "\n",
      "step: 5450 training 0.533333            validation 0.5432\n",
      "\n",
      "step: 5500 training 0.583333            validation 0.5432\n",
      "\n",
      "step: 5550 training 0.483333            validation 0.5404\n",
      "\n",
      "step: 5600 training 0.516667            validation 0.5418\n",
      "\n",
      "step: 5650 training 0.616667            validation 0.5412\n",
      "\n",
      "step: 5700 training 0.55            validation 0.5436\n",
      "\n",
      "step: 5750 training 0.6            validation 0.5438\n",
      "\n",
      "step: 5800 training 0.566667            validation 0.5386\n",
      "\n",
      "step: 5850 training 0.6            validation 0.5422\n",
      "\n",
      "step: 5900 training 0.566667            validation 0.5426\n",
      "\n",
      "step: 5950 training 0.483333            validation 0.5446\n",
      "\n",
      "step: 6000 training 0.6            validation 0.5462\n",
      "\n",
      "step: 6050 training 0.55            validation 0.544\n",
      "\n",
      "step: 6100 training 0.65            validation 0.5474\n",
      "\n",
      "step: 6150 training 0.45            validation 0.5464\n",
      "\n",
      "step: 6200 training 0.55            validation 0.5442\n",
      "\n",
      "step: 6250 training 0.566667            validation 0.5464\n",
      "\n",
      "step: 6300 training 0.533333            validation 0.5462\n",
      "\n",
      "step: 6350 training 0.616667            validation 0.5472\n",
      "\n",
      "step: 6400 training 0.516667            validation 0.545\n",
      "\n",
      "step: 6450 training 0.566667            validation 0.5466\n",
      "\n",
      "step: 6500 training 0.583333            validation 0.5464\n",
      "\n",
      "step: 6550 training 0.483333            validation 0.545\n",
      "\n",
      "step: 6600 training 0.566667            validation 0.5454\n",
      "\n",
      "step: 6650 training 0.55            validation 0.5454\n",
      "\n",
      "step: 6700 training 0.516667            validation 0.5484\n",
      "\n",
      "step: 6750 training 0.533333            validation 0.545\n",
      "\n",
      "step: 6800 training 0.6            validation 0.5474\n",
      "\n",
      "step: 6850 training 0.65            validation 0.5484\n",
      "\n",
      "step: 6900 training 0.616667            validation 0.548\n",
      "\n",
      "step: 6950 training 0.6            validation 0.547\n",
      "\n",
      "step: 7000 training 0.6            validation 0.5478\n",
      "\n",
      "step: 7050 training 0.683333            validation 0.548\n",
      "\n",
      "step: 7100 training 0.566667            validation 0.5464\n",
      "\n",
      "step: 7150 training 0.716667            validation 0.548\n",
      "\n",
      "step: 7200 training 0.6            validation 0.5478\n",
      "\n",
      "step: 7250 training 0.5            validation 0.5462\n",
      "\n",
      "step: 7300 training 0.533333            validation 0.547\n",
      "\n",
      "step: 7350 training 0.633333            validation 0.5454\n",
      "\n",
      "step: 7400 training 0.533333            validation 0.5452\n",
      "\n",
      "step: 7450 training 0.466667            validation 0.5466\n",
      "\n",
      "step: 7500 training 0.5            validation 0.547\n",
      "\n",
      "step: 7550 training 0.6            validation 0.5474\n",
      "\n",
      "step: 7600 training 0.65            validation 0.5476\n",
      "\n",
      "step: 7650 training 0.583333            validation 0.5464\n",
      "\n",
      "step: 7700 training 0.583333            validation 0.5464\n",
      "\n",
      "step: 7750 training 0.55            validation 0.5478\n",
      "\n",
      "step: 7800 training 0.533333            validation 0.5486\n",
      "\n",
      "step: 7850 training 0.633333            validation 0.5478\n",
      "\n",
      "step: 7900 training 0.533333            validation 0.5464\n",
      "\n",
      "step: 7950 training 0.55            validation 0.5482\n",
      "\n",
      "step: 8000 training 0.633333            validation 0.5482\n",
      "\n",
      "step: 8050 training 0.516667            validation 0.55\n",
      "\n",
      "step: 8100 training 0.633333            validation 0.55\n",
      "\n",
      "step: 8150 training 0.433333            validation 0.5478\n",
      "\n",
      "step: 8200 training 0.55            validation 0.548\n",
      "\n",
      "step: 8250 training 0.65            validation 0.5488\n",
      "\n",
      "step: 8300 training 0.6            validation 0.5492\n",
      "\n",
      "step: 8350 training 0.516667            validation 0.5454\n",
      "\n",
      "step: 8400 training 0.666667            validation 0.5508\n",
      "\n",
      "step: 8450 training 0.566667            validation 0.551\n",
      "\n",
      "step: 8500 training 0.583333            validation 0.55\n",
      "\n",
      "step: 8550 training 0.616667            validation 0.5478\n",
      "\n",
      "step: 8600 training 0.633333            validation 0.5476\n",
      "\n",
      "step: 8650 training 0.6            validation 0.5518\n",
      "\n",
      "step: 8700 training 0.483333            validation 0.55\n",
      "\n",
      "step: 8750 training 0.583333            validation 0.5494\n",
      "\n",
      "step: 8800 training 0.633333            validation 0.5518\n",
      "\n",
      "step: 8850 training 0.6            validation 0.552\n",
      "\n",
      "step: 8900 training 0.533333            validation 0.5498\n",
      "\n",
      "step: 8950 training 0.733333            validation 0.5508\n",
      "\n",
      "step: 9000 training 0.5            validation 0.548\n",
      "\n",
      "step: 9050 training 0.566667            validation 0.5486\n",
      "\n",
      "step: 9100 training 0.65            validation 0.5516\n",
      "\n",
      "step: 9150 training 0.5            validation 0.5512\n",
      "\n",
      "step: 9200 training 0.5            validation 0.5526\n",
      "\n",
      "step: 9250 training 0.516667            validation 0.5492\n",
      "\n",
      "step: 9300 training 0.583333            validation 0.5496\n",
      "\n",
      "step: 9350 training 0.55            validation 0.5514\n",
      "\n",
      "step: 9400 training 0.566667            validation 0.5514\n",
      "\n",
      "step: 9450 training 0.533333            validation 0.5506\n",
      "\n",
      "step: 9500 training 0.566667            validation 0.5512\n",
      "\n",
      "step: 9550 training 0.616667            validation 0.5524\n",
      "\n",
      "step: 9600 training 0.55            validation 0.5502\n",
      "\n",
      "step: 9650 training 0.55            validation 0.552\n",
      "\n",
      "step: 9700 training 0.5            validation 0.5492\n",
      "\n",
      "step: 9750 training 0.533333            validation 0.5498\n",
      "\n",
      "step: 9800 training 0.5            validation 0.5496\n",
      "\n",
      "step: 9850 training 0.633333            validation 0.551\n",
      "\n",
      "step: 9900 training 0.583333            validation 0.5512\n",
      "\n",
      "step: 9950 training 0.6            validation 0.5502\n",
      "\n",
      "step: 10000 training 0.466667            validation 0.5526\n",
      "\n",
      "step: 10050 training 0.466667            validation 0.55\n",
      "\n",
      "step: 10100 training 0.5            validation 0.5518\n",
      "\n",
      "step: 10150 training 0.566667            validation 0.551\n",
      "\n",
      "step: 10200 training 0.6            validation 0.5522\n",
      "\n",
      "step: 10250 training 0.566667            validation 0.5518\n",
      "\n",
      "step: 10300 training 0.516667            validation 0.5544\n",
      "\n",
      "step: 10350 training 0.6            validation 0.551\n",
      "\n",
      "step: 10400 training 0.5            validation 0.5524\n",
      "\n",
      "step: 10450 training 0.65            validation 0.5516\n",
      "\n",
      "step: 10500 training 0.516667            validation 0.5522\n",
      "\n",
      "step: 10550 training 0.5            validation 0.5518\n",
      "\n",
      "step: 10600 training 0.583333            validation 0.5512\n",
      "\n",
      "step: 10650 training 0.633333            validation 0.5528\n",
      "\n",
      "step: 10700 training 0.483333            validation 0.5516\n",
      "\n",
      "step: 10750 training 0.55            validation 0.5534\n",
      "\n",
      "step: 10800 training 0.583333            validation 0.549\n",
      "\n",
      "step: 10850 training 0.55            validation 0.5516\n",
      "\n",
      "step: 10900 training 0.55            validation 0.5516\n",
      "\n",
      "step: 10950 training 0.45            validation 0.5538\n",
      "\n",
      "step: 11000 training 0.616667            validation 0.551\n",
      "\n",
      "step: 11050 training 0.633333            validation 0.5536\n",
      "\n",
      "step: 11100 training 0.466667            validation 0.5522\n",
      "\n",
      "step: 11150 training 0.7            validation 0.5524\n",
      "\n",
      "step: 11200 training 0.433333            validation 0.5534\n",
      "\n",
      "step: 11250 training 0.65            validation 0.552\n",
      "\n",
      "step: 11300 training 0.5            validation 0.5522\n",
      "\n",
      "step: 11350 training 0.516667            validation 0.5524\n",
      "\n",
      "step: 11400 training 0.6            validation 0.553\n",
      "\n",
      "step: 11450 training 0.5            validation 0.5504\n",
      "\n",
      "step: 11500 training 0.483333            validation 0.5532\n",
      "\n",
      "step: 11550 training 0.65            validation 0.5496\n",
      "\n",
      "step: 11600 training 0.65            validation 0.5518\n",
      "\n",
      "step: 11650 training 0.633333            validation 0.5534\n",
      "\n",
      "step: 11700 training 0.666667            validation 0.5542\n",
      "\n",
      "step: 11750 training 0.516667            validation 0.5522\n",
      "\n",
      "step: 11800 training 0.616667            validation 0.55\n",
      "\n",
      "step: 11850 training 0.583333            validation 0.553\n",
      "\n",
      "step: 11900 training 0.633333            validation 0.552\n",
      "\n",
      "step: 11950 training 0.65            validation 0.5536\n",
      "\n",
      "step: 12000 training 0.533333            validation 0.553\n",
      "\n",
      "step: 12050 training 0.533333            validation 0.5536\n",
      "\n",
      "step: 12100 training 0.6            validation 0.556\n",
      "\n",
      "step: 12150 training 0.566667            validation 0.5532\n",
      "\n",
      "step: 12200 training 0.683333            validation 0.5544\n",
      "\n",
      "step: 12250 training 0.466667            validation 0.5528\n",
      "\n",
      "step: 12300 training 0.65            validation 0.552\n",
      "\n",
      "step: 12350 training 0.55            validation 0.5528\n",
      "\n",
      "step: 12400 training 0.716667            validation 0.554\n",
      "\n",
      "step: 12450 training 0.566667            validation 0.554\n",
      "\n",
      "step: 12500 training 0.6            validation 0.5534\n",
      "\n",
      "step: 12550 training 0.6            validation 0.5504\n",
      "\n",
      "step: 12600 training 0.516667            validation 0.5542\n",
      "\n",
      "step: 12650 training 0.6            validation 0.5532\n",
      "\n",
      "step: 12700 training 0.616667            validation 0.5532\n",
      "\n",
      "step: 12750 training 0.533333            validation 0.5532\n",
      "\n",
      "step: 12800 training 0.583333            validation 0.5546\n",
      "\n",
      "step: 12850 training 0.566667            validation 0.5544\n",
      "\n",
      "step: 12900 training 0.566667            validation 0.555\n",
      "\n",
      "step: 12950 training 0.65            validation 0.554\n",
      "\n",
      "step: 13000 training 0.633333            validation 0.5552\n",
      "\n",
      "step: 13050 training 0.666667            validation 0.553\n",
      "\n",
      "step: 13100 training 0.6            validation 0.5514\n",
      "\n",
      "step: 13150 training 0.566667            validation 0.5546\n",
      "\n",
      "step: 13200 training 0.6            validation 0.557\n",
      "\n",
      "step: 13250 training 0.583333            validation 0.5536\n",
      "\n",
      "step: 13300 training 0.616667            validation 0.5538\n",
      "\n",
      "step: 13350 training 0.633333            validation 0.5556\n",
      "\n",
      "step: 13400 training 0.566667            validation 0.5568\n",
      "\n",
      "step: 13450 training 0.583333            validation 0.5538\n",
      "\n",
      "step: 13500 training 0.533333            validation 0.5556\n",
      "\n",
      "step: 13550 training 0.633333            validation 0.5572\n",
      "\n",
      "step: 13600 training 0.566667            validation 0.556\n",
      "\n",
      "step: 13650 training 0.583333            validation 0.5568\n",
      "\n",
      "step: 13700 training 0.55            validation 0.5566\n",
      "\n",
      "step: 13750 training 0.516667            validation 0.5538\n",
      "\n",
      "step: 13800 training 0.566667            validation 0.5564\n",
      "\n",
      "step: 13850 training 0.583333            validation 0.5574\n",
      "\n",
      "step: 13900 training 0.6            validation 0.5582\n",
      "\n",
      "step: 13950 training 0.466667            validation 0.5564\n",
      "\n",
      "step: 14000 training 0.616667            validation 0.556\n",
      "\n",
      "step: 14050 training 0.733333            validation 0.556\n",
      "\n",
      "step: 14100 training 0.566667            validation 0.554\n",
      "\n",
      "step: 14150 training 0.55            validation 0.5578\n",
      "\n",
      "step: 14200 training 0.533333            validation 0.5552\n",
      "\n",
      "step: 14250 training 0.45            validation 0.5574\n",
      "\n",
      "step: 14300 training 0.516667            validation 0.5562\n",
      "\n",
      "step: 14350 training 0.533333            validation 0.5574\n",
      "\n",
      "step: 14400 training 0.616667            validation 0.556\n",
      "\n",
      "step: 14450 training 0.566667            validation 0.5576\n",
      "\n",
      "step: 14500 training 0.6            validation 0.5562\n",
      "\n",
      "step: 14550 training 0.566667            validation 0.5564\n",
      "\n",
      "step: 14600 training 0.583333            validation 0.555\n",
      "\n",
      "step: 14650 training 0.466667            validation 0.554\n",
      "\n",
      "step: 14700 training 0.6            validation 0.5552\n",
      "\n",
      "step: 14750 training 0.566667            validation 0.5558\n",
      "\n",
      "step: 14800 training 0.566667            validation 0.5544\n",
      "\n",
      "step: 14850 training 0.583333            validation 0.555\n",
      "\n",
      "step: 14900 training 0.566667            validation 0.5552\n",
      "\n",
      "step: 14950 training 0.583333            validation 0.555\n",
      "\n",
      "step: 15000 training 0.55            validation 0.5568\n",
      "\n",
      "step: 15050 training 0.483333            validation 0.5564\n",
      "\n",
      "step: 15100 training 0.65            validation 0.5564\n",
      "\n",
      "step: 15150 training 0.6            validation 0.555\n",
      "\n",
      "step: 15200 training 0.516667            validation 0.5536\n",
      "\n",
      "step: 15250 training 0.616667            validation 0.5564\n",
      "\n",
      "step: 15300 training 0.6            validation 0.5582\n",
      "\n",
      "step: 15350 training 0.533333            validation 0.558\n",
      "\n",
      "step: 15400 training 0.566667            validation 0.555\n",
      "\n",
      "step: 15450 training 0.566667            validation 0.5562\n",
      "\n",
      "step: 15500 training 0.566667            validation 0.5564\n",
      "\n",
      "step: 15550 training 0.583333            validation 0.5544\n",
      "\n",
      "step: 15600 training 0.5            validation 0.5566\n",
      "\n",
      "step: 15650 training 0.466667            validation 0.557\n",
      "\n",
      "step: 15700 training 0.483333            validation 0.555\n",
      "\n",
      "step: 15750 training 0.566667            validation 0.5572\n",
      "\n",
      "step: 15800 training 0.566667            validation 0.5576\n",
      "\n",
      "step: 15850 training 0.583333            validation 0.5564\n",
      "\n",
      "step: 15900 training 0.583333            validation 0.5562\n",
      "\n",
      "step: 15950 training 0.616667            validation 0.5564\n",
      "\n",
      "step: 16000 training 0.65            validation 0.555\n",
      "\n",
      "step: 16050 training 0.516667            validation 0.5564\n",
      "\n",
      "step: 16100 training 0.533333            validation 0.5564\n",
      "\n",
      "step: 16150 training 0.683333            validation 0.5558\n",
      "\n",
      "step: 16200 training 0.4            validation 0.5556\n",
      "\n",
      "step: 16250 training 0.483333            validation 0.5538\n",
      "\n",
      "step: 16300 training 0.616667            validation 0.5558\n",
      "\n",
      "step: 16350 training 0.616667            validation 0.5556\n",
      "\n",
      "step: 16400 training 0.416667            validation 0.5556\n",
      "\n",
      "step: 16450 training 0.5            validation 0.5558\n",
      "\n",
      "step: 16500 training 0.5            validation 0.5544\n",
      "\n",
      "step: 16550 training 0.466667            validation 0.553\n",
      "\n",
      "step: 16600 training 0.516667            validation 0.5548\n",
      "\n",
      "step: 16650 training 0.6            validation 0.557\n",
      "\n",
      "step: 16700 training 0.6            validation 0.5562\n",
      "\n",
      "step: 16750 training 0.516667            validation 0.5556\n",
      "\n",
      "step: 16800 training 0.6            validation 0.5588\n",
      "\n",
      "step: 16850 training 0.45            validation 0.5562\n",
      "\n",
      "step: 16900 training 0.533333            validation 0.557\n",
      "\n",
      "step: 16950 training 0.533333            validation 0.556\n",
      "\n",
      "step: 17000 training 0.533333            validation 0.5566\n",
      "\n",
      "step: 17050 training 0.65            validation 0.557\n",
      "\n",
      "step: 17100 training 0.7            validation 0.5572\n",
      "\n",
      "step: 17150 training 0.45            validation 0.5562\n",
      "\n",
      "step: 17200 training 0.6            validation 0.5552\n",
      "\n",
      "step: 17250 training 0.7            validation 0.5556\n",
      "\n",
      "step: 17300 training 0.516667            validation 0.557\n",
      "\n",
      "step: 17350 training 0.566667            validation 0.5558\n",
      "\n",
      "step: 17400 training 0.55            validation 0.557\n",
      "\n",
      "step: 17450 training 0.616667            validation 0.5554\n",
      "\n",
      "step: 17500 training 0.65            validation 0.5558\n",
      "\n",
      "step: 17550 training 0.6            validation 0.555\n",
      "\n",
      "step: 17600 training 0.45            validation 0.5568\n",
      "\n",
      "step: 17650 training 0.566667            validation 0.5558\n",
      "\n",
      "step: 17700 training 0.55            validation 0.5562\n",
      "\n",
      "step: 17750 training 0.633333            validation 0.5548\n",
      "\n",
      "step: 17800 training 0.6            validation 0.5556\n",
      "\n",
      "step: 17850 training 0.583333            validation 0.5558\n",
      "\n",
      "step: 17900 training 0.516667            validation 0.556\n",
      "\n",
      "step: 17950 training 0.616667            validation 0.5584\n",
      "\n",
      "step: 18000 training 0.6            validation 0.5582\n",
      "\n",
      "step: 18050 training 0.5            validation 0.5546\n",
      "\n",
      "step: 18100 training 0.65            validation 0.5546\n",
      "\n",
      "step: 18150 training 0.55            validation 0.556\n",
      "\n",
      "step: 18200 training 0.666667            validation 0.5556\n",
      "\n",
      "step: 18250 training 0.633333            validation 0.5568\n",
      "\n",
      "step: 18300 training 0.55            validation 0.5548\n",
      "\n",
      "step: 18350 training 0.566667            validation 0.5556\n",
      "\n",
      "step: 18400 training 0.666667            validation 0.5562\n",
      "\n",
      "step: 18450 training 0.583333            validation 0.5572\n",
      "\n",
      "step: 18500 training 0.6            validation 0.5572\n",
      "\n",
      "step: 18550 training 0.616667            validation 0.5562\n",
      "\n",
      "step: 18600 training 0.516667            validation 0.5568\n",
      "\n",
      "step: 18650 training 0.45            validation 0.5554\n",
      "\n",
      "step: 18700 training 0.666667            validation 0.5574\n",
      "\n",
      "step: 18750 training 0.55            validation 0.5574\n",
      "\n",
      "step: 18800 training 0.6            validation 0.5564\n",
      "\n",
      "step: 18850 training 0.633333            validation 0.5594\n",
      "\n",
      "step: 18900 training 0.55            validation 0.5538\n",
      "\n",
      "step: 18950 training 0.65            validation 0.5566\n",
      "\n",
      "step: 19000 training 0.683333            validation 0.5546\n",
      "\n",
      "step: 19050 training 0.583333            validation 0.5576\n",
      "\n",
      "step: 19100 training 0.516667            validation 0.5562\n",
      "\n",
      "step: 19150 training 0.616667            validation 0.5552\n",
      "\n",
      "step: 19200 training 0.5            validation 0.556\n",
      "\n",
      "step: 19250 training 0.616667            validation 0.5548\n",
      "\n",
      "step: 19300 training 0.566667            validation 0.5566\n",
      "\n",
      "step: 19350 training 0.6            validation 0.5588\n",
      "\n",
      "step: 19400 training 0.566667            validation 0.5604\n",
      "\n",
      "step: 19450 training 0.566667            validation 0.555\n",
      "\n",
      "step: 19500 training 0.65            validation 0.5556\n",
      "\n",
      "step: 19550 training 0.55            validation 0.5574\n",
      "\n",
      "step: 19600 training 0.55            validation 0.5578\n",
      "\n",
      "step: 19650 training 0.566667            validation 0.5568\n",
      "\n",
      "step: 19700 training 0.5            validation 0.557\n",
      "\n",
      "step: 19750 training 0.566667            validation 0.5548\n",
      "\n",
      "step: 19800 training 0.483333            validation 0.5552\n",
      "\n",
      "step: 19850 training 0.6            validation 0.5542\n",
      "\n",
      "step: 19900 training 0.6            validation 0.556\n",
      "\n",
      "step: 19950 training 0.466667            validation 0.5562\n",
      "\n",
      "step: 20000 training 0.666667            validation 0.557\n",
      "\n",
      "step: 20050 training 0.55            validation 0.5572\n",
      "\n",
      "step: 20100 training 0.633333            validation 0.5566\n",
      "\n",
      "step: 20150 training 0.6            validation 0.557\n",
      "\n",
      "step: 20200 training 0.516667            validation 0.5574\n",
      "\n",
      "step: 20250 training 0.516667            validation 0.5574\n",
      "\n",
      "step: 20300 training 0.616667            validation 0.5594\n",
      "\n",
      "step: 20350 training 0.533333            validation 0.5556\n",
      "\n",
      "step: 20400 training 0.416667            validation 0.5576\n",
      "\n",
      "step: 20450 training 0.683333            validation 0.558\n",
      "\n",
      "step: 20500 training 0.533333            validation 0.5548\n",
      "\n",
      "step: 20550 training 0.616667            validation 0.5554\n",
      "\n",
      "step: 20600 training 0.533333            validation 0.5582\n",
      "\n",
      "step: 20650 training 0.583333            validation 0.5566\n",
      "\n",
      "step: 20700 training 0.6            validation 0.556\n",
      "\n",
      "step: 20750 training 0.583333            validation 0.556\n",
      "\n",
      "step: 20800 training 0.65            validation 0.5562\n",
      "\n",
      "step: 20850 training 0.583333            validation 0.5576\n",
      "\n",
      "step: 20900 training 0.7            validation 0.5562\n",
      "\n",
      "step: 20950 training 0.583333            validation 0.5562\n",
      "\n",
      "step: 21000 training 0.633333            validation 0.5566\n",
      "\n",
      "step: 21050 training 0.55            validation 0.5574\n",
      "\n",
      "step: 21100 training 0.65            validation 0.5582\n",
      "\n",
      "step: 21150 training 0.533333            validation 0.557\n",
      "\n",
      "step: 21200 training 0.633333            validation 0.5584\n",
      "\n",
      "step: 21250 training 0.583333            validation 0.5562\n",
      "\n",
      "step: 21300 training 0.5            validation 0.5578\n",
      "\n",
      "step: 21350 training 0.7            validation 0.5564\n",
      "\n",
      "step: 21400 training 0.5            validation 0.5562\n",
      "\n",
      "step: 21450 training 0.666667            validation 0.5588\n",
      "\n",
      "step: 21500 training 0.55            validation 0.5584\n",
      "\n",
      "step: 21550 training 0.6            validation 0.5568\n",
      "\n",
      "step: 21600 training 0.533333            validation 0.5582\n",
      "\n",
      "step: 21650 training 0.533333            validation 0.5582\n",
      "\n",
      "step: 21700 training 0.55            validation 0.5578\n",
      "\n",
      "step: 21750 training 0.633333            validation 0.5588\n",
      "\n",
      "step: 21800 training 0.583333            validation 0.559\n",
      "\n",
      "step: 21850 training 0.683333            validation 0.5568\n",
      "\n",
      "step: 21900 training 0.45            validation 0.5564\n",
      "\n",
      "step: 21950 training 0.5            validation 0.557\n",
      "\n",
      "step: 22000 training 0.566667            validation 0.5594\n",
      "\n",
      "step: 22050 training 0.65            validation 0.5576\n",
      "\n",
      "step: 22100 training 0.516667            validation 0.5578\n",
      "\n",
      "step: 22150 training 0.483333            validation 0.5578\n",
      "\n",
      "step: 22200 training 0.6            validation 0.558\n",
      "\n",
      "step: 22250 training 0.516667            validation 0.5582\n",
      "\n",
      "step: 22300 training 0.583333            validation 0.556\n",
      "\n",
      "step: 22350 training 0.65            validation 0.5578\n",
      "\n",
      "step: 22400 training 0.65            validation 0.558\n",
      "\n",
      "step: 22450 training 0.5            validation 0.5586\n",
      "\n",
      "step: 22500 training 0.633333            validation 0.559\n",
      "\n",
      "step: 22550 training 0.466667            validation 0.557\n",
      "\n",
      "step: 22600 training 0.516667            validation 0.5588\n",
      "\n",
      "step: 22650 training 0.566667            validation 0.5592\n",
      "\n",
      "step: 22700 training 0.483333            validation 0.5592\n",
      "\n",
      "step: 22750 training 0.55            validation 0.557\n",
      "\n",
      "step: 22800 training 0.633333            validation 0.555\n",
      "\n",
      "step: 22850 training 0.6            validation 0.5576\n",
      "\n",
      "step: 22900 training 0.65            validation 0.555\n",
      "\n",
      "step: 22950 training 0.433333            validation 0.5584\n",
      "\n",
      "step: 23000 training 0.616667            validation 0.5594\n",
      "\n",
      "step: 23050 training 0.6            validation 0.5584\n",
      "\n",
      "step: 23100 training 0.583333            validation 0.5574\n",
      "\n",
      "step: 23150 training 0.566667            validation 0.5546\n",
      "\n",
      "step: 23200 training 0.633333            validation 0.5588\n",
      "\n",
      "step: 23250 training 0.683333            validation 0.558\n",
      "\n",
      "step: 23300 training 0.566667            validation 0.5564\n",
      "\n",
      "step: 23350 training 0.5            validation 0.559\n",
      "\n",
      "step: 23400 training 0.65            validation 0.5562\n",
      "\n",
      "step: 23450 training 0.65            validation 0.558\n",
      "\n",
      "step: 23500 training 0.583333            validation 0.556\n",
      "\n",
      "step: 23550 training 0.583333            validation 0.5576\n",
      "\n",
      "step: 23600 training 0.533333            validation 0.557\n",
      "\n",
      "step: 23650 training 0.5            validation 0.5558\n",
      "\n",
      "step: 23700 training 0.566667            validation 0.5566\n",
      "\n",
      "step: 23750 training 0.6            validation 0.5576\n",
      "\n",
      "step: 23800 training 0.666667            validation 0.5574\n",
      "\n",
      "step: 23850 training 0.583333            validation 0.5564\n",
      "\n",
      "step: 23900 training 0.516667            validation 0.556\n",
      "\n",
      "step: 23950 training 0.483333            validation 0.5568\n",
      "\n",
      "step: 24000 training 0.516667            validation 0.5568\n",
      "\n",
      "step: 24050 training 0.433333            validation 0.5566\n",
      "\n",
      "step: 24100 training 0.683333            validation 0.5578\n",
      "\n",
      "step: 24150 training 0.583333            validation 0.5578\n",
      "\n",
      "step: 24200 training 0.666667            validation 0.559\n",
      "\n",
      "step: 24250 training 0.566667            validation 0.5574\n",
      "\n",
      "step: 24300 training 0.6            validation 0.5574\n",
      "\n",
      "step: 24350 training 0.633333            validation 0.557\n",
      "\n",
      "step: 24400 training 0.6            validation 0.5546\n",
      "\n",
      "step: 24450 training 0.633333            validation 0.557\n",
      "\n",
      "step: 24500 training 0.6            validation 0.5608\n",
      "\n",
      "step: 24550 training 0.566667            validation 0.5582\n",
      "\n",
      "step: 24600 training 0.55            validation 0.5578\n",
      "\n",
      "step: 24650 training 0.516667            validation 0.557\n",
      "\n",
      "step: 24700 training 0.466667            validation 0.5578\n",
      "\n",
      "step: 24750 training 0.566667            validation 0.5576\n",
      "\n",
      "step: 24800 training 0.433333            validation 0.5572\n",
      "\n",
      "step: 24850 training 0.566667            validation 0.5582\n",
      "\n",
      "step: 24900 training 0.5            validation 0.5558\n",
      "\n",
      "step: 24950 training 0.583333            validation 0.5586\n",
      "\n",
      "step: 25000 training 0.6            validation 0.5586\n",
      "\n",
      "step: 25050 training 0.5            validation 0.5578\n",
      "\n",
      "step: 25100 training 0.55            validation 0.5582\n",
      "\n",
      "step: 25150 training 0.616667            validation 0.5576\n",
      "\n",
      "step: 25200 training 0.616667            validation 0.557\n",
      "\n",
      "step: 25250 training 0.466667            validation 0.5568\n",
      "\n",
      "step: 25300 training 0.55            validation 0.5564\n",
      "\n",
      "step: 25350 training 0.65            validation 0.5558\n",
      "\n",
      "step: 25400 training 0.533333            validation 0.559\n",
      "\n",
      "step: 25450 training 0.566667            validation 0.557\n",
      "\n",
      "step: 25500 training 0.516667            validation 0.5562\n",
      "\n",
      "step: 25550 training 0.5            validation 0.558\n",
      "\n",
      "step: 25600 training 0.65            validation 0.5572\n",
      "\n",
      "step: 25650 training 0.5            validation 0.5582\n",
      "\n",
      "step: 25700 training 0.7            validation 0.5568\n",
      "\n",
      "step: 25750 training 0.466667            validation 0.5574\n",
      "\n",
      "step: 25800 training 0.616667            validation 0.5556\n",
      "\n",
      "step: 25850 training 0.416667            validation 0.5576\n",
      "\n",
      "step: 25900 training 0.566667            validation 0.5582\n",
      "\n",
      "step: 25950 training 0.533333            validation 0.5582\n",
      "\n",
      "step: 26000 training 0.533333            validation 0.5566\n",
      "\n",
      "step: 26050 training 0.583333            validation 0.5564\n",
      "\n",
      "step: 26100 training 0.516667            validation 0.5582\n",
      "\n",
      "step: 26150 training 0.5            validation 0.5568\n",
      "\n",
      "step: 26200 training 0.483333            validation 0.5576\n",
      "\n",
      "step: 26250 training 0.516667            validation 0.5574\n",
      "\n",
      "step: 26300 training 0.533333            validation 0.5572\n",
      "\n",
      "step: 26350 training 0.683333            validation 0.5576\n",
      "\n",
      "step: 26400 training 0.6            validation 0.5586\n",
      "\n",
      "step: 26450 training 0.566667            validation 0.557\n",
      "\n",
      "step: 26500 training 0.566667            validation 0.5566\n",
      "\n",
      "step: 26550 training 0.416667            validation 0.5572\n",
      "\n",
      "step: 26600 training 0.5            validation 0.5586\n",
      "\n",
      "step: 26650 training 0.683333            validation 0.557\n",
      "\n",
      "step: 26700 training 0.466667            validation 0.558\n",
      "\n",
      "step: 26750 training 0.616667            validation 0.5576\n",
      "\n",
      "step: 26800 training 0.533333            validation 0.559\n",
      "\n",
      "step: 26850 training 0.466667            validation 0.5594\n",
      "\n",
      "step: 26900 training 0.55            validation 0.558\n",
      "\n",
      "step: 26950 training 0.616667            validation 0.5586\n",
      "\n",
      "step: 27000 training 0.566667            validation 0.5574\n",
      "\n",
      "step: 27050 training 0.516667            validation 0.5578\n",
      "\n",
      "step: 27100 training 0.5            validation 0.5578\n",
      "\n",
      "step: 27150 training 0.65            validation 0.5586\n",
      "\n",
      "step: 27200 training 0.45            validation 0.5574\n",
      "\n",
      "step: 27250 training 0.633333            validation 0.5592\n",
      "\n",
      "step: 27300 training 0.55            validation 0.5596\n",
      "\n",
      "step: 27350 training 0.55            validation 0.5566\n",
      "\n",
      "step: 27400 training 0.55            validation 0.5586\n",
      "\n",
      "step: 27450 training 0.466667            validation 0.5548\n",
      "\n",
      "step: 27500 training 0.55            validation 0.5562\n",
      "\n",
      "step: 27550 training 0.666667            validation 0.5558\n",
      "\n",
      "step: 27600 training 0.55            validation 0.5578\n",
      "\n",
      "step: 27650 training 0.583333            validation 0.5578\n",
      "\n",
      "step: 27700 training 0.583333            validation 0.5582\n",
      "\n",
      "step: 27750 training 0.533333            validation 0.558\n",
      "\n",
      "step: 27800 training 0.6            validation 0.5552\n",
      "\n",
      "step: 27850 training 0.6            validation 0.5568\n",
      "\n",
      "step: 27900 training 0.55            validation 0.5548\n",
      "\n",
      "step: 27950 training 0.533333            validation 0.559\n",
      "\n",
      "step: 28000 training 0.6            validation 0.5596\n",
      "\n",
      "step: 28050 training 0.6            validation 0.5566\n",
      "\n",
      "step: 28100 training 0.666667            validation 0.556\n",
      "\n",
      "step: 28150 training 0.666667            validation 0.5592\n",
      "\n",
      "step: 28200 training 0.566667            validation 0.5576\n",
      "\n",
      "step: 28250 training 0.6            validation 0.5602\n",
      "\n",
      "step: 28300 training 0.583333            validation 0.5602\n",
      "\n",
      "step: 28350 training 0.433333            validation 0.5594\n",
      "\n",
      "step: 28400 training 0.516667            validation 0.5584\n",
      "\n",
      "step: 28450 training 0.7            validation 0.56\n",
      "\n",
      "step: 28500 training 0.616667            validation 0.5592\n",
      "\n",
      "step: 28550 training 0.566667            validation 0.5582\n",
      "\n",
      "step: 28600 training 0.566667            validation 0.56\n",
      "\n",
      "step: 28650 training 0.666667            validation 0.5588\n",
      "\n",
      "step: 28700 training 0.6            validation 0.5586\n",
      "\n",
      "step: 28750 training 0.483333            validation 0.5558\n",
      "\n",
      "step: 28800 training 0.666667            validation 0.559\n",
      "\n",
      "step: 28850 training 0.533333            validation 0.5582\n",
      "\n",
      "step: 28900 training 0.583333            validation 0.5578\n",
      "\n",
      "step: 28950 training 0.616667            validation 0.5602\n",
      "\n",
      "step: 29000 training 0.55            validation 0.5594\n",
      "\n",
      "step: 29050 training 0.55            validation 0.5584\n",
      "\n",
      "step: 29100 training 0.683333            validation 0.5596\n",
      "\n",
      "step: 29150 training 0.533333            validation 0.5552\n",
      "\n",
      "step: 29200 training 0.55            validation 0.5572\n",
      "\n",
      "step: 29250 training 0.483333            validation 0.558\n",
      "\n",
      "step: 29300 training 0.683333            validation 0.5588\n",
      "\n",
      "step: 29350 training 0.566667            validation 0.5588\n",
      "\n",
      "step: 29400 training 0.55            validation 0.5586\n",
      "\n",
      "step: 29450 training 0.583333            validation 0.5598\n",
      "\n",
      "step: 29500 training 0.533333            validation 0.5596\n",
      "\n",
      "step: 29550 training 0.616667            validation 0.557\n",
      "\n",
      "step: 29600 training 0.45            validation 0.557\n",
      "\n",
      "step: 29650 training 0.583333            validation 0.5572\n",
      "\n",
      "step: 29700 training 0.583333            validation 0.5556\n",
      "\n",
      "step: 29750 training 0.6            validation 0.56\n",
      "\n",
      "step: 29800 training 0.616667            validation 0.5558\n",
      "\n",
      "step: 29850 training 0.583333            validation 0.5598\n",
      "\n",
      "step: 29900 training 0.583333            validation 0.5568\n",
      "\n",
      "step: 29950 training 0.583333            validation 0.5588\n",
      "\n",
      "step: 30000 training 0.5            validation 0.5588\n",
      "\n",
      "step: 30050 training 0.533333            validation 0.5568\n",
      "\n",
      "step: 30100 training 0.583333            validation 0.5588\n",
      "\n",
      "step: 30150 training 0.45            validation 0.5556\n",
      "\n",
      "step: 30200 training 0.683333            validation 0.5572\n",
      "\n",
      "step: 30250 training 0.45            validation 0.557\n",
      "\n",
      "step: 30300 training 0.566667            validation 0.5576\n",
      "\n",
      "step: 30350 training 0.583333            validation 0.5564\n",
      "\n",
      "step: 30400 training 0.566667            validation 0.5584\n",
      "\n",
      "step: 30450 training 0.466667            validation 0.5556\n",
      "\n",
      "step: 30500 training 0.55            validation 0.559\n",
      "\n",
      "step: 30550 training 0.6            validation 0.556\n",
      "\n",
      "step: 30600 training 0.483333            validation 0.5596\n",
      "\n",
      "step: 30650 training 0.65            validation 0.5602\n",
      "\n",
      "step: 30700 training 0.566667            validation 0.558\n",
      "\n",
      "step: 30750 training 0.416667            validation 0.5586\n",
      "\n",
      "step: 30800 training 0.516667            validation 0.5588\n",
      "\n",
      "step: 30850 training 0.566667            validation 0.5584\n",
      "\n",
      "step: 30900 training 0.466667            validation 0.556\n",
      "\n",
      "step: 30950 training 0.483333            validation 0.5588\n",
      "\n",
      "step: 31000 training 0.55            validation 0.5574\n",
      "\n",
      "step: 31050 training 0.5            validation 0.5576\n",
      "\n",
      "step: 31100 training 0.633333            validation 0.5576\n",
      "\n",
      "step: 31150 training 0.7            validation 0.559\n",
      "\n",
      "step: 31200 training 0.466667            validation 0.5574\n",
      "\n",
      "step: 31250 training 0.533333            validation 0.559\n",
      "\n",
      "step: 31300 training 0.55            validation 0.5598\n",
      "\n",
      "step: 31350 training 0.516667            validation 0.5598\n",
      "\n",
      "step: 31400 training 0.55            validation 0.5604\n",
      "\n",
      "step: 31450 training 0.583333            validation 0.5604\n",
      "\n",
      "step: 31500 training 0.683333            validation 0.559\n",
      "\n",
      "step: 31550 training 0.566667            validation 0.5582\n",
      "\n",
      "step: 31600 training 0.416667            validation 0.5586\n",
      "\n",
      "step: 31650 training 0.666667            validation 0.56\n",
      "\n",
      "step: 31700 training 0.466667            validation 0.5606\n",
      "\n",
      "step: 31750 training 0.65            validation 0.5588\n",
      "\n",
      "step: 31800 training 0.516667            validation 0.5576\n",
      "\n",
      "step: 31850 training 0.55            validation 0.5594\n",
      "\n",
      "step: 31900 training 0.533333            validation 0.5592\n",
      "\n",
      "step: 31950 training 0.6            validation 0.5612\n",
      "\n",
      "step: 32000 training 0.483333            validation 0.5586\n",
      "\n",
      "step: 32050 training 0.533333            validation 0.5598\n",
      "\n",
      "step: 32100 training 0.583333            validation 0.5588\n",
      "\n",
      "step: 32150 training 0.533333            validation 0.5598\n",
      "\n",
      "step: 32200 training 0.6            validation 0.561\n",
      "\n",
      "step: 32250 training 0.6            validation 0.5596\n",
      "\n",
      "step: 32300 training 0.55            validation 0.5594\n",
      "\n",
      "step: 32350 training 0.616667            validation 0.559\n",
      "\n",
      "step: 32400 training 0.683333            validation 0.5594\n",
      "\n",
      "step: 32450 training 0.633333            validation 0.5604\n",
      "\n",
      "step: 32500 training 0.55            validation 0.5584\n",
      "\n",
      "step: 32550 training 0.516667            validation 0.5588\n",
      "\n",
      "step: 32600 training 0.616667            validation 0.5604\n",
      "\n",
      "step: 32650 training 0.583333            validation 0.5606\n",
      "\n",
      "step: 32700 training 0.55            validation 0.5578\n",
      "\n",
      "step: 32750 training 0.6            validation 0.5574\n",
      "\n",
      "step: 32800 training 0.566667            validation 0.5584\n",
      "\n",
      "step: 32850 training 0.5            validation 0.559\n",
      "\n",
      "step: 32900 training 0.55            validation 0.5566\n",
      "\n",
      "step: 32950 training 0.516667            validation 0.5604\n",
      "\n",
      "step: 33000 training 0.533333            validation 0.5578\n",
      "\n",
      "step: 33050 training 0.583333            validation 0.5594\n",
      "\n",
      "step: 33100 training 0.616667            validation 0.5592\n",
      "\n",
      "step: 33150 training 0.433333            validation 0.558\n",
      "\n",
      "step: 33200 training 0.583333            validation 0.5576\n",
      "\n",
      "step: 33250 training 0.533333            validation 0.5572\n",
      "\n",
      "step: 33300 training 0.633333            validation 0.5588\n",
      "\n",
      "step: 33350 training 0.566667            validation 0.5602\n",
      "\n",
      "step: 33400 training 0.566667            validation 0.5594\n",
      "\n",
      "step: 33450 training 0.633333            validation 0.557\n",
      "\n",
      "step: 33500 training 0.583333            validation 0.5612\n",
      "\n",
      "step: 33550 training 0.6            validation 0.559\n",
      "\n",
      "step: 33600 training 0.466667            validation 0.5584\n",
      "\n",
      "step: 33650 training 0.6            validation 0.5596\n",
      "\n",
      "step: 33700 training 0.716667            validation 0.5588\n",
      "\n",
      "step: 33750 training 0.683333            validation 0.5596\n",
      "\n",
      "step: 33800 training 0.7            validation 0.5598\n",
      "\n",
      "step: 33850 training 0.616667            validation 0.5608\n",
      "\n",
      "step: 33900 training 0.65            validation 0.5598\n",
      "\n",
      "step: 33950 training 0.516667            validation 0.5568\n",
      "\n",
      "step: 34000 training 0.516667            validation 0.5602\n",
      "\n",
      "step: 34050 training 0.566667            validation 0.5592\n",
      "\n",
      "step: 34100 training 0.566667            validation 0.5602\n",
      "\n",
      "step: 34150 training 0.55            validation 0.559\n",
      "\n",
      "step: 34200 training 0.65            validation 0.558\n",
      "\n",
      "step: 34250 training 0.566667            validation 0.5602\n",
      "\n",
      "step: 34300 training 0.483333            validation 0.5594\n",
      "\n",
      "step: 34350 training 0.683333            validation 0.5612\n",
      "\n",
      "step: 34400 training 0.616667            validation 0.559\n",
      "\n",
      "step: 34450 training 0.533333            validation 0.5574\n",
      "\n",
      "step: 34500 training 0.7            validation 0.5594\n",
      "\n",
      "step: 34550 training 0.583333            validation 0.557\n",
      "\n",
      "step: 34600 training 0.516667            validation 0.5596\n",
      "\n",
      "step: 34650 training 0.566667            validation 0.5582\n",
      "\n",
      "step: 34700 training 0.583333            validation 0.5576\n",
      "\n",
      "step: 34750 training 0.516667            validation 0.5562\n",
      "\n",
      "step: 34800 training 0.566667            validation 0.5592\n",
      "\n",
      "step: 34850 training 0.616667            validation 0.5582\n",
      "\n",
      "step: 34900 training 0.6            validation 0.558\n",
      "\n",
      "step: 34950 training 0.6            validation 0.5592\n",
      "\n",
      "step: 35000 training 0.633333            validation 0.5592\n",
      "\n",
      "step: 35050 training 0.55            validation 0.56\n",
      "\n",
      "step: 35100 training 0.416667            validation 0.5574\n",
      "\n",
      "step: 35150 training 0.633333            validation 0.5562\n",
      "\n",
      "step: 35200 training 0.533333            validation 0.5564\n",
      "\n",
      "step: 35250 training 0.6            validation 0.5576\n",
      "\n",
      "step: 35300 training 0.6            validation 0.5584\n",
      "\n",
      "step: 35350 training 0.65            validation 0.5572\n",
      "\n",
      "step: 35400 training 0.533333            validation 0.5592\n",
      "\n",
      "step: 35450 training 0.65            validation 0.5568\n",
      "\n",
      "step: 35500 training 0.583333            validation 0.5566\n",
      "\n",
      "step: 35550 training 0.416667            validation 0.5588\n",
      "\n",
      "step: 35600 training 0.566667            validation 0.561\n",
      "\n",
      "step: 35650 training 0.616667            validation 0.5592\n",
      "\n",
      "step: 35700 training 0.616667            validation 0.556\n",
      "\n",
      "step: 35750 training 0.583333            validation 0.556\n",
      "\n",
      "step: 35800 training 0.5            validation 0.558\n",
      "\n",
      "step: 35850 training 0.583333            validation 0.5566\n",
      "\n",
      "step: 35900 training 0.65            validation 0.5572\n",
      "\n",
      "step: 35950 training 0.533333            validation 0.5564\n",
      "\n",
      "step: 36000 training 0.566667            validation 0.5578\n",
      "\n",
      "step: 36050 training 0.55            validation 0.556\n",
      "\n",
      "step: 36100 training 0.616667            validation 0.558\n",
      "\n",
      "step: 36150 training 0.55            validation 0.5584\n",
      "\n",
      "step: 36200 training 0.55            validation 0.5568\n",
      "\n",
      "step: 36250 training 0.516667            validation 0.5594\n",
      "\n",
      "step: 36300 training 0.583333            validation 0.5592\n",
      "\n",
      "step: 36350 training 0.583333            validation 0.5608\n",
      "\n",
      "step: 36400 training 0.566667            validation 0.5584\n",
      "\n",
      "step: 36450 training 0.516667            validation 0.56\n",
      "\n",
      "step: 36500 training 0.583333            validation 0.5606\n",
      "\n",
      "step: 36550 training 0.6            validation 0.561\n",
      "\n",
      "step: 36600 training 0.6            validation 0.561\n",
      "\n",
      "step: 36650 training 0.683333            validation 0.561\n",
      "\n",
      "step: 36700 training 0.583333            validation 0.56\n",
      "\n",
      "step: 36750 training 0.633333            validation 0.5592\n",
      "\n",
      "step: 36800 training 0.6            validation 0.5586\n",
      "\n",
      "step: 36850 training 0.516667            validation 0.5582\n",
      "\n",
      "step: 36900 training 0.516667            validation 0.5588\n",
      "\n",
      "step: 36950 training 0.566667            validation 0.5594\n",
      "\n",
      "step: 37000 training 0.6            validation 0.5574\n",
      "\n",
      "step: 37050 training 0.5            validation 0.5614\n",
      "\n",
      "step: 37100 training 0.616667            validation 0.5594\n",
      "\n",
      "step: 37150 training 0.466667            validation 0.5588\n",
      "\n",
      "step: 37200 training 0.533333            validation 0.5596\n",
      "\n",
      "step: 37250 training 0.583333            validation 0.5612\n",
      "\n",
      "step: 37300 training 0.533333            validation 0.5588\n",
      "\n",
      "step: 37350 training 0.55            validation 0.558\n",
      "\n",
      "step: 37400 training 0.583333            validation 0.558\n",
      "\n",
      "step: 37450 training 0.583333            validation 0.5574\n",
      "\n",
      "step: 37500 training 0.483333            validation 0.5586\n",
      "\n",
      "step: 37550 training 0.533333            validation 0.5592\n",
      "\n",
      "step: 37600 training 0.5            validation 0.5534\n",
      "\n",
      "step: 37650 training 0.5            validation 0.558\n",
      "\n",
      "step: 37700 training 0.433333            validation 0.5586\n",
      "\n",
      "step: 37750 training 0.55            validation 0.5602\n",
      "\n",
      "step: 37800 training 0.583333            validation 0.561\n",
      "\n",
      "step: 37850 training 0.55            validation 0.5568\n",
      "\n",
      "step: 37900 training 0.5            validation 0.5582\n",
      "\n",
      "step: 37950 training 0.633333            validation 0.5586\n",
      "\n",
      "step: 38000 training 0.533333            validation 0.5604\n",
      "\n",
      "step: 38050 training 0.566667            validation 0.557\n",
      "\n",
      "step: 38100 training 0.55            validation 0.5604\n",
      "\n",
      "step: 38150 training 0.6            validation 0.5584\n",
      "\n",
      "step: 38200 training 0.5            validation 0.56\n",
      "\n",
      "step: 38250 training 0.566667            validation 0.5568\n",
      "\n",
      "step: 38300 training 0.516667            validation 0.5602\n",
      "\n",
      "step: 38350 training 0.55            validation 0.5596\n",
      "\n",
      "step: 38400 training 0.616667            validation 0.5608\n",
      "\n",
      "step: 38450 training 0.6            validation 0.5578\n",
      "\n",
      "step: 38500 training 0.516667            validation 0.5558\n",
      "\n",
      "step: 38550 training 0.566667            validation 0.5592\n",
      "\n",
      "step: 38600 training 0.666667            validation 0.56\n",
      "\n",
      "step: 38650 training 0.566667            validation 0.5586\n",
      "\n",
      "step: 38700 training 0.6            validation 0.5592\n",
      "\n",
      "step: 38750 training 0.566667            validation 0.5572\n",
      "\n",
      "step: 38800 training 0.6            validation 0.5566\n",
      "\n",
      "step: 38850 training 0.433333            validation 0.5572\n",
      "\n",
      "step: 38900 training 0.5            validation 0.5572\n",
      "\n",
      "step: 38950 training 0.616667            validation 0.5578\n",
      "\n",
      "step: 39000 training 0.55            validation 0.5576\n",
      "\n",
      "step: 39050 training 0.666667            validation 0.5616\n",
      "\n",
      "step: 39100 training 0.6            validation 0.556\n",
      "\n",
      "step: 39150 training 0.5            validation 0.5602\n",
      "\n",
      "step: 39200 training 0.566667            validation 0.5578\n",
      "\n",
      "step: 39250 training 0.466667            validation 0.5616\n",
      "\n",
      "step: 39300 training 0.45            validation 0.559\n",
      "\n",
      "step: 39350 training 0.616667            validation 0.5568\n",
      "\n",
      "step: 39400 training 0.516667            validation 0.5584\n",
      "\n",
      "step: 39450 training 0.583333            validation 0.5584\n",
      "\n",
      "step: 39500 training 0.583333            validation 0.5592\n",
      "\n",
      "step: 39550 training 0.516667            validation 0.5598\n",
      "\n",
      "step: 39600 training 0.566667            validation 0.5572\n",
      "\n",
      "step: 39650 training 0.5            validation 0.5622\n",
      "\n",
      "step: 39700 training 0.616667            validation 0.5564\n",
      "\n",
      "step: 39750 training 0.65            validation 0.5598\n",
      "\n",
      "step: 39800 training 0.55            validation 0.561\n",
      "\n",
      "step: 39850 training 0.416667            validation 0.5602\n",
      "\n",
      "step: 39900 training 0.55            validation 0.56\n",
      "\n",
      "step: 39950 training 0.55            validation 0.559\n",
      "\n",
      "step: 40000 training 0.55            validation 0.5602\n",
      "\n",
      "step: 40050 training 0.45            validation 0.5568\n",
      "\n",
      "step: 40100 training 0.516667            validation 0.557\n",
      "\n",
      "step: 40150 training 0.566667            validation 0.5596\n",
      "\n",
      "step: 40200 training 0.6            validation 0.5572\n",
      "\n",
      "step: 40250 training 0.666667            validation 0.5592\n",
      "\n",
      "step: 40300 training 0.616667            validation 0.5594\n",
      "\n",
      "step: 40350 training 0.55            validation 0.5596\n",
      "\n",
      "step: 40400 training 0.55            validation 0.5586\n",
      "\n",
      "step: 40450 training 0.533333            validation 0.5588\n",
      "\n",
      "step: 40500 training 0.566667            validation 0.5592\n",
      "\n",
      "step: 40550 training 0.516667            validation 0.5586\n",
      "\n",
      "step: 40600 training 0.533333            validation 0.5564\n",
      "\n",
      "step: 40650 training 0.5            validation 0.5598\n",
      "\n",
      "step: 40700 training 0.566667            validation 0.5558\n",
      "\n",
      "step: 40750 training 0.583333            validation 0.558\n",
      "\n",
      "step: 40800 training 0.65            validation 0.558\n",
      "\n",
      "step: 40850 training 0.583333            validation 0.5614\n",
      "\n",
      "step: 40900 training 0.616667            validation 0.561\n",
      "\n",
      "step: 40950 training 0.55            validation 0.56\n",
      "\n",
      "step: 41000 training 0.65            validation 0.5592\n",
      "\n",
      "step: 41050 training 0.516667            validation 0.5584\n",
      "\n",
      "step: 41100 training 0.716667            validation 0.5596\n",
      "\n",
      "step: 41150 training 0.516667            validation 0.5604\n",
      "\n",
      "step: 41200 training 0.55            validation 0.5594\n",
      "\n",
      "step: 41250 training 0.65            validation 0.5582\n",
      "\n",
      "step: 41300 training 0.45            validation 0.5608\n",
      "\n",
      "step: 41350 training 0.583333            validation 0.559\n",
      "\n",
      "step: 41400 training 0.533333            validation 0.5594\n",
      "\n",
      "step: 41450 training 0.5            validation 0.562\n",
      "\n",
      "step: 41500 training 0.466667            validation 0.5596\n",
      "\n",
      "step: 41550 training 0.633333            validation 0.5614\n",
      "\n",
      "step: 41600 training 0.6            validation 0.559\n",
      "\n",
      "step: 41650 training 0.65            validation 0.5614\n",
      "\n",
      "step: 41700 training 0.516667            validation 0.5612\n",
      "\n",
      "step: 41750 training 0.516667            validation 0.5596\n",
      "\n",
      "step: 41800 training 0.516667            validation 0.5584\n",
      "\n",
      "step: 41850 training 0.55            validation 0.5588\n",
      "\n",
      "step: 41900 training 0.65            validation 0.5598\n",
      "\n",
      "step: 41950 training 0.55            validation 0.5566\n",
      "\n",
      "step: 42000 training 0.616667            validation 0.5576\n",
      "\n",
      "step: 42050 training 0.566667            validation 0.5606\n",
      "\n",
      "step: 42100 training 0.666667            validation 0.562\n",
      "\n",
      "step: 42150 training 0.583333            validation 0.5588\n",
      "\n",
      "step: 42200 training 0.583333            validation 0.561\n",
      "\n",
      "step: 42250 training 0.533333            validation 0.5616\n",
      "\n",
      "step: 42300 training 0.466667            validation 0.557\n",
      "\n",
      "step: 42350 training 0.616667            validation 0.5604\n",
      "\n",
      "step: 42400 training 0.6            validation 0.56\n",
      "\n",
      "step: 42450 training 0.566667            validation 0.559\n",
      "\n",
      "step: 42500 training 0.55            validation 0.5606\n",
      "\n",
      "step: 42550 training 0.583333            validation 0.5578\n",
      "\n",
      "step: 42600 training 0.5            validation 0.5576\n",
      "\n",
      "step: 42650 training 0.5            validation 0.5588\n",
      "\n",
      "step: 42700 training 0.55            validation 0.561\n",
      "\n",
      "step: 42750 training 0.5            validation 0.5614\n",
      "\n",
      "step: 42800 training 0.583333            validation 0.558\n",
      "\n",
      "step: 42850 training 0.6            validation 0.5594\n",
      "\n",
      "step: 42900 training 0.583333            validation 0.558\n",
      "\n",
      "step: 42950 training 0.533333            validation 0.5586\n",
      "\n",
      "step: 43000 training 0.6            validation 0.5586\n",
      "\n",
      "step: 43050 training 0.5            validation 0.5594\n",
      "\n",
      "step: 43100 training 0.516667            validation 0.5578\n",
      "\n",
      "step: 43150 training 0.583333            validation 0.5582\n",
      "\n",
      "step: 43200 training 0.416667            validation 0.5582\n",
      "\n",
      "step: 43250 training 0.666667            validation 0.5582\n",
      "\n",
      "step: 43300 training 0.633333            validation 0.5594\n",
      "\n",
      "step: 43350 training 0.666667            validation 0.5602\n",
      "\n",
      "step: 43400 training 0.6            validation 0.5572\n",
      "\n",
      "step: 43450 training 0.45            validation 0.5604\n",
      "\n",
      "step: 43500 training 0.533333            validation 0.5578\n",
      "\n",
      "step: 43550 training 0.683333            validation 0.5612\n",
      "\n",
      "step: 43600 training 0.533333            validation 0.5586\n",
      "\n",
      "step: 43650 training 0.516667            validation 0.559\n",
      "\n",
      "step: 43700 training 0.55            validation 0.5574\n",
      "\n",
      "step: 43750 training 0.733333            validation 0.558\n",
      "\n",
      "step: 43800 training 0.616667            validation 0.5588\n",
      "\n",
      "step: 43850 training 0.633333            validation 0.559\n",
      "\n",
      "step: 43900 training 0.583333            validation 0.5576\n",
      "\n",
      "step: 43950 training 0.533333            validation 0.5594\n",
      "\n",
      "step: 44000 training 0.633333            validation 0.5606\n",
      "\n",
      "step: 44050 training 0.666667            validation 0.5588\n",
      "\n",
      "step: 44100 training 0.5            validation 0.5586\n",
      "\n",
      "step: 44150 training 0.516667            validation 0.5596\n",
      "\n",
      "step: 44200 training 0.5            validation 0.5578\n",
      "\n",
      "step: 44250 training 0.533333            validation 0.5606\n",
      "\n",
      "step: 44300 training 0.633333            validation 0.5584\n",
      "\n",
      "step: 44350 training 0.516667            validation 0.5554\n",
      "\n",
      "step: 44400 training 0.533333            validation 0.5572\n",
      "\n",
      "step: 44450 training 0.633333            validation 0.5598\n",
      "\n",
      "step: 44500 training 0.583333            validation 0.5586\n",
      "\n",
      "step: 44550 training 0.633333            validation 0.5578\n",
      "\n",
      "step: 44600 training 0.533333            validation 0.558\n",
      "\n",
      "step: 44650 training 0.55            validation 0.5604\n",
      "\n",
      "step: 44700 training 0.6            validation 0.559\n",
      "\n",
      "step: 44750 training 0.6            validation 0.5594\n",
      "\n",
      "step: 44800 training 0.65            validation 0.5564\n",
      "\n",
      "step: 44850 training 0.616667            validation 0.5576\n",
      "\n",
      "step: 44900 training 0.716667            validation 0.5604\n",
      "\n",
      "step: 44950 training 0.566667            validation 0.5604\n",
      "\n",
      "step: 45000 training 0.416667            validation 0.5596\n",
      "\n",
      "step: 45050 training 0.55            validation 0.5602\n",
      "\n",
      "step: 45100 training 0.55            validation 0.5578\n",
      "\n",
      "step: 45150 training 0.616667            validation 0.5586\n",
      "\n",
      "step: 45200 training 0.616667            validation 0.5588\n",
      "\n",
      "step: 45250 training 0.466667            validation 0.5588\n",
      "\n",
      "step: 45300 training 0.666667            validation 0.559\n",
      "\n",
      "step: 45350 training 0.616667            validation 0.5586\n",
      "\n",
      "step: 45400 training 0.583333            validation 0.5574\n",
      "\n",
      "step: 45450 training 0.516667            validation 0.5596\n",
      "\n",
      "step: 45500 training 0.45            validation 0.5598\n",
      "\n",
      "step: 45550 training 0.533333            validation 0.558\n",
      "\n",
      "step: 45600 training 0.433333            validation 0.5584\n",
      "\n",
      "step: 45650 training 0.633333            validation 0.5588\n",
      "\n",
      "step: 45700 training 0.5            validation 0.5584\n",
      "\n",
      "step: 45750 training 0.65            validation 0.5586\n",
      "\n",
      "step: 45800 training 0.583333            validation 0.5618\n",
      "\n",
      "step: 45850 training 0.633333            validation 0.5588\n",
      "\n",
      "step: 45900 training 0.583333            validation 0.5566\n",
      "\n",
      "step: 45950 training 0.6            validation 0.5592\n",
      "\n",
      "step: 46000 training 0.533333            validation 0.5554\n",
      "\n",
      "step: 46050 training 0.566667            validation 0.5598\n",
      "\n",
      "step: 46100 training 0.583333            validation 0.5596\n",
      "\n",
      "step: 46150 training 0.433333            validation 0.5582\n",
      "\n",
      "step: 46200 training 0.566667            validation 0.5598\n",
      "\n",
      "step: 46250 training 0.633333            validation 0.5594\n",
      "\n",
      "step: 46300 training 0.5            validation 0.5596\n",
      "\n",
      "step: 46350 training 0.5            validation 0.5584\n",
      "\n",
      "step: 46400 training 0.516667            validation 0.559\n",
      "\n",
      "step: 46450 training 0.533333            validation 0.5592\n",
      "\n",
      "step: 46500 training 0.5            validation 0.5588\n",
      "\n",
      "step: 46550 training 0.6            validation 0.5594\n",
      "\n",
      "step: 46600 training 0.616667            validation 0.5596\n",
      "\n",
      "step: 46650 training 0.633333            validation 0.5576\n",
      "\n",
      "step: 46700 training 0.566667            validation 0.5606\n",
      "\n",
      "step: 46750 training 0.633333            validation 0.559\n",
      "\n",
      "step: 46800 training 0.6            validation 0.5564\n",
      "\n",
      "step: 46850 training 0.616667            validation 0.5586\n",
      "\n",
      "step: 46900 training 0.55            validation 0.559\n",
      "\n",
      "step: 46950 training 0.616667            validation 0.56\n",
      "\n",
      "step: 47000 training 0.55            validation 0.5586\n",
      "\n",
      "step: 47050 training 0.55            validation 0.5606\n",
      "\n",
      "step: 47100 training 0.65            validation 0.559\n",
      "\n",
      "step: 47150 training 0.55            validation 0.5592\n",
      "\n",
      "step: 47200 training 0.65            validation 0.5564\n",
      "\n",
      "step: 47250 training 0.55            validation 0.556\n",
      "\n",
      "step: 47300 training 0.6            validation 0.5586\n",
      "\n",
      "step: 47350 training 0.433333            validation 0.5576\n",
      "\n",
      "step: 47400 training 0.683333            validation 0.5588\n",
      "\n",
      "step: 47450 training 0.6            validation 0.558\n",
      "\n",
      "step: 47500 training 0.566667            validation 0.5582\n",
      "\n",
      "step: 47550 training 0.633333            validation 0.5556\n",
      "\n",
      "step: 47600 training 0.616667            validation 0.558\n",
      "\n",
      "step: 47650 training 0.55            validation 0.5582\n",
      "\n",
      "step: 47700 training 0.583333            validation 0.5584\n",
      "\n",
      "step: 47750 training 0.516667            validation 0.5596\n",
      "\n",
      "step: 47800 training 0.583333            validation 0.5616\n",
      "\n",
      "step: 47850 training 0.616667            validation 0.5578\n",
      "\n",
      "step: 47900 training 0.6            validation 0.5566\n",
      "\n",
      "step: 47950 training 0.483333            validation 0.56\n",
      "\n",
      "step: 48000 training 0.65            validation 0.5576\n",
      "\n",
      "step: 48050 training 0.566667            validation 0.5596\n",
      "\n",
      "step: 48100 training 0.566667            validation 0.5586\n",
      "\n",
      "step: 48150 training 0.5            validation 0.56\n",
      "\n",
      "step: 48200 training 0.55            validation 0.5592\n",
      "\n",
      "step: 48250 training 0.566667            validation 0.5572\n",
      "\n",
      "step: 48300 training 0.516667            validation 0.5584\n",
      "\n",
      "step: 48350 training 0.633333            validation 0.5584\n",
      "\n",
      "step: 48400 training 0.55            validation 0.5596\n",
      "\n",
      "step: 48450 training 0.5            validation 0.5598\n",
      "\n",
      "step: 48500 training 0.6            validation 0.5576\n",
      "\n",
      "step: 48550 training 0.7            validation 0.5582\n",
      "\n",
      "step: 48600 training 0.533333            validation 0.5568\n",
      "\n",
      "step: 48650 training 0.616667            validation 0.5586\n",
      "\n",
      "step: 48700 training 0.533333            validation 0.5574\n",
      "\n",
      "step: 48750 training 0.583333            validation 0.5598\n",
      "\n",
      "step: 48800 training 0.566667            validation 0.5586\n",
      "\n",
      "step: 48850 training 0.566667            validation 0.5584\n",
      "\n",
      "step: 48900 training 0.6            validation 0.5602\n",
      "\n",
      "step: 48950 training 0.533333            validation 0.5598\n",
      "\n",
      "step: 49000 training 0.583333            validation 0.557\n",
      "\n",
      "step: 49050 training 0.566667            validation 0.5596\n",
      "\n",
      "step: 49100 training 0.533333            validation 0.56\n",
      "\n",
      "step: 49150 training 0.516667            validation 0.5592\n",
      "\n",
      "step: 49200 training 0.666667            validation 0.56\n",
      "\n",
      "step: 49250 training 0.6            validation 0.558\n",
      "\n",
      "step: 49300 training 0.583333            validation 0.5588\n",
      "\n",
      "step: 49350 training 0.5            validation 0.5596\n",
      "\n",
      "step: 49400 training 0.6            validation 0.56\n",
      "\n",
      "step: 49450 training 0.55            validation 0.5604\n",
      "\n",
      "step: 49500 training 0.516667            validation 0.5578\n",
      "\n",
      "step: 49550 training 0.5            validation 0.5594\n",
      "\n",
      "step: 49600 training 0.483333            validation 0.5606\n",
      "\n",
      "step: 49650 training 0.45            validation 0.5606\n",
      "\n",
      "step: 49700 training 0.616667            validation 0.5596\n",
      "\n",
      "step: 49750 training 0.566667            validation 0.562\n",
      "\n",
      "step: 49800 training 0.633333            validation 0.558\n",
      "\n",
      "step: 49850 training 0.583333            validation 0.558\n",
      "\n",
      "step: 49900 training 0.6            validation 0.5624\n",
      "\n",
      "step: 49950 training 0.533333            validation 0.5616\n",
      "\n",
      "step: 50000 training 0.633333            validation 0.5596\n",
      "\n",
      "step: 50050 training 0.616667            validation 0.5584\n",
      "\n",
      "step: 50100 training 0.666667            validation 0.5596\n",
      "\n",
      "step: 50150 training 0.616667            validation 0.56\n",
      "\n",
      "step: 50200 training 0.65            validation 0.5616\n",
      "\n",
      "step: 50250 training 0.55            validation 0.5636\n",
      "\n",
      "step: 50300 training 0.4            validation 0.5586\n",
      "\n",
      "step: 50350 training 0.566667            validation 0.5594\n",
      "\n",
      "step: 50400 training 0.516667            validation 0.5608\n",
      "\n",
      "step: 50450 training 0.55            validation 0.5626\n",
      "\n",
      "step: 50500 training 0.65            validation 0.5622\n",
      "\n",
      "step: 50550 training 0.583333            validation 0.5562\n",
      "\n",
      "step: 50600 training 0.483333            validation 0.56\n",
      "\n",
      "step: 50650 training 0.533333            validation 0.5616\n",
      "\n",
      "step: 50700 training 0.483333            validation 0.559\n",
      "\n",
      "step: 50750 training 0.733333            validation 0.5618\n",
      "\n",
      "step: 50800 training 0.65            validation 0.5582\n",
      "\n",
      "step: 50850 training 0.55            validation 0.56\n",
      "\n",
      "step: 50900 training 0.6            validation 0.5598\n",
      "\n",
      "step: 50950 training 0.516667            validation 0.5624\n",
      "\n",
      "step: 51000 training 0.566667            validation 0.5598\n",
      "\n",
      "step: 51050 training 0.516667            validation 0.5616\n",
      "\n",
      "step: 51100 training 0.583333            validation 0.559\n",
      "\n",
      "step: 51150 training 0.533333            validation 0.5598\n",
      "\n",
      "step: 51200 training 0.6            validation 0.56\n",
      "\n",
      "step: 51250 training 0.616667            validation 0.559\n",
      "\n",
      "step: 51300 training 0.583333            validation 0.56\n",
      "\n",
      "step: 51350 training 0.666667            validation 0.5582\n",
      "\n",
      "step: 51400 training 0.6            validation 0.5582\n",
      "\n",
      "step: 51450 training 0.5            validation 0.5576\n",
      "\n",
      "step: 51500 training 0.583333            validation 0.5584\n",
      "\n",
      "step: 51550 training 0.616667            validation 0.5578\n",
      "\n",
      "step: 51600 training 0.583333            validation 0.5566\n",
      "\n",
      "step: 51650 training 0.55            validation 0.561\n",
      "\n",
      "step: 51700 training 0.5            validation 0.5582\n",
      "\n",
      "step: 51750 training 0.6            validation 0.5608\n",
      "\n",
      "step: 51800 training 0.583333            validation 0.5604\n",
      "\n",
      "step: 51850 training 0.516667            validation 0.56\n",
      "\n",
      "step: 51900 training 0.466667            validation 0.5604\n",
      "\n",
      "step: 51950 training 0.566667            validation 0.5606\n",
      "\n",
      "step: 52000 training 0.516667            validation 0.5574\n",
      "\n",
      "step: 52050 training 0.483333            validation 0.5606\n",
      "\n",
      "step: 52100 training 0.633333            validation 0.5594\n",
      "\n",
      "step: 52150 training 0.583333            validation 0.559\n",
      "\n",
      "step: 52200 training 0.533333            validation 0.5594\n",
      "\n",
      "step: 52250 training 0.633333            validation 0.5576\n",
      "\n",
      "step: 52300 training 0.633333            validation 0.5616\n",
      "\n",
      "step: 52350 training 0.583333            validation 0.5608\n",
      "\n",
      "step: 52400 training 0.566667            validation 0.5594\n",
      "\n",
      "step: 52450 training 0.6            validation 0.5592\n",
      "\n",
      "step: 52500 training 0.516667            validation 0.5588\n",
      "\n",
      "step: 52550 training 0.566667            validation 0.5614\n",
      "\n",
      "step: 52600 training 0.516667            validation 0.5576\n",
      "\n",
      "step: 52650 training 0.583333            validation 0.56\n",
      "\n",
      "step: 52700 training 0.483333            validation 0.5588\n",
      "\n",
      "step: 52750 training 0.5            validation 0.561\n",
      "\n",
      "step: 52800 training 0.6            validation 0.5608\n",
      "\n",
      "step: 52850 training 0.483333            validation 0.5614\n",
      "\n",
      "step: 52900 training 0.516667            validation 0.5612\n",
      "\n",
      "step: 52950 training 0.533333            validation 0.5598\n",
      "\n",
      "step: 53000 training 0.633333            validation 0.5594\n",
      "\n",
      "step: 53050 training 0.633333            validation 0.5604\n",
      "\n",
      "step: 53100 training 0.566667            validation 0.5616\n",
      "\n",
      "step: 53150 training 0.55            validation 0.5592\n",
      "\n",
      "step: 53200 training 0.466667            validation 0.5592\n",
      "\n",
      "step: 53250 training 0.483333            validation 0.561\n",
      "\n",
      "step: 53300 training 0.466667            validation 0.5592\n",
      "\n",
      "step: 53350 training 0.5            validation 0.559\n",
      "\n",
      "step: 53400 training 0.616667            validation 0.5606\n",
      "\n",
      "step: 53450 training 0.616667            validation 0.5604\n",
      "\n",
      "step: 53500 training 0.65            validation 0.5588\n",
      "\n",
      "step: 53550 training 0.616667            validation 0.557\n",
      "\n",
      "step: 53600 training 0.583333            validation 0.5606\n",
      "\n",
      "step: 53650 training 0.616667            validation 0.561\n",
      "\n",
      "step: 53700 training 0.533333            validation 0.56\n",
      "\n",
      "step: 53750 training 0.616667            validation 0.5602\n",
      "\n",
      "step: 53800 training 0.616667            validation 0.559\n",
      "\n",
      "step: 53850 training 0.666667            validation 0.5584\n",
      "\n",
      "step: 53900 training 0.633333            validation 0.5604\n",
      "\n",
      "step: 53950 training 0.466667            validation 0.5594\n",
      "\n",
      "step: 54000 training 0.533333            validation 0.5602\n",
      "\n",
      "step: 54050 training 0.566667            validation 0.5598\n",
      "\n",
      "step: 54100 training 0.55            validation 0.5602\n",
      "\n",
      "step: 54150 training 0.55            validation 0.5586\n",
      "\n",
      "step: 54200 training 0.583333            validation 0.559\n",
      "\n",
      "step: 54250 training 0.566667            validation 0.5576\n",
      "\n",
      "step: 54300 training 0.55            validation 0.5598\n",
      "\n",
      "step: 54350 training 0.6            validation 0.5558\n",
      "\n",
      "step: 54400 training 0.583333            validation 0.5556\n",
      "\n",
      "step: 54450 training 0.616667            validation 0.5576\n",
      "\n",
      "step: 54500 training 0.616667            validation 0.5594\n",
      "\n",
      "step: 54550 training 0.65            validation 0.5604\n",
      "\n",
      "step: 54600 training 0.616667            validation 0.5598\n",
      "\n",
      "step: 54650 training 0.533333            validation 0.5592\n",
      "\n",
      "step: 54700 training 0.5            validation 0.5596\n",
      "\n",
      "step: 54750 training 0.483333            validation 0.5598\n",
      "\n",
      "step: 54800 training 0.45            validation 0.5618\n",
      "\n",
      "step: 54850 training 0.5            validation 0.5594\n",
      "\n",
      "step: 54900 training 0.533333            validation 0.5576\n",
      "\n",
      "step: 54950 training 0.583333            validation 0.5596\n",
      "\n",
      "step: 55000 training 0.516667            validation 0.5588\n",
      "\n",
      "step: 55050 training 0.683333            validation 0.5582\n",
      "\n",
      "step: 55100 training 0.616667            validation 0.5602\n",
      "\n",
      "step: 55150 training 0.633333            validation 0.56\n",
      "\n",
      "step: 55200 training 0.566667            validation 0.5618\n",
      "\n",
      "step: 55250 training 0.566667            validation 0.5586\n",
      "\n",
      "step: 55300 training 0.666667            validation 0.5582\n",
      "\n",
      "step: 55350 training 0.45            validation 0.5596\n",
      "\n",
      "step: 55400 training 0.466667            validation 0.5564\n",
      "\n",
      "step: 55450 training 0.566667            validation 0.558\n",
      "\n",
      "step: 55500 training 0.616667            validation 0.5582\n",
      "\n",
      "step: 55550 training 0.566667            validation 0.5594\n",
      "\n",
      "step: 55600 training 0.45            validation 0.5604\n",
      "\n",
      "step: 55650 training 0.616667            validation 0.5602\n",
      "\n",
      "step: 55700 training 0.633333            validation 0.5604\n",
      "\n",
      "step: 55750 training 0.533333            validation 0.5582\n",
      "\n",
      "step: 55800 training 0.55            validation 0.56\n",
      "\n",
      "step: 55850 training 0.533333            validation 0.5586\n",
      "\n",
      "step: 55900 training 0.583333            validation 0.5602\n",
      "\n",
      "step: 55950 training 0.583333            validation 0.5572\n",
      "\n",
      "step: 56000 training 0.616667            validation 0.5602\n",
      "\n",
      "step: 56050 training 0.6            validation 0.5584\n",
      "\n",
      "step: 56100 training 0.666667            validation 0.5574\n",
      "\n",
      "step: 56150 training 0.583333            validation 0.5598\n",
      "\n",
      "step: 56200 training 0.583333            validation 0.5614\n",
      "\n",
      "step: 56250 training 0.616667            validation 0.5598\n",
      "\n",
      "step: 56300 training 0.433333            validation 0.558\n",
      "\n",
      "step: 56350 training 0.666667            validation 0.5584\n",
      "\n",
      "step: 56400 training 0.566667            validation 0.5602\n",
      "\n",
      "step: 56450 training 0.5            validation 0.5598\n",
      "\n",
      "step: 56500 training 0.566667            validation 0.5576\n",
      "\n",
      "step: 56550 training 0.633333            validation 0.559\n",
      "\n",
      "step: 56600 training 0.566667            validation 0.5612\n",
      "\n",
      "step: 56650 training 0.566667            validation 0.5586\n",
      "\n",
      "step: 56700 training 0.6            validation 0.5592\n",
      "\n",
      "step: 56750 training 0.55            validation 0.559\n",
      "\n",
      "step: 56800 training 0.6            validation 0.56\n",
      "\n",
      "step: 56850 training 0.566667            validation 0.5572\n",
      "\n",
      "step: 56900 training 0.683333            validation 0.5608\n",
      "\n",
      "step: 56950 training 0.666667            validation 0.5598\n",
      "\n",
      "step: 57000 training 0.583333            validation 0.5594\n",
      "\n",
      "step: 57050 training 0.566667            validation 0.5596\n",
      "\n",
      "step: 57100 training 0.65            validation 0.5602\n",
      "\n",
      "step: 57150 training 0.533333            validation 0.5616\n",
      "\n",
      "step: 57200 training 0.6            validation 0.5596\n",
      "\n",
      "step: 57250 training 0.65            validation 0.5604\n",
      "\n",
      "step: 57300 training 0.55            validation 0.5614\n",
      "\n",
      "step: 57350 training 0.516667            validation 0.5592\n",
      "\n",
      "step: 57400 training 0.583333            validation 0.5606\n",
      "\n",
      "step: 57450 training 0.566667            validation 0.5608\n",
      "\n",
      "step: 57500 training 0.533333            validation 0.5604\n",
      "\n",
      "step: 57550 training 0.533333            validation 0.5586\n",
      "\n",
      "step: 57600 training 0.483333            validation 0.5598\n",
      "\n",
      "step: 57650 training 0.65            validation 0.5592\n",
      "\n",
      "step: 57700 training 0.616667            validation 0.5606\n",
      "\n",
      "step: 57750 training 0.566667            validation 0.5592\n",
      "\n",
      "step: 57800 training 0.616667            validation 0.5602\n",
      "\n",
      "step: 57850 training 0.6            validation 0.5584\n",
      "\n",
      "step: 57900 training 0.566667            validation 0.5606\n",
      "\n",
      "step: 57950 training 0.6            validation 0.5584\n",
      "\n",
      "step: 58000 training 0.683333            validation 0.5604\n",
      "\n",
      "step: 58050 training 0.533333            validation 0.5614\n",
      "\n",
      "step: 58100 training 0.533333            validation 0.5576\n",
      "\n",
      "step: 58150 training 0.55            validation 0.5582\n",
      "\n",
      "step: 58200 training 0.433333            validation 0.5608\n",
      "\n",
      "step: 58250 training 0.5            validation 0.5582\n",
      "\n",
      "step: 58300 training 0.616667            validation 0.5608\n",
      "\n",
      "step: 58350 training 0.516667            validation 0.56\n",
      "\n",
      "step: 58400 training 0.55            validation 0.5584\n",
      "\n",
      "step: 58450 training 0.583333            validation 0.5602\n",
      "\n",
      "step: 58500 training 0.55            validation 0.561\n",
      "\n",
      "step: 58550 training 0.533333            validation 0.5576\n",
      "\n",
      "step: 58600 training 0.55            validation 0.5614\n",
      "\n",
      "step: 58650 training 0.6            validation 0.5614\n",
      "\n",
      "step: 58700 training 0.583333            validation 0.561\n",
      "\n",
      "step: 58750 training 0.55            validation 0.5614\n",
      "\n",
      "step: 58800 training 0.566667            validation 0.5598\n",
      "\n",
      "step: 58850 training 0.683333            validation 0.561\n",
      "\n",
      "step: 58900 training 0.6            validation 0.5606\n",
      "\n",
      "step: 58950 training 0.566667            validation 0.5628\n",
      "\n",
      "step: 59000 training 0.533333            validation 0.5596\n",
      "\n",
      "step: 59050 training 0.65            validation 0.5612\n",
      "\n",
      "step: 59100 training 0.6            validation 0.5612\n",
      "\n",
      "step: 59150 training 0.566667            validation 0.5602\n",
      "\n",
      "step: 59200 training 0.583333            validation 0.5588\n",
      "\n",
      "step: 59250 training 0.533333            validation 0.5588\n",
      "\n",
      "step: 59300 training 0.6            validation 0.559\n",
      "\n",
      "step: 59350 training 0.533333            validation 0.5604\n",
      "\n",
      "step: 59400 training 0.533333            validation 0.5598\n",
      "\n",
      "step: 59450 training 0.583333            validation 0.5588\n",
      "\n",
      "step: 59500 training 0.55            validation 0.5584\n",
      "\n",
      "step: 59550 training 0.566667            validation 0.5586\n",
      "\n",
      "step: 59600 training 0.533333            validation 0.5574\n",
      "\n",
      "step: 59650 training 0.466667            validation 0.5598\n",
      "\n",
      "step: 59700 training 0.466667            validation 0.5598\n",
      "\n",
      "step: 59750 training 0.616667            validation 0.5602\n",
      "\n",
      "step: 59800 training 0.633333            validation 0.5586\n",
      "\n",
      "step: 59850 training 0.55            validation 0.5602\n",
      "\n",
      "step: 59900 training 0.6            validation 0.5614\n",
      "\n",
      "step: 59950 training 0.583333            validation 0.5602\n",
      "\n",
      "step: 60000 training 0.566667            validation 0.559\n",
      "\n",
      "step: 60050 training 0.516667            validation 0.56\n",
      "\n",
      "step: 60100 training 0.516667            validation 0.557\n",
      "\n",
      "step: 60150 training 0.583333            validation 0.5594\n",
      "\n",
      "step: 60200 training 0.516667            validation 0.5584\n",
      "\n",
      "step: 60250 training 0.616667            validation 0.5596\n",
      "\n",
      "step: 60300 training 0.65            validation 0.5592\n",
      "\n",
      "step: 60350 training 0.666667            validation 0.5612\n",
      "\n",
      "step: 60400 training 0.566667            validation 0.56\n",
      "\n",
      "step: 60450 training 0.55            validation 0.5578\n",
      "\n",
      "step: 60500 training 0.566667            validation 0.5622\n",
      "\n",
      "step: 60550 training 0.516667            validation 0.5594\n",
      "\n",
      "step: 60600 training 0.566667            validation 0.56\n",
      "\n",
      "step: 60650 training 0.583333            validation 0.5574\n",
      "\n",
      "step: 60700 training 0.533333            validation 0.56\n",
      "\n",
      "step: 60750 training 0.633333            validation 0.5584\n",
      "\n",
      "step: 60800 training 0.666667            validation 0.5602\n",
      "\n",
      "step: 60850 training 0.566667            validation 0.5616\n",
      "\n",
      "step: 60900 training 0.55            validation 0.5592\n",
      "\n",
      "step: 60950 training 0.533333            validation 0.5614\n",
      "\n",
      "step: 61000 training 0.6            validation 0.5576\n",
      "\n",
      "step: 61050 training 0.6            validation 0.5612\n",
      "\n",
      "step: 61100 training 0.583333            validation 0.562\n",
      "\n",
      "step: 61150 training 0.716667            validation 0.561\n",
      "\n",
      "step: 61200 training 0.516667            validation 0.561\n",
      "\n",
      "step: 61250 training 0.7            validation 0.5578\n",
      "\n",
      "step: 61300 training 0.666667            validation 0.5592\n",
      "\n",
      "step: 61350 training 0.533333            validation 0.558\n",
      "\n",
      "step: 61400 training 0.55            validation 0.561\n",
      "\n",
      "step: 61450 training 0.666667            validation 0.5602\n",
      "\n",
      "step: 61500 training 0.6            validation 0.561\n",
      "\n",
      "step: 61550 training 0.566667            validation 0.5608\n",
      "\n",
      "step: 61600 training 0.6            validation 0.5608\n",
      "\n",
      "step: 61650 training 0.483333            validation 0.5614\n",
      "\n",
      "step: 61700 training 0.483333            validation 0.5584\n",
      "\n",
      "step: 61750 training 0.616667            validation 0.5594\n",
      "\n",
      "step: 61800 training 0.483333            validation 0.5606\n",
      "\n",
      "step: 61850 training 0.616667            validation 0.5618\n",
      "\n",
      "step: 61900 training 0.583333            validation 0.5606\n",
      "\n",
      "step: 61950 training 0.533333            validation 0.5586\n",
      "\n",
      "step: 62000 training 0.5            validation 0.5594\n",
      "\n",
      "step: 62050 training 0.633333            validation 0.5604\n",
      "\n",
      "step: 62100 training 0.566667            validation 0.5572\n",
      "\n",
      "step: 62150 training 0.466667            validation 0.559\n",
      "\n",
      "step: 62200 training 0.633333            validation 0.5596\n",
      "\n",
      "step: 62250 training 0.55            validation 0.561\n",
      "\n",
      "step: 62300 training 0.633333            validation 0.5594\n",
      "\n",
      "step: 62350 training 0.5            validation 0.5614\n",
      "\n",
      "step: 62400 training 0.65            validation 0.5588\n",
      "\n",
      "step: 62450 training 0.666667            validation 0.5596\n",
      "\n",
      "step: 62500 training 0.65            validation 0.5606\n",
      "\n",
      "step: 62550 training 0.483333            validation 0.5584\n",
      "\n",
      "step: 62600 training 0.583333            validation 0.5598\n",
      "\n",
      "step: 62650 training 0.616667            validation 0.5608\n",
      "\n",
      "step: 62700 training 0.566667            validation 0.5588\n",
      "\n",
      "step: 62750 training 0.633333            validation 0.5606\n",
      "\n",
      "step: 62800 training 0.516667            validation 0.5626\n",
      "\n",
      "step: 62850 training 0.483333            validation 0.559\n",
      "\n",
      "step: 62900 training 0.483333            validation 0.56\n",
      "\n",
      "step: 62950 training 0.7            validation 0.5636\n",
      "\n",
      "step: 63000 training 0.616667            validation 0.5588\n",
      "\n",
      "step: 63050 training 0.566667            validation 0.561\n",
      "\n",
      "step: 63100 training 0.55            validation 0.5596\n",
      "\n",
      "step: 63150 training 0.6            validation 0.5606\n",
      "\n",
      "step: 63200 training 0.516667            validation 0.5608\n",
      "\n",
      "step: 63250 training 0.616667            validation 0.5616\n",
      "\n",
      "step: 63300 training 0.6            validation 0.5626\n",
      "\n",
      "step: 63350 training 0.65            validation 0.5628\n",
      "\n",
      "step: 63400 training 0.616667            validation 0.5624\n",
      "\n",
      "step: 63450 training 0.683333            validation 0.5616\n",
      "\n",
      "step: 63500 training 0.566667            validation 0.5622\n",
      "\n",
      "step: 63550 training 0.666667            validation 0.5602\n",
      "\n",
      "step: 63600 training 0.666667            validation 0.56\n",
      "\n",
      "step: 63650 training 0.65            validation 0.5602\n",
      "\n",
      "step: 63700 training 0.566667            validation 0.5608\n",
      "\n",
      "step: 63750 training 0.483333            validation 0.5594\n",
      "\n",
      "step: 63800 training 0.616667            validation 0.5612\n",
      "\n",
      "step: 63850 training 0.566667            validation 0.5608\n",
      "\n",
      "step: 63900 training 0.533333            validation 0.562\n",
      "\n",
      "step: 63950 training 0.65            validation 0.5592\n",
      "\n",
      "step: 64000 training 0.533333            validation 0.5626\n",
      "\n",
      "step: 64050 training 0.616667            validation 0.5594\n",
      "\n",
      "step: 64100 training 0.533333            validation 0.56\n",
      "\n",
      "step: 64150 training 0.55            validation 0.5604\n",
      "\n",
      "step: 64200 training 0.6            validation 0.561\n",
      "\n",
      "step: 64250 training 0.65            validation 0.5594\n",
      "\n",
      "step: 64300 training 0.583333            validation 0.559\n",
      "\n",
      "step: 64350 training 0.666667            validation 0.5602\n",
      "\n",
      "step: 64400 training 0.633333            validation 0.56\n",
      "\n",
      "step: 64450 training 0.666667            validation 0.5608\n",
      "\n",
      "step: 64500 training 0.55            validation 0.5618\n",
      "\n",
      "step: 64550 training 0.55            validation 0.5602\n",
      "\n",
      "step: 64600 training 0.6            validation 0.5614\n",
      "\n",
      "step: 64650 training 0.533333            validation 0.5566\n",
      "\n",
      "step: 64700 training 0.483333            validation 0.5588\n",
      "\n",
      "step: 64750 training 0.55            validation 0.5598\n",
      "\n",
      "step: 64800 training 0.55            validation 0.5584\n",
      "\n",
      "step: 64850 training 0.65            validation 0.5594\n",
      "\n",
      "step: 64900 training 0.566667            validation 0.5614\n",
      "\n",
      "step: 64950 training 0.583333            validation 0.5606\n",
      "\n",
      "step: 65000 training 0.516667            validation 0.5608\n",
      "\n",
      "step: 65050 training 0.583333            validation 0.562\n",
      "\n",
      "step: 65100 training 0.616667            validation 0.5608\n",
      "\n",
      "step: 65150 training 0.6            validation 0.5586\n",
      "\n",
      "step: 65200 training 0.6            validation 0.5604\n",
      "\n",
      "step: 65250 training 0.516667            validation 0.5596\n",
      "\n",
      "step: 65300 training 0.533333            validation 0.5604\n",
      "\n",
      "step: 65350 training 0.616667            validation 0.5618\n",
      "\n",
      "step: 65400 training 0.633333            validation 0.5606\n",
      "\n",
      "step: 65450 training 0.566667            validation 0.5614\n",
      "\n",
      "step: 65500 training 0.683333            validation 0.5606\n",
      "\n",
      "step: 65550 training 0.633333            validation 0.56\n",
      "\n",
      "step: 65600 training 0.583333            validation 0.5616\n",
      "\n",
      "step: 65650 training 0.6            validation 0.562\n",
      "\n",
      "step: 65700 training 0.683333            validation 0.5606\n",
      "\n",
      "step: 65750 training 0.65            validation 0.5594\n",
      "\n",
      "step: 65800 training 0.683333            validation 0.5596\n",
      "\n",
      "step: 65850 training 0.45            validation 0.562\n",
      "\n",
      "step: 65900 training 0.55            validation 0.561\n",
      "\n",
      "step: 65950 training 0.566667            validation 0.5592\n",
      "\n",
      "step: 66000 training 0.65            validation 0.5606\n",
      "\n",
      "step: 66050 training 0.666667            validation 0.56\n",
      "\n",
      "step: 66100 training 0.566667            validation 0.56\n",
      "\n",
      "step: 66150 training 0.6            validation 0.56\n",
      "\n",
      "step: 66200 training 0.516667            validation 0.5606\n",
      "\n",
      "step: 66250 training 0.616667            validation 0.5596\n",
      "\n",
      "step: 66300 training 0.616667            validation 0.5608\n",
      "\n",
      "step: 66350 training 0.533333            validation 0.5618\n",
      "\n",
      "step: 66400 training 0.5            validation 0.56\n",
      "\n",
      "step: 66450 training 0.6            validation 0.5608\n",
      "\n",
      "step: 66500 training 0.633333            validation 0.5608\n",
      "\n",
      "step: 66550 training 0.666667            validation 0.5582\n",
      "\n",
      "step: 66600 training 0.55            validation 0.5586\n",
      "\n",
      "step: 66650 training 0.6            validation 0.5606\n",
      "\n",
      "step: 66700 training 0.633333            validation 0.5586\n",
      "\n",
      "step: 66750 training 0.616667            validation 0.5608\n",
      "\n",
      "step: 66800 training 0.533333            validation 0.5608\n",
      "\n",
      "step: 66850 training 0.633333            validation 0.5604\n",
      "\n",
      "step: 66900 training 0.533333            validation 0.5608\n",
      "\n",
      "step: 66950 training 0.533333            validation 0.561\n",
      "\n",
      "step: 67000 training 0.5            validation 0.5582\n",
      "\n",
      "step: 67050 training 0.483333            validation 0.5592\n",
      "\n",
      "step: 67100 training 0.566667            validation 0.5596\n",
      "\n",
      "step: 67150 training 0.516667            validation 0.559\n",
      "\n",
      "step: 67200 training 0.55            validation 0.5604\n",
      "\n",
      "step: 67250 training 0.6            validation 0.5604\n",
      "\n",
      "step: 67300 training 0.666667            validation 0.5574\n",
      "\n",
      "step: 67350 training 0.616667            validation 0.5586\n",
      "\n",
      "step: 67400 training 0.6            validation 0.5606\n",
      "\n",
      "step: 67450 training 0.6            validation 0.5606\n",
      "\n",
      "step: 67500 training 0.6            validation 0.5582\n",
      "\n",
      "step: 67550 training 0.583333            validation 0.562\n",
      "\n",
      "step: 67600 training 0.616667            validation 0.5626\n",
      "\n",
      "step: 67650 training 0.5            validation 0.5608\n",
      "\n",
      "step: 67700 training 0.516667            validation 0.5618\n",
      "\n",
      "step: 67750 training 0.616667            validation 0.5618\n",
      "\n",
      "step: 67800 training 0.466667            validation 0.5606\n",
      "\n",
      "step: 67850 training 0.566667            validation 0.5604\n",
      "\n",
      "step: 67900 training 0.516667            validation 0.5604\n",
      "\n",
      "step: 67950 training 0.55            validation 0.5604\n",
      "\n",
      "step: 68000 training 0.516667            validation 0.558\n",
      "\n",
      "step: 68050 training 0.516667            validation 0.5584\n",
      "\n",
      "step: 68100 training 0.666667            validation 0.5608\n",
      "\n",
      "step: 68150 training 0.566667            validation 0.5594\n",
      "\n",
      "step: 68200 training 0.45            validation 0.5604\n",
      "\n",
      "step: 68250 training 0.683333            validation 0.5606\n",
      "\n",
      "step: 68300 training 0.6            validation 0.5612\n",
      "\n",
      "step: 68350 training 0.716667            validation 0.5612\n",
      "\n",
      "step: 68400 training 0.583333            validation 0.5586\n",
      "\n",
      "step: 68450 training 0.666667            validation 0.5584\n",
      "\n",
      "step: 68500 training 0.566667            validation 0.5618\n",
      "\n",
      "step: 68550 training 0.6            validation 0.5612\n",
      "\n",
      "step: 68600 training 0.633333            validation 0.5598\n",
      "\n",
      "step: 68650 training 0.483333            validation 0.5602\n",
      "\n",
      "step: 68700 training 0.5            validation 0.5584\n",
      "\n",
      "step: 68750 training 0.65            validation 0.5608\n",
      "\n",
      "step: 68800 training 0.533333            validation 0.5624\n",
      "\n",
      "step: 68850 training 0.616667            validation 0.5606\n",
      "\n",
      "step: 68900 training 0.566667            validation 0.5602\n",
      "\n",
      "step: 68950 training 0.516667            validation 0.558\n",
      "\n",
      "step: 69000 training 0.55            validation 0.5592\n",
      "\n",
      "step: 69050 training 0.566667            validation 0.5584\n",
      "\n",
      "step: 69100 training 0.65            validation 0.5604\n",
      "\n",
      "step: 69150 training 0.6            validation 0.5586\n",
      "\n",
      "step: 69200 training 0.566667            validation 0.5572\n",
      "\n",
      "step: 69250 training 0.633333            validation 0.5606\n",
      "\n",
      "step: 69300 training 0.566667            validation 0.5596\n",
      "\n",
      "step: 69350 training 0.433333            validation 0.5598\n",
      "\n",
      "step: 69400 training 0.716667            validation 0.5606\n",
      "\n",
      "step: 69450 training 0.5            validation 0.5592\n",
      "\n",
      "step: 69500 training 0.666667            validation 0.5586\n",
      "\n",
      "step: 69550 training 0.5            validation 0.557\n",
      "\n",
      "step: 69600 training 0.6            validation 0.5596\n",
      "\n",
      "step: 69650 training 0.6            validation 0.5616\n",
      "\n",
      "step: 69700 training 0.616667            validation 0.5588\n",
      "\n",
      "step: 69750 training 0.666667            validation 0.5604\n",
      "\n",
      "step: 69800 training 0.666667            validation 0.5604\n",
      "\n",
      "step: 69850 training 0.516667            validation 0.559\n",
      "\n",
      "step: 69900 training 0.55            validation 0.56\n",
      "\n",
      "step: 69950 training 0.533333            validation 0.5598\n",
      "\n",
      "step: 70000 training 0.566667            validation 0.5586\n",
      "\n",
      "step: 70050 training 0.483333            validation 0.56\n",
      "\n",
      "step: 70100 training 0.483333            validation 0.5606\n",
      "\n",
      "step: 70150 training 0.583333            validation 0.5608\n",
      "\n",
      "step: 70200 training 0.55            validation 0.5606\n",
      "\n",
      "step: 70250 training 0.566667            validation 0.5606\n",
      "\n",
      "step: 70300 training 0.5            validation 0.5594\n",
      "\n",
      "step: 70350 training 0.616667            validation 0.561\n",
      "\n",
      "step: 70400 training 0.466667            validation 0.558\n",
      "\n",
      "step: 70450 training 0.583333            validation 0.5594\n",
      "\n",
      "step: 70500 training 0.433333            validation 0.5616\n",
      "\n",
      "step: 70550 training 0.65            validation 0.559\n",
      "\n",
      "step: 70600 training 0.633333            validation 0.5604\n",
      "\n",
      "step: 70650 training 0.583333            validation 0.5588\n",
      "\n",
      "step: 70700 training 0.583333            validation 0.5602\n",
      "\n",
      "step: 70750 training 0.566667            validation 0.562\n",
      "\n",
      "step: 70800 training 0.483333            validation 0.5604\n",
      "\n",
      "step: 70850 training 0.683333            validation 0.5606\n",
      "\n",
      "step: 70900 training 0.466667            validation 0.5598\n",
      "\n",
      "step: 70950 training 0.65            validation 0.5614\n",
      "\n",
      "step: 71000 training 0.583333            validation 0.5594\n",
      "\n",
      "step: 71050 training 0.616667            validation 0.56\n",
      "\n",
      "step: 71100 training 0.55            validation 0.5608\n",
      "\n",
      "step: 71150 training 0.6            validation 0.5612\n",
      "\n",
      "step: 71200 training 0.566667            validation 0.5612\n",
      "\n",
      "step: 71250 training 0.583333            validation 0.559\n",
      "\n",
      "step: 71300 training 0.583333            validation 0.5612\n",
      "\n",
      "step: 71350 training 0.55            validation 0.5592\n",
      "\n",
      "step: 71400 training 0.616667            validation 0.5604\n",
      "\n",
      "step: 71450 training 0.533333            validation 0.56\n",
      "\n",
      "step: 71500 training 0.5            validation 0.5608\n",
      "\n",
      "step: 71550 training 0.516667            validation 0.5628\n",
      "\n",
      "step: 71600 training 0.45            validation 0.5604\n",
      "\n",
      "step: 71650 training 0.616667            validation 0.563\n",
      "\n",
      "step: 71700 training 0.633333            validation 0.5642\n",
      "\n",
      "step: 71750 training 0.65            validation 0.5614\n",
      "\n",
      "step: 71800 training 0.55            validation 0.563\n",
      "\n",
      "step: 71850 training 0.7            validation 0.5622\n",
      "\n",
      "step: 71900 training 0.65            validation 0.5588\n",
      "\n",
      "step: 71950 training 0.566667            validation 0.562\n",
      "\n",
      "step: 72000 training 0.633333            validation 0.559\n",
      "\n",
      "step: 72050 training 0.5            validation 0.5602\n",
      "\n",
      "step: 72100 training 0.616667            validation 0.56\n",
      "\n",
      "step: 72150 training 0.633333            validation 0.558\n",
      "\n",
      "step: 72200 training 0.583333            validation 0.5612\n",
      "\n",
      "step: 72250 training 0.716667            validation 0.5624\n",
      "\n",
      "step: 72300 training 0.65            validation 0.5584\n",
      "\n",
      "step: 72350 training 0.616667            validation 0.558\n",
      "\n",
      "step: 72400 training 0.65            validation 0.5594\n",
      "\n",
      "step: 72450 training 0.683333            validation 0.5592\n",
      "\n",
      "step: 72500 training 0.516667            validation 0.5602\n",
      "\n",
      "step: 72550 training 0.583333            validation 0.5602\n",
      "\n",
      "step: 72600 training 0.583333            validation 0.5606\n",
      "\n",
      "step: 72650 training 0.533333            validation 0.5606\n",
      "\n",
      "step: 72700 training 0.45            validation 0.5588\n",
      "\n",
      "step: 72750 training 0.516667            validation 0.5612\n",
      "\n",
      "step: 72800 training 0.65            validation 0.56\n",
      "\n",
      "step: 72850 training 0.533333            validation 0.5622\n",
      "\n",
      "step: 72900 training 0.516667            validation 0.5576\n",
      "\n",
      "step: 72950 training 0.5            validation 0.5594\n",
      "\n",
      "step: 73000 training 0.583333            validation 0.5584\n",
      "\n",
      "step: 73050 training 0.55            validation 0.5584\n",
      "\n",
      "step: 73100 training 0.516667            validation 0.5604\n",
      "\n",
      "step: 73150 training 0.616667            validation 0.5598\n",
      "\n",
      "step: 73200 training 0.6            validation 0.5592\n",
      "\n",
      "step: 73250 training 0.533333            validation 0.5602\n",
      "\n",
      "step: 73300 training 0.55            validation 0.5592\n",
      "\n",
      "step: 73350 training 0.6            validation 0.5598\n",
      "\n",
      "step: 73400 training 0.583333            validation 0.5596\n",
      "\n",
      "step: 73450 training 0.45            validation 0.5602\n",
      "\n",
      "step: 73500 training 0.516667            validation 0.56\n",
      "\n",
      "step: 73550 training 0.633333            validation 0.5596\n",
      "\n",
      "step: 73600 training 0.583333            validation 0.5582\n",
      "\n",
      "step: 73650 training 0.566667            validation 0.5578\n",
      "\n",
      "step: 73700 training 0.633333            validation 0.559\n",
      "\n",
      "step: 73750 training 0.566667            validation 0.5594\n",
      "\n",
      "step: 73800 training 0.6            validation 0.5586\n",
      "\n",
      "step: 73850 training 0.533333            validation 0.5588\n",
      "\n",
      "step: 73900 training 0.583333            validation 0.5614\n",
      "\n",
      "step: 73950 training 0.583333            validation 0.5594\n",
      "\n",
      "step: 74000 training 0.616667            validation 0.5608\n",
      "\n",
      "step: 74050 training 0.616667            validation 0.56\n",
      "\n",
      "step: 74100 training 0.5            validation 0.561\n",
      "\n",
      "step: 74150 training 0.566667            validation 0.5594\n",
      "\n",
      "step: 74200 training 0.633333            validation 0.559\n",
      "\n",
      "step: 74250 training 0.633333            validation 0.5578\n",
      "\n",
      "step: 74300 training 0.566667            validation 0.5594\n",
      "\n",
      "step: 74350 training 0.616667            validation 0.5594\n",
      "\n",
      "step: 74400 training 0.533333            validation 0.561\n",
      "\n",
      "step: 74450 training 0.516667            validation 0.5604\n",
      "\n",
      "step: 74500 training 0.633333            validation 0.5596\n",
      "\n",
      "step: 74550 training 0.6            validation 0.56\n",
      "\n",
      "step: 74600 training 0.583333            validation 0.5626\n",
      "\n",
      "step: 74650 training 0.566667            validation 0.5594\n",
      "\n",
      "step: 74700 training 0.65            validation 0.5604\n",
      "\n",
      "step: 74750 training 0.566667            validation 0.5596\n",
      "\n",
      "step: 74800 training 0.616667            validation 0.5604\n",
      "\n",
      "step: 74850 training 0.566667            validation 0.5594\n",
      "\n",
      "step: 74900 training 0.583333            validation 0.5606\n",
      "\n",
      "step: 74950 training 0.483333            validation 0.5602\n",
      "\n",
      "step: 75000 training 0.466667            validation 0.5596\n",
      "\n",
      "step: 75050 training 0.666667            validation 0.558\n",
      "\n",
      "step: 75100 training 0.616667            validation 0.5606\n",
      "\n",
      "step: 75150 training 0.65            validation 0.5608\n",
      "\n",
      "step: 75200 training 0.6            validation 0.5602\n",
      "\n",
      "step: 75250 training 0.566667            validation 0.5598\n",
      "\n",
      "step: 75300 training 0.55            validation 0.5572\n",
      "\n",
      "step: 75350 training 0.583333            validation 0.5596\n",
      "\n",
      "step: 75400 training 0.616667            validation 0.5586\n",
      "\n",
      "step: 75450 training 0.666667            validation 0.5598\n",
      "\n",
      "step: 75500 training 0.533333            validation 0.56\n",
      "\n",
      "step: 75550 training 0.533333            validation 0.5594\n",
      "\n",
      "step: 75600 training 0.566667            validation 0.5592\n",
      "\n",
      "step: 75650 training 0.583333            validation 0.5598\n",
      "\n",
      "step: 75700 training 0.6            validation 0.56\n",
      "\n",
      "step: 75750 training 0.6            validation 0.558\n",
      "\n",
      "step: 75800 training 0.65            validation 0.558\n",
      "\n",
      "step: 75850 training 0.65            validation 0.5578\n",
      "\n",
      "step: 75900 training 0.716667            validation 0.5596\n",
      "\n",
      "step: 75950 training 0.55            validation 0.5596\n",
      "\n",
      "step: 76000 training 0.566667            validation 0.56\n",
      "\n",
      "step: 76050 training 0.65            validation 0.5604\n",
      "\n",
      "step: 76100 training 0.45            validation 0.5592\n",
      "\n",
      "step: 76150 training 0.616667            validation 0.5594\n",
      "\n",
      "step: 76200 training 0.516667            validation 0.5572\n",
      "\n",
      "step: 76250 training 0.566667            validation 0.5584\n",
      "\n",
      "step: 76300 training 0.55            validation 0.5592\n",
      "\n",
      "step: 76350 training 0.533333            validation 0.559\n",
      "\n",
      "step: 76400 training 0.583333            validation 0.5614\n",
      "\n",
      "step: 76450 training 0.7            validation 0.5594\n",
      "\n",
      "step: 76500 training 0.583333            validation 0.5606\n",
      "\n",
      "step: 76550 training 0.633333            validation 0.5606\n",
      "\n",
      "step: 76600 training 0.6            validation 0.5604\n",
      "\n",
      "step: 76650 training 0.55            validation 0.5594\n",
      "\n",
      "step: 76700 training 0.516667            validation 0.5588\n",
      "\n",
      "step: 76750 training 0.666667            validation 0.558\n",
      "\n",
      "step: 76800 training 0.65            validation 0.5586\n",
      "\n",
      "step: 76850 training 0.616667            validation 0.5596\n",
      "\n",
      "step: 76900 training 0.5            validation 0.561\n",
      "\n",
      "step: 76950 training 0.6            validation 0.5602\n",
      "\n",
      "step: 77000 training 0.666667            validation 0.5588\n",
      "\n",
      "step: 77050 training 0.616667            validation 0.559\n",
      "\n",
      "step: 77100 training 0.566667            validation 0.5586\n",
      "\n",
      "step: 77150 training 0.583333            validation 0.5604\n",
      "\n",
      "step: 77200 training 0.666667            validation 0.559\n",
      "\n",
      "step: 77250 training 0.516667            validation 0.5608\n",
      "\n",
      "step: 77300 training 0.516667            validation 0.5596\n",
      "\n",
      "step: 77350 training 0.566667            validation 0.5612\n",
      "\n",
      "step: 77400 training 0.583333            validation 0.5602\n",
      "\n",
      "step: 77450 training 0.65            validation 0.5574\n",
      "\n",
      "step: 77500 training 0.533333            validation 0.5612\n",
      "\n",
      "step: 77550 training 0.616667            validation 0.5614\n",
      "\n",
      "step: 77600 training 0.466667            validation 0.5616\n",
      "\n",
      "step: 77650 training 0.566667            validation 0.5584\n",
      "\n",
      "step: 77700 training 0.616667            validation 0.5596\n",
      "\n",
      "step: 77750 training 0.6            validation 0.5608\n",
      "\n",
      "step: 77800 training 0.65            validation 0.5602\n",
      "\n",
      "step: 77850 training 0.616667            validation 0.5604\n",
      "\n",
      "step: 77900 training 0.583333            validation 0.5608\n",
      "\n",
      "step: 77950 training 0.683333            validation 0.5616\n",
      "\n",
      "step: 78000 training 0.516667            validation 0.5594\n",
      "\n",
      "step: 78050 training 0.65            validation 0.5604\n",
      "\n",
      "step: 78100 training 0.666667            validation 0.5598\n",
      "\n",
      "step: 78150 training 0.5            validation 0.5604\n",
      "\n",
      "step: 78200 training 0.6            validation 0.5598\n",
      "\n",
      "step: 78250 training 0.616667            validation 0.559\n",
      "\n",
      "step: 78300 training 0.666667            validation 0.5604\n",
      "\n",
      "step: 78350 training 0.65            validation 0.56\n",
      "\n",
      "step: 78400 training 0.616667            validation 0.5574\n",
      "\n",
      "step: 78450 training 0.683333            validation 0.56\n",
      "\n",
      "step: 78500 training 0.633333            validation 0.5574\n",
      "\n",
      "step: 78550 training 0.583333            validation 0.5586\n",
      "\n",
      "step: 78600 training 0.566667            validation 0.5598\n",
      "\n",
      "step: 78650 training 0.633333            validation 0.559\n",
      "\n",
      "step: 78700 training 0.616667            validation 0.5598\n",
      "\n",
      "step: 78750 training 0.666667            validation 0.5604\n",
      "\n",
      "step: 78800 training 0.583333            validation 0.5604\n",
      "\n",
      "step: 78850 training 0.6            validation 0.5582\n",
      "\n",
      "step: 78900 training 0.416667            validation 0.5562\n",
      "\n",
      "step: 78950 training 0.6            validation 0.5596\n",
      "\n",
      "step: 79000 training 0.6            validation 0.5598\n",
      "\n",
      "step: 79050 training 0.616667            validation 0.5592\n",
      "\n",
      "step: 79100 training 0.5            validation 0.56\n",
      "\n",
      "step: 79150 training 0.516667            validation 0.5602\n",
      "\n",
      "step: 79200 training 0.533333            validation 0.5604\n",
      "\n",
      "step: 79250 training 0.633333            validation 0.558\n",
      "\n",
      "step: 79300 training 0.683333            validation 0.56\n",
      "\n",
      "step: 79350 training 0.483333            validation 0.5604\n",
      "\n",
      "step: 79400 training 0.566667            validation 0.5596\n",
      "\n",
      "step: 79450 training 0.5            validation 0.5586\n",
      "\n",
      "step: 79500 training 0.5            validation 0.5572\n",
      "\n",
      "step: 79550 training 0.6            validation 0.5598\n",
      "\n",
      "step: 79600 training 0.533333            validation 0.5616\n",
      "\n",
      "step: 79650 training 0.6            validation 0.5616\n",
      "\n",
      "step: 79700 training 0.6            validation 0.5592\n",
      "\n",
      "step: 79750 training 0.616667            validation 0.5592\n",
      "\n",
      "step: 79800 training 0.55            validation 0.5594\n",
      "\n",
      "step: 79850 training 0.566667            validation 0.559\n",
      "\n",
      "step: 79900 training 0.633333            validation 0.5596\n",
      "\n",
      "step: 79950 training 0.65            validation 0.5598\n",
      "\n",
      "step: 80000 training 0.616667            validation 0.5596\n",
      "\n",
      "step: 80050 training 0.55            validation 0.5586\n",
      "\n",
      "step: 80100 training 0.633333            validation 0.5604\n",
      "\n",
      "step: 80150 training 0.566667            validation 0.56\n",
      "\n",
      "step: 80200 training 0.516667            validation 0.5608\n",
      "\n",
      "step: 80250 training 0.616667            validation 0.5596\n",
      "\n",
      "step: 80300 training 0.45            validation 0.5594\n",
      "\n",
      "step: 80350 training 0.616667            validation 0.5578\n",
      "\n",
      "step: 80400 training 0.533333            validation 0.5592\n",
      "\n",
      "step: 80450 training 0.583333            validation 0.5602\n",
      "\n",
      "step: 80500 training 0.483333            validation 0.5588\n",
      "\n",
      "step: 80550 training 0.5            validation 0.5614\n",
      "\n",
      "step: 80600 training 0.55            validation 0.5606\n",
      "\n",
      "step: 80650 training 0.566667            validation 0.56\n",
      "\n",
      "step: 80700 training 0.65            validation 0.5614\n",
      "\n",
      "step: 80750 training 0.7            validation 0.5606\n",
      "\n",
      "step: 80800 training 0.45            validation 0.5608\n",
      "\n",
      "step: 80850 training 0.633333            validation 0.562\n",
      "\n",
      "step: 80900 training 0.55            validation 0.5612\n",
      "\n",
      "step: 80950 training 0.633333            validation 0.5614\n",
      "\n",
      "step: 81000 training 0.633333            validation 0.5598\n",
      "\n",
      "step: 81050 training 0.5            validation 0.5576\n",
      "\n",
      "step: 81100 training 0.5            validation 0.5602\n",
      "\n",
      "step: 81150 training 0.5            validation 0.562\n",
      "\n",
      "step: 81200 training 0.666667            validation 0.5606\n",
      "\n",
      "step: 81250 training 0.633333            validation 0.5592\n",
      "\n",
      "step: 81300 training 0.633333            validation 0.5608\n",
      "\n",
      "step: 81350 training 0.616667            validation 0.5606\n",
      "\n",
      "step: 81400 training 0.55            validation 0.561\n",
      "\n",
      "step: 81450 training 0.716667            validation 0.5598\n",
      "\n",
      "step: 81500 training 0.6            validation 0.5606\n",
      "\n",
      "step: 81550 training 0.616667            validation 0.5604\n",
      "\n",
      "step: 81600 training 0.666667            validation 0.5596\n",
      "\n",
      "step: 81650 training 0.583333            validation 0.56\n",
      "\n",
      "step: 81700 training 0.516667            validation 0.5606\n",
      "\n",
      "step: 81750 training 0.566667            validation 0.5602\n",
      "\n",
      "step: 81800 training 0.616667            validation 0.5598\n",
      "\n",
      "step: 81850 training 0.5            validation 0.5614\n",
      "\n",
      "step: 81900 training 0.566667            validation 0.5592\n",
      "\n",
      "step: 81950 training 0.566667            validation 0.5586\n",
      "\n",
      "step: 82000 training 0.516667            validation 0.5618\n",
      "\n",
      "step: 82050 training 0.583333            validation 0.5606\n",
      "\n",
      "step: 82100 training 0.65            validation 0.5608\n",
      "\n",
      "step: 82150 training 0.5            validation 0.5596\n",
      "\n",
      "step: 82200 training 0.633333            validation 0.5608\n",
      "\n",
      "step: 82250 training 0.616667            validation 0.5614\n",
      "\n",
      "step: 82300 training 0.533333            validation 0.5586\n",
      "\n",
      "step: 82350 training 0.533333            validation 0.56\n",
      "\n",
      "step: 82400 training 0.6            validation 0.5624\n",
      "\n",
      "step: 82450 training 0.5            validation 0.5586\n",
      "\n",
      "step: 82500 training 0.633333            validation 0.5598\n",
      "\n",
      "step: 82550 training 0.566667            validation 0.5602\n",
      "\n",
      "step: 82600 training 0.633333            validation 0.5614\n",
      "\n",
      "step: 82650 training 0.416667            validation 0.5608\n",
      "\n",
      "step: 82700 training 0.6            validation 0.561\n",
      "\n",
      "step: 82750 training 0.616667            validation 0.5616\n",
      "\n",
      "step: 82800 training 0.716667            validation 0.5602\n",
      "\n",
      "step: 82850 training 0.516667            validation 0.5602\n",
      "\n",
      "step: 82900 training 0.6            validation 0.5624\n",
      "\n",
      "step: 82950 training 0.55            validation 0.5612\n",
      "\n",
      "step: 83000 training 0.6            validation 0.5616\n",
      "\n",
      "step: 83050 training 0.7            validation 0.5592\n",
      "\n",
      "step: 83100 training 0.55            validation 0.5618\n",
      "\n",
      "step: 83150 training 0.583333            validation 0.5592\n",
      "\n",
      "step: 83200 training 0.616667            validation 0.5598\n",
      "\n",
      "step: 83250 training 0.583333            validation 0.5578\n",
      "\n",
      "step: 83300 training 0.466667            validation 0.5594\n",
      "\n",
      "step: 83350 training 0.516667            validation 0.559\n",
      "\n",
      "step: 83400 training 0.666667            validation 0.5588\n",
      "\n",
      "step: 83450 training 0.65            validation 0.5598\n",
      "\n",
      "step: 83500 training 0.5            validation 0.5582\n",
      "\n",
      "step: 83550 training 0.5            validation 0.5602\n",
      "\n",
      "step: 83600 training 0.7            validation 0.5614\n",
      "\n",
      "step: 83650 training 0.583333            validation 0.5598\n",
      "\n",
      "step: 83700 training 0.516667            validation 0.5606\n",
      "\n",
      "step: 83750 training 0.666667            validation 0.561\n",
      "\n",
      "step: 83800 training 0.566667            validation 0.5592\n",
      "\n",
      "step: 83850 training 0.566667            validation 0.5598\n",
      "\n",
      "step: 83900 training 0.6            validation 0.5546\n",
      "\n",
      "step: 83950 training 0.533333            validation 0.56\n",
      "\n",
      "step: 84000 training 0.616667            validation 0.5588\n",
      "\n",
      "step: 84050 training 0.616667            validation 0.5588\n",
      "\n",
      "step: 84100 training 0.55            validation 0.5598\n",
      "\n",
      "step: 84150 training 0.483333            validation 0.5604\n",
      "\n",
      "step: 84200 training 0.55            validation 0.5614\n",
      "\n",
      "step: 84250 training 0.533333            validation 0.5614\n",
      "\n",
      "step: 84300 training 0.6            validation 0.5602\n",
      "\n",
      "step: 84350 training 0.633333            validation 0.56\n",
      "\n",
      "step: 84400 training 0.55            validation 0.5612\n",
      "\n",
      "step: 84450 training 0.466667            validation 0.5586\n",
      "\n",
      "step: 84500 training 0.666667            validation 0.561\n",
      "\n",
      "step: 84550 training 0.633333            validation 0.5624\n",
      "\n",
      "step: 84600 training 0.666667            validation 0.5624\n",
      "\n",
      "step: 84650 training 0.55            validation 0.5618\n",
      "\n",
      "step: 84700 training 0.5            validation 0.5606\n",
      "\n",
      "step: 84750 training 0.566667            validation 0.5612\n",
      "\n",
      "step: 84800 training 0.6            validation 0.5596\n",
      "\n",
      "step: 84850 training 0.55            validation 0.5598\n",
      "\n",
      "step: 84900 training 0.55            validation 0.5596\n",
      "\n",
      "step: 84950 training 0.5            validation 0.5602\n",
      "\n",
      "step: 85000 training 0.533333            validation 0.5584\n",
      "\n",
      "step: 85050 training 0.566667            validation 0.5606\n",
      "\n",
      "step: 85100 training 0.616667            validation 0.559\n",
      "\n",
      "step: 85150 training 0.633333            validation 0.561\n",
      "\n",
      "step: 85200 training 0.65            validation 0.5602\n",
      "\n",
      "step: 85250 training 0.616667            validation 0.5606\n",
      "\n",
      "step: 85300 training 0.45            validation 0.558\n",
      "\n",
      "step: 85350 training 0.4            validation 0.5604\n",
      "\n",
      "step: 85400 training 0.5            validation 0.5594\n",
      "\n",
      "step: 85450 training 0.666667            validation 0.559\n",
      "\n",
      "step: 85500 training 0.55            validation 0.5578\n",
      "\n",
      "step: 85550 training 0.616667            validation 0.5582\n",
      "\n",
      "step: 85600 training 0.6            validation 0.5604\n",
      "\n",
      "step: 85650 training 0.6            validation 0.5612\n",
      "\n",
      "step: 85700 training 0.483333            validation 0.5602\n",
      "\n",
      "step: 85750 training 0.566667            validation 0.5596\n",
      "\n",
      "step: 85800 training 0.45            validation 0.5606\n",
      "\n",
      "step: 85850 training 0.616667            validation 0.5588\n",
      "\n",
      "step: 85900 training 0.633333            validation 0.5592\n",
      "\n",
      "step: 85950 training 0.583333            validation 0.5594\n",
      "\n",
      "step: 86000 training 0.616667            validation 0.5594\n",
      "\n",
      "step: 86050 training 0.583333            validation 0.561\n",
      "\n",
      "step: 86100 training 0.466667            validation 0.5602\n",
      "\n",
      "step: 86150 training 0.533333            validation 0.562\n",
      "\n",
      "step: 86200 training 0.516667            validation 0.5598\n",
      "\n",
      "step: 86250 training 0.583333            validation 0.5586\n",
      "\n",
      "step: 86300 training 0.516667            validation 0.561\n",
      "\n",
      "step: 86350 training 0.6            validation 0.5606\n",
      "\n",
      "step: 86400 training 0.483333            validation 0.5608\n",
      "\n",
      "step: 86450 training 0.566667            validation 0.5598\n",
      "\n",
      "step: 86500 training 0.616667            validation 0.5604\n",
      "\n",
      "step: 86550 training 0.583333            validation 0.5604\n",
      "\n",
      "step: 86600 training 0.533333            validation 0.5596\n",
      "\n",
      "step: 86650 training 0.55            validation 0.5608\n",
      "\n",
      "step: 86700 training 0.6            validation 0.5576\n",
      "\n",
      "step: 86750 training 0.6            validation 0.559\n",
      "\n",
      "step: 86800 training 0.566667            validation 0.5606\n",
      "\n",
      "step: 86850 training 0.483333            validation 0.5586\n",
      "\n",
      "step: 86900 training 0.55            validation 0.5588\n",
      "\n",
      "step: 86950 training 0.65            validation 0.5624\n",
      "\n",
      "step: 87000 training 0.633333            validation 0.563\n",
      "\n",
      "step: 87050 training 0.533333            validation 0.5598\n",
      "\n",
      "step: 87100 training 0.433333            validation 0.5602\n",
      "\n",
      "step: 87150 training 0.566667            validation 0.5602\n",
      "\n",
      "step: 87200 training 0.683333            validation 0.5602\n",
      "\n",
      "step: 87250 training 0.616667            validation 0.563\n",
      "\n",
      "step: 87300 training 0.5            validation 0.5622\n",
      "\n",
      "step: 87350 training 0.55            validation 0.5598\n",
      "\n",
      "step: 87400 training 0.55            validation 0.5602\n",
      "\n",
      "step: 87450 training 0.65            validation 0.5638\n",
      "\n",
      "step: 87500 training 0.6            validation 0.562\n",
      "\n",
      "step: 87550 training 0.65            validation 0.5612\n",
      "\n",
      "step: 87600 training 0.533333            validation 0.561\n",
      "\n",
      "step: 87650 training 0.616667            validation 0.558\n",
      "\n",
      "step: 87700 training 0.616667            validation 0.561\n",
      "\n",
      "step: 87750 training 0.616667            validation 0.561\n",
      "\n",
      "step: 87800 training 0.616667            validation 0.5608\n",
      "\n",
      "step: 87850 training 0.616667            validation 0.5618\n",
      "\n",
      "step: 87900 training 0.55            validation 0.5614\n",
      "\n",
      "step: 87950 training 0.566667            validation 0.5632\n",
      "\n",
      "step: 88000 training 0.566667            validation 0.5622\n",
      "\n",
      "step: 88050 training 0.566667            validation 0.56\n",
      "\n",
      "step: 88100 training 0.533333            validation 0.5608\n",
      "\n",
      "step: 88150 training 0.516667            validation 0.563\n",
      "\n",
      "step: 88200 training 0.45            validation 0.56\n",
      "\n",
      "step: 88250 training 0.583333            validation 0.5608\n",
      "\n",
      "step: 88300 training 0.683333            validation 0.5618\n",
      "\n",
      "step: 88350 training 0.533333            validation 0.5602\n",
      "\n",
      "step: 88400 training 0.6            validation 0.5608\n",
      "\n",
      "step: 88450 training 0.55            validation 0.5596\n",
      "\n",
      "step: 88500 training 0.65            validation 0.5588\n",
      "\n",
      "step: 88550 training 0.583333            validation 0.5608\n",
      "\n",
      "step: 88600 training 0.583333            validation 0.5604\n",
      "\n",
      "step: 88650 training 0.633333            validation 0.5588\n",
      "\n",
      "step: 88700 training 0.6            validation 0.5604\n",
      "\n",
      "step: 88750 training 0.5            validation 0.5602\n",
      "\n",
      "step: 88800 training 0.516667            validation 0.5604\n",
      "\n",
      "step: 88850 training 0.583333            validation 0.5592\n",
      "\n",
      "step: 88900 training 0.55            validation 0.561\n",
      "\n",
      "step: 88950 training 0.466667            validation 0.558\n",
      "\n",
      "step: 89000 training 0.683333            validation 0.5608\n",
      "\n",
      "step: 89050 training 0.6            validation 0.5622\n",
      "\n",
      "step: 89100 training 0.55            validation 0.5618\n",
      "\n",
      "step: 89150 training 0.683333            validation 0.5606\n",
      "\n",
      "step: 89200 training 0.533333            validation 0.5588\n",
      "\n",
      "step: 89250 training 0.566667            validation 0.5596\n",
      "\n",
      "step: 89300 training 0.633333            validation 0.5612\n",
      "\n",
      "step: 89350 training 0.583333            validation 0.56\n",
      "\n",
      "step: 89400 training 0.45            validation 0.5602\n",
      "\n",
      "step: 89450 training 0.566667            validation 0.5594\n",
      "\n",
      "step: 89500 training 0.45            validation 0.561\n",
      "\n",
      "step: 89550 training 0.566667            validation 0.5604\n",
      "\n",
      "step: 89600 training 0.566667            validation 0.5594\n",
      "\n",
      "step: 89650 training 0.583333            validation 0.56\n",
      "\n",
      "step: 89700 training 0.633333            validation 0.5618\n",
      "\n",
      "step: 89750 training 0.516667            validation 0.562\n",
      "\n",
      "step: 89800 training 0.483333            validation 0.5606\n",
      "\n",
      "step: 89850 training 0.633333            validation 0.5588\n",
      "\n",
      "step: 89900 training 0.483333            validation 0.5578\n",
      "\n",
      "step: 89950 training 0.5            validation 0.5588\n",
      "\n",
      "step: 90000 training 0.433333            validation 0.557\n",
      "\n",
      "step: 90050 training 0.633333            validation 0.5586\n",
      "\n",
      "step: 90100 training 0.583333            validation 0.559\n",
      "\n",
      "step: 90150 training 0.633333            validation 0.559\n",
      "\n",
      "step: 90200 training 0.533333            validation 0.5606\n",
      "\n",
      "step: 90250 training 0.566667            validation 0.5616\n",
      "\n",
      "step: 90300 training 0.55            validation 0.5594\n",
      "\n",
      "step: 90350 training 0.566667            validation 0.5576\n",
      "\n",
      "step: 90400 training 0.55            validation 0.5602\n",
      "\n",
      "step: 90450 training 0.6            validation 0.5596\n",
      "\n",
      "step: 90500 training 0.466667            validation 0.5624\n",
      "\n",
      "step: 90550 training 0.55            validation 0.5606\n",
      "\n",
      "step: 90600 training 0.533333            validation 0.561\n",
      "\n",
      "step: 90650 training 0.616667            validation 0.5608\n",
      "\n",
      "step: 90700 training 0.416667            validation 0.5602\n",
      "\n",
      "step: 90750 training 0.566667            validation 0.5594\n",
      "\n",
      "step: 90800 training 0.55            validation 0.56\n",
      "\n",
      "step: 90850 training 0.633333            validation 0.559\n",
      "\n",
      "step: 90900 training 0.566667            validation 0.5608\n",
      "\n",
      "step: 90950 training 0.55            validation 0.5594\n",
      "\n",
      "step: 91000 training 0.55            validation 0.5586\n",
      "\n",
      "step: 91050 training 0.566667            validation 0.5586\n",
      "\n",
      "step: 91100 training 0.533333            validation 0.559\n",
      "\n",
      "step: 91150 training 0.633333            validation 0.5592\n",
      "\n",
      "step: 91200 training 0.466667            validation 0.5596\n",
      "\n",
      "step: 91250 training 0.516667            validation 0.5602\n",
      "\n",
      "step: 91300 training 0.666667            validation 0.5592\n",
      "\n",
      "step: 91350 training 0.6            validation 0.5592\n",
      "\n",
      "step: 91400 training 0.666667            validation 0.561\n",
      "\n",
      "step: 91450 training 0.583333            validation 0.5586\n",
      "\n",
      "step: 91500 training 0.566667            validation 0.561\n",
      "\n",
      "step: 91550 training 0.5            validation 0.5608\n",
      "\n",
      "step: 91600 training 0.616667            validation 0.5582\n",
      "\n",
      "step: 91650 training 0.616667            validation 0.5594\n",
      "\n",
      "step: 91700 training 0.616667            validation 0.5594\n",
      "\n",
      "step: 91750 training 0.566667            validation 0.5582\n",
      "\n",
      "step: 91800 training 0.533333            validation 0.5602\n",
      "\n",
      "step: 91850 training 0.616667            validation 0.5568\n",
      "\n",
      "step: 91900 training 0.566667            validation 0.56\n",
      "\n",
      "step: 91950 training 0.633333            validation 0.5604\n",
      "\n",
      "step: 92000 training 0.566667            validation 0.5606\n",
      "\n",
      "step: 92050 training 0.616667            validation 0.5598\n",
      "\n",
      "step: 92100 training 0.55            validation 0.5594\n",
      "\n",
      "step: 92150 training 0.583333            validation 0.5582\n",
      "\n",
      "step: 92200 training 0.55            validation 0.5578\n",
      "\n",
      "step: 92250 training 0.616667            validation 0.56\n",
      "\n",
      "step: 92300 training 0.516667            validation 0.56\n",
      "\n",
      "step: 92350 training 0.65            validation 0.563\n",
      "\n",
      "step: 92400 training 0.516667            validation 0.5616\n",
      "\n",
      "step: 92450 training 0.533333            validation 0.5592\n",
      "\n",
      "step: 92500 training 0.6            validation 0.5566\n",
      "\n",
      "step: 92550 training 0.483333            validation 0.5598\n",
      "\n",
      "step: 92600 training 0.6            validation 0.5598\n",
      "\n",
      "step: 92650 training 0.616667            validation 0.5588\n",
      "\n",
      "step: 92700 training 0.616667            validation 0.559\n",
      "\n",
      "step: 92750 training 0.65            validation 0.5594\n",
      "\n",
      "step: 92800 training 0.666667            validation 0.5596\n",
      "\n",
      "step: 92850 training 0.55            validation 0.558\n",
      "\n",
      "step: 92900 training 0.566667            validation 0.559\n",
      "\n",
      "step: 92950 training 0.683333            validation 0.559\n",
      "\n",
      "step: 93000 training 0.533333            validation 0.5602\n",
      "\n",
      "step: 93050 training 0.666667            validation 0.5606\n",
      "\n",
      "step: 93100 training 0.566667            validation 0.5602\n",
      "\n",
      "step: 93150 training 0.566667            validation 0.56\n",
      "\n",
      "step: 93200 training 0.566667            validation 0.5596\n",
      "\n",
      "step: 93250 training 0.6            validation 0.5614\n",
      "\n",
      "step: 93300 training 0.6            validation 0.559\n",
      "\n",
      "step: 93350 training 0.583333            validation 0.5604\n",
      "\n",
      "step: 93400 training 0.7            validation 0.56\n",
      "\n",
      "step: 93450 training 0.6            validation 0.5594\n",
      "\n",
      "step: 93500 training 0.616667            validation 0.5588\n",
      "\n",
      "step: 93550 training 0.633333            validation 0.56\n",
      "\n",
      "step: 93600 training 0.616667            validation 0.5592\n",
      "\n",
      "step: 93650 training 0.716667            validation 0.5602\n",
      "\n",
      "step: 93700 training 0.566667            validation 0.5594\n",
      "\n",
      "step: 93750 training 0.683333            validation 0.557\n",
      "\n",
      "step: 93800 training 0.6            validation 0.5592\n",
      "\n",
      "step: 93850 training 0.533333            validation 0.5574\n",
      "\n",
      "step: 93900 training 0.533333            validation 0.559\n",
      "\n",
      "step: 93950 training 0.533333            validation 0.5586\n",
      "\n",
      "step: 94000 training 0.566667            validation 0.5606\n",
      "\n",
      "step: 94050 training 0.55            validation 0.56\n",
      "\n",
      "step: 94100 training 0.55            validation 0.5612\n",
      "\n",
      "step: 94150 training 0.55            validation 0.5584\n",
      "\n",
      "step: 94200 training 0.65            validation 0.5622\n",
      "\n",
      "step: 94250 training 0.533333            validation 0.5592\n",
      "\n",
      "step: 94300 training 0.616667            validation 0.5612\n",
      "\n",
      "step: 94350 training 0.7            validation 0.5594\n",
      "\n",
      "step: 94400 training 0.516667            validation 0.561\n",
      "\n",
      "step: 94450 training 0.55            validation 0.5592\n",
      "\n",
      "step: 94500 training 0.516667            validation 0.5594\n",
      "\n",
      "step: 94550 training 0.6            validation 0.5614\n",
      "\n",
      "step: 94600 training 0.566667            validation 0.559\n",
      "\n",
      "step: 94650 training 0.6            validation 0.5614\n",
      "\n",
      "step: 94700 training 0.566667            validation 0.5602\n",
      "\n",
      "step: 94750 training 0.7            validation 0.559\n",
      "\n",
      "step: 94800 training 0.583333            validation 0.5602\n",
      "\n",
      "step: 94850 training 0.7            validation 0.5596\n",
      "\n",
      "step: 94900 training 0.6            validation 0.5606\n",
      "\n",
      "step: 94950 training 0.533333            validation 0.5608\n",
      "\n",
      "step: 95000 training 0.583333            validation 0.5554\n",
      "\n",
      "step: 95050 training 0.55            validation 0.5622\n",
      "\n",
      "step: 95100 training 0.65            validation 0.5604\n",
      "\n",
      "step: 95150 training 0.55            validation 0.5602\n",
      "\n",
      "step: 95200 training 0.666667            validation 0.5604\n",
      "\n",
      "step: 95250 training 0.65            validation 0.5618\n",
      "\n",
      "step: 95300 training 0.633333            validation 0.5594\n",
      "\n",
      "step: 95350 training 0.533333            validation 0.5578\n",
      "\n",
      "step: 95400 training 0.6            validation 0.5574\n",
      "\n",
      "step: 95450 training 0.55            validation 0.5616\n",
      "\n",
      "step: 95500 training 0.616667            validation 0.5582\n",
      "\n",
      "step: 95550 training 0.583333            validation 0.558\n",
      "\n",
      "step: 95600 training 0.55            validation 0.5606\n",
      "\n",
      "step: 95650 training 0.583333            validation 0.5602\n",
      "\n",
      "step: 95700 training 0.6            validation 0.561\n",
      "\n",
      "step: 95750 training 0.55            validation 0.5604\n",
      "\n",
      "step: 95800 training 0.6            validation 0.5588\n",
      "\n",
      "step: 95850 training 0.516667            validation 0.5592\n",
      "\n",
      "step: 95900 training 0.5            validation 0.5592\n",
      "\n",
      "step: 95950 training 0.633333            validation 0.5602\n",
      "\n",
      "step: 96000 training 0.616667            validation 0.5586\n",
      "\n",
      "step: 96050 training 0.533333            validation 0.5602\n",
      "\n",
      "step: 96100 training 0.633333            validation 0.559\n",
      "\n",
      "step: 96150 training 0.566667            validation 0.5596\n",
      "\n",
      "step: 96200 training 0.6            validation 0.5598\n",
      "\n",
      "step: 96250 training 0.583333            validation 0.5572\n",
      "\n",
      "step: 96300 training 0.633333            validation 0.5592\n",
      "\n",
      "step: 96350 training 0.466667            validation 0.5604\n",
      "\n",
      "step: 96400 training 0.633333            validation 0.5606\n",
      "\n",
      "step: 96450 training 0.583333            validation 0.56\n",
      "\n",
      "step: 96500 training 0.716667            validation 0.5608\n",
      "\n",
      "step: 96550 training 0.65            validation 0.5602\n",
      "\n",
      "step: 96600 training 0.55            validation 0.5604\n",
      "\n",
      "step: 96650 training 0.55            validation 0.5596\n",
      "\n",
      "step: 96700 training 0.5            validation 0.5594\n",
      "\n",
      "step: 96750 training 0.6            validation 0.5598\n",
      "\n",
      "step: 96800 training 0.616667            validation 0.5606\n",
      "\n",
      "step: 96850 training 0.733333            validation 0.5592\n",
      "\n",
      "step: 96900 training 0.55            validation 0.5586\n",
      "\n",
      "step: 96950 training 0.583333            validation 0.561\n",
      "\n",
      "step: 97000 training 0.55            validation 0.5606\n",
      "\n",
      "step: 97050 training 0.466667            validation 0.5582\n",
      "\n",
      "step: 97100 training 0.633333            validation 0.558\n",
      "\n",
      "step: 97150 training 0.633333            validation 0.5584\n",
      "\n",
      "step: 97200 training 0.583333            validation 0.5588\n",
      "\n",
      "step: 97250 training 0.566667            validation 0.558\n",
      "\n",
      "step: 97300 training 0.533333            validation 0.5578\n",
      "\n",
      "step: 97350 training 0.7            validation 0.5586\n",
      "\n",
      "step: 97400 training 0.466667            validation 0.5576\n",
      "\n",
      "step: 97450 training 0.533333            validation 0.5594\n",
      "\n",
      "step: 97500 training 0.583333            validation 0.559\n",
      "\n",
      "step: 97550 training 0.6            validation 0.5588\n",
      "\n",
      "step: 97600 training 0.6            validation 0.5602\n",
      "\n",
      "step: 97650 training 0.5            validation 0.5604\n",
      "\n",
      "step: 97700 training 0.6            validation 0.5582\n",
      "\n",
      "step: 97750 training 0.583333            validation 0.5586\n",
      "\n",
      "step: 97800 training 0.616667            validation 0.5604\n",
      "\n",
      "step: 97850 training 0.516667            validation 0.562\n",
      "\n",
      "step: 97900 training 0.4            validation 0.56\n",
      "\n",
      "step: 97950 training 0.55            validation 0.5602\n",
      "\n",
      "step: 98000 training 0.6            validation 0.5598\n",
      "\n",
      "step: 98050 training 0.516667            validation 0.5606\n",
      "\n",
      "step: 98100 training 0.6            validation 0.5626\n",
      "\n",
      "step: 98150 training 0.633333            validation 0.5612\n",
      "\n",
      "step: 98200 training 0.6            validation 0.5596\n",
      "\n",
      "step: 98250 training 0.6            validation 0.5594\n",
      "\n",
      "step: 98300 training 0.55            validation 0.5586\n",
      "\n",
      "step: 98350 training 0.5            validation 0.5598\n",
      "\n",
      "step: 98400 training 0.516667            validation 0.5606\n",
      "\n",
      "step: 98450 training 0.483333            validation 0.56\n",
      "\n",
      "step: 98500 training 0.6            validation 0.5596\n",
      "\n",
      "step: 98550 training 0.666667            validation 0.5626\n",
      "\n",
      "step: 98600 training 0.583333            validation 0.5582\n",
      "\n",
      "step: 98650 training 0.583333            validation 0.5582\n",
      "\n",
      "step: 98700 training 0.683333            validation 0.5606\n",
      "\n",
      "step: 98750 training 0.633333            validation 0.559\n",
      "\n",
      "step: 98800 training 0.633333            validation 0.5604\n",
      "\n",
      "step: 98850 training 0.483333            validation 0.5614\n",
      "\n",
      "step: 98900 training 0.483333            validation 0.5594\n",
      "\n",
      "step: 98950 training 0.583333            validation 0.5598\n",
      "\n",
      "step: 99000 training 0.516667            validation 0.5604\n",
      "\n",
      "step: 99050 training 0.566667            validation 0.56\n",
      "\n",
      "step: 99100 training 0.616667            validation 0.5606\n",
      "\n",
      "step: 99150 training 0.516667            validation 0.5616\n",
      "\n",
      "step: 99200 training 0.616667            validation 0.5606\n",
      "\n",
      "step: 99250 training 0.6            validation 0.5602\n",
      "\n",
      "step: 99300 training 0.6            validation 0.56\n",
      "\n",
      "step: 99350 training 0.583333            validation 0.5602\n",
      "\n",
      "step: 99400 training 0.566667            validation 0.5608\n",
      "\n",
      "step: 99450 training 0.666667            validation 0.5592\n",
      "\n",
      "step: 99500 training 0.516667            validation 0.5622\n",
      "\n",
      "step: 99550 training 0.683333            validation 0.5584\n",
      "\n",
      "step: 99600 training 0.6            validation 0.5586\n",
      "\n",
      "step: 99650 training 0.65            validation 0.5578\n",
      "\n",
      "step: 99700 training 0.583333            validation 0.561\n",
      "\n",
      "step: 99750 training 0.516667            validation 0.5598\n",
      "\n",
      "step: 99800 training 0.55            validation 0.5602\n",
      "\n",
      "step: 99850 training 0.6            validation 0.5596\n",
      "\n",
      "step: 99900 training 0.566667            validation 0.559\n",
      "\n",
      "step: 99950 training 0.6            validation 0.5592\n",
      "\n",
      "step: 100000 training 0.6            validation 0.5588\n",
      "\n",
      "step: 100050 training 0.616667            validation 0.561\n",
      "\n",
      "step: 100100 training 0.616667            validation 0.5606\n",
      "\n",
      "step: 100150 training 0.666667            validation 0.5598\n",
      "\n",
      "step: 100200 training 0.566667            validation 0.561\n",
      "\n",
      "step: 100250 training 0.65            validation 0.559\n",
      "\n",
      "step: 100300 training 0.6            validation 0.559\n",
      "\n",
      "step: 100350 training 0.65            validation 0.5596\n",
      "\n",
      "step: 100400 training 0.633333            validation 0.5598\n",
      "\n",
      "step: 100450 training 0.5            validation 0.5602\n",
      "\n",
      "step: 100500 training 0.633333            validation 0.5584\n",
      "\n",
      "step: 100550 training 0.583333            validation 0.5584\n",
      "\n",
      "step: 100600 training 0.666667            validation 0.56\n",
      "\n",
      "step: 100650 training 0.55            validation 0.5608\n",
      "\n",
      "step: 100700 training 0.483333            validation 0.5614\n",
      "\n",
      "step: 100750 training 0.65            validation 0.5594\n",
      "\n",
      "step: 100800 training 0.65            validation 0.56\n",
      "\n",
      "step: 100850 training 0.516667            validation 0.5612\n",
      "\n",
      "step: 100900 training 0.633333            validation 0.561\n",
      "\n",
      "step: 100950 training 0.516667            validation 0.5622\n",
      "\n",
      "step: 101000 training 0.633333            validation 0.5606\n",
      "\n",
      "step: 101050 training 0.583333            validation 0.5606\n",
      "\n",
      "step: 101100 training 0.65            validation 0.5592\n",
      "\n",
      "step: 101150 training 0.616667            validation 0.5588\n",
      "\n",
      "step: 101200 training 0.566667            validation 0.5588\n",
      "\n",
      "step: 101250 training 0.616667            validation 0.5614\n",
      "\n",
      "step: 101300 training 0.566667            validation 0.5592\n",
      "\n",
      "step: 101350 training 0.583333            validation 0.5586\n",
      "\n",
      "step: 101400 training 0.5            validation 0.5602\n",
      "\n",
      "step: 101450 training 0.483333            validation 0.5596\n",
      "\n",
      "step: 101500 training 0.683333            validation 0.5604\n",
      "\n",
      "step: 101550 training 0.683333            validation 0.561\n",
      "\n",
      "step: 101600 training 0.616667            validation 0.5614\n",
      "\n",
      "step: 101650 training 0.566667            validation 0.56\n",
      "\n",
      "step: 101700 training 0.566667            validation 0.562\n",
      "\n",
      "step: 101750 training 0.55            validation 0.5604\n",
      "\n",
      "step: 101800 training 0.5            validation 0.5608\n",
      "\n",
      "step: 101850 training 0.533333            validation 0.5608\n",
      "\n",
      "step: 101900 training 0.566667            validation 0.5592\n",
      "\n",
      "step: 101950 training 0.65            validation 0.5616\n",
      "\n",
      "step: 102000 training 0.55            validation 0.5606\n",
      "\n",
      "step: 102050 training 0.583333            validation 0.56\n",
      "\n",
      "step: 102100 training 0.633333            validation 0.5584\n",
      "\n",
      "step: 102150 training 0.55            validation 0.56\n",
      "\n",
      "step: 102200 training 0.55            validation 0.5608\n",
      "\n",
      "step: 102250 training 0.616667            validation 0.5594\n",
      "\n",
      "step: 102300 training 0.65            validation 0.5598\n",
      "\n",
      "step: 102350 training 0.633333            validation 0.5612\n",
      "\n",
      "step: 102400 training 0.583333            validation 0.559\n",
      "\n",
      "step: 102450 training 0.633333            validation 0.561\n",
      "\n",
      "step: 102500 training 0.583333            validation 0.559\n",
      "\n",
      "step: 102550 training 0.533333            validation 0.5594\n",
      "\n",
      "step: 102600 training 0.633333            validation 0.5608\n",
      "\n",
      "step: 102650 training 0.6            validation 0.5616\n",
      "\n",
      "step: 102700 training 0.583333            validation 0.5612\n",
      "\n",
      "step: 102750 training 0.6            validation 0.5598\n",
      "\n",
      "step: 102800 training 0.583333            validation 0.5618\n",
      "\n",
      "step: 102850 training 0.616667            validation 0.5576\n",
      "\n",
      "step: 102900 training 0.583333            validation 0.5596\n",
      "\n",
      "step: 102950 training 0.55            validation 0.5602\n",
      "\n",
      "step: 103000 training 0.55            validation 0.5624\n",
      "\n",
      "step: 103050 training 0.6            validation 0.562\n",
      "\n",
      "step: 103100 training 0.466667            validation 0.5588\n",
      "\n",
      "step: 103150 training 0.716667            validation 0.562\n",
      "\n",
      "step: 103200 training 0.65            validation 0.56\n",
      "\n",
      "step: 103250 training 0.533333            validation 0.56\n",
      "\n",
      "step: 103300 training 0.616667            validation 0.5616\n",
      "\n",
      "step: 103350 training 0.5            validation 0.56\n",
      "\n",
      "step: 103400 training 0.533333            validation 0.5606\n",
      "\n",
      "step: 103450 training 0.566667            validation 0.5596\n",
      "\n",
      "step: 103500 training 0.516667            validation 0.5588\n",
      "\n",
      "step: 103550 training 0.55            validation 0.561\n",
      "\n",
      "step: 103600 training 0.6            validation 0.5566\n",
      "\n",
      "step: 103650 training 0.566667            validation 0.56\n",
      "\n",
      "step: 103700 training 0.516667            validation 0.5602\n",
      "\n",
      "step: 103750 training 0.55            validation 0.5592\n",
      "\n",
      "step: 103800 training 0.583333            validation 0.5582\n",
      "\n",
      "step: 103850 training 0.65            validation 0.5594\n",
      "\n",
      "step: 103900 training 0.683333            validation 0.5604\n",
      "\n",
      "step: 103950 training 0.7            validation 0.5616\n",
      "\n",
      "step: 104000 training 0.65            validation 0.5606\n",
      "\n",
      "step: 104050 training 0.516667            validation 0.5584\n",
      "\n",
      "step: 104100 training 0.533333            validation 0.5612\n",
      "\n",
      "step: 104150 training 0.583333            validation 0.5594\n",
      "\n",
      "step: 104200 training 0.45            validation 0.5596\n",
      "\n",
      "step: 104250 training 0.516667            validation 0.5616\n",
      "\n",
      "step: 104300 training 0.666667            validation 0.5596\n",
      "\n",
      "step: 104350 training 0.566667            validation 0.562\n",
      "\n",
      "step: 104400 training 0.666667            validation 0.561\n",
      "\n",
      "step: 104450 training 0.633333            validation 0.5588\n",
      "\n",
      "step: 104500 training 0.633333            validation 0.5608\n",
      "\n",
      "step: 104550 training 0.516667            validation 0.5606\n",
      "\n",
      "step: 104600 training 0.666667            validation 0.5608\n",
      "\n",
      "step: 104650 training 0.55            validation 0.5598\n",
      "\n",
      "step: 104700 training 0.6            validation 0.5602\n",
      "\n",
      "step: 104750 training 0.6            validation 0.5574\n",
      "\n",
      "step: 104800 training 0.566667            validation 0.5602\n",
      "\n",
      "step: 104850 training 0.633333            validation 0.5604\n",
      "\n",
      "step: 104900 training 0.633333            validation 0.56\n",
      "\n",
      "step: 104950 training 0.583333            validation 0.5612\n",
      "\n",
      "step: 105000 training 0.4            validation 0.5604\n",
      "\n",
      "step: 105050 training 0.566667            validation 0.5596\n",
      "\n",
      "step: 105100 training 0.466667            validation 0.5614\n",
      "\n",
      "step: 105150 training 0.6            validation 0.5588\n",
      "\n",
      "step: 105200 training 0.533333            validation 0.5598\n",
      "\n",
      "step: 105250 training 0.516667            validation 0.5606\n",
      "\n",
      "step: 105300 training 0.533333            validation 0.5602\n",
      "\n",
      "step: 105350 training 0.633333            validation 0.5588\n",
      "\n",
      "step: 105400 training 0.633333            validation 0.5602\n",
      "\n",
      "step: 105450 training 0.566667            validation 0.5598\n",
      "\n",
      "step: 105500 training 0.583333            validation 0.561\n",
      "\n",
      "step: 105550 training 0.55            validation 0.559\n",
      "\n",
      "step: 105600 training 0.566667            validation 0.558\n",
      "\n",
      "step: 105650 training 0.433333            validation 0.5584\n",
      "\n",
      "step: 105700 training 0.583333            validation 0.561\n",
      "\n",
      "step: 105750 training 0.533333            validation 0.5596\n",
      "\n",
      "step: 105800 training 0.666667            validation 0.5582\n",
      "\n",
      "step: 105850 training 0.566667            validation 0.5616\n",
      "\n",
      "step: 105900 training 0.6            validation 0.5602\n",
      "\n",
      "step: 105950 training 0.6            validation 0.56\n",
      "\n",
      "step: 106000 training 0.666667            validation 0.5604\n",
      "\n",
      "step: 106050 training 0.733333            validation 0.5614\n",
      "\n",
      "step: 106100 training 0.683333            validation 0.5596\n",
      "\n",
      "step: 106150 training 0.516667            validation 0.5604\n",
      "\n",
      "step: 106200 training 0.633333            validation 0.561\n",
      "\n",
      "step: 106250 training 0.633333            validation 0.5606\n",
      "\n",
      "step: 106300 training 0.55            validation 0.56\n",
      "\n",
      "step: 106350 training 0.566667            validation 0.5604\n",
      "\n",
      "step: 106400 training 0.566667            validation 0.5614\n",
      "\n",
      "step: 106450 training 0.566667            validation 0.562\n",
      "\n",
      "step: 106500 training 0.633333            validation 0.5612\n",
      "\n",
      "step: 106550 training 0.633333            validation 0.5604\n",
      "\n",
      "step: 106600 training 0.6            validation 0.5604\n",
      "\n",
      "step: 106650 training 0.45            validation 0.5596\n",
      "\n",
      "step: 106700 training 0.65            validation 0.5618\n",
      "\n",
      "step: 106750 training 0.483333            validation 0.5598\n",
      "\n",
      "step: 106800 training 0.583333            validation 0.5612\n",
      "\n",
      "step: 106850 training 0.566667            validation 0.5594\n",
      "\n",
      "step: 106900 training 0.533333            validation 0.5616\n",
      "\n",
      "step: 106950 training 0.6            validation 0.5612\n",
      "\n",
      "step: 107000 training 0.633333            validation 0.5596\n",
      "\n",
      "step: 107050 training 0.583333            validation 0.561\n",
      "\n",
      "step: 107100 training 0.616667            validation 0.5602\n",
      "\n",
      "step: 107150 training 0.566667            validation 0.5608\n",
      "\n",
      "step: 107200 training 0.483333            validation 0.5592\n",
      "\n",
      "step: 107250 training 0.616667            validation 0.561\n",
      "\n",
      "step: 107300 training 0.55            validation 0.561\n",
      "\n",
      "step: 107350 training 0.6            validation 0.5612\n",
      "\n",
      "step: 107400 training 0.616667            validation 0.5604\n",
      "\n",
      "step: 107450 training 0.666667            validation 0.5602\n",
      "\n",
      "step: 107500 training 0.583333            validation 0.5616\n",
      "\n",
      "step: 107550 training 0.65            validation 0.5614\n",
      "\n",
      "step: 107600 training 0.566667            validation 0.5604\n",
      "\n",
      "step: 107650 training 0.55            validation 0.561\n",
      "\n",
      "step: 107700 training 0.6            validation 0.5596\n",
      "\n",
      "step: 107750 training 0.583333            validation 0.5608\n",
      "\n",
      "step: 107800 training 0.683333            validation 0.5606\n",
      "\n",
      "step: 107850 training 0.483333            validation 0.5592\n",
      "\n",
      "step: 107900 training 0.633333            validation 0.5598\n",
      "\n",
      "step: 107950 training 0.616667            validation 0.5606\n",
      "\n",
      "step: 108000 training 0.516667            validation 0.5602\n",
      "\n",
      "step: 108050 training 0.466667            validation 0.5618\n",
      "\n",
      "step: 108100 training 0.583333            validation 0.5622\n",
      "\n",
      "step: 108150 training 0.566667            validation 0.5594\n",
      "\n",
      "step: 108200 training 0.566667            validation 0.5592\n",
      "\n",
      "step: 108250 training 0.666667            validation 0.56\n",
      "\n",
      "step: 108300 training 0.55            validation 0.5592\n",
      "\n",
      "step: 108350 training 0.55            validation 0.5584\n",
      "\n",
      "step: 108400 training 0.516667            validation 0.5608\n",
      "\n",
      "step: 108450 training 0.433333            validation 0.56\n",
      "\n",
      "step: 108500 training 0.566667            validation 0.5614\n",
      "\n",
      "step: 108550 training 0.55            validation 0.562\n",
      "\n",
      "step: 108600 training 0.616667            validation 0.561\n",
      "\n",
      "step: 108650 training 0.5            validation 0.5612\n",
      "\n",
      "step: 108700 training 0.433333            validation 0.561\n",
      "\n",
      "step: 108750 training 0.633333            validation 0.5612\n",
      "\n",
      "step: 108800 training 0.616667            validation 0.5586\n",
      "\n",
      "step: 108850 training 0.6            validation 0.5608\n",
      "\n",
      "step: 108900 training 0.566667            validation 0.5604\n",
      "\n",
      "step: 108950 training 0.633333            validation 0.5604\n",
      "\n",
      "step: 109000 training 0.583333            validation 0.5612\n",
      "\n",
      "step: 109050 training 0.616667            validation 0.5612\n",
      "\n",
      "step: 109100 training 0.533333            validation 0.5624\n",
      "\n",
      "step: 109150 training 0.65            validation 0.5602\n",
      "\n",
      "step: 109200 training 0.616667            validation 0.5592\n",
      "\n",
      "step: 109250 training 0.633333            validation 0.5602\n",
      "\n",
      "step: 109300 training 0.616667            validation 0.5616\n",
      "\n",
      "step: 109350 training 0.433333            validation 0.5594\n",
      "\n",
      "step: 109400 training 0.683333            validation 0.5606\n",
      "\n",
      "step: 109450 training 0.566667            validation 0.5612\n",
      "\n",
      "step: 109500 training 0.483333            validation 0.5594\n",
      "\n",
      "step: 109550 training 0.516667            validation 0.5592\n",
      "\n",
      "step: 109600 training 0.616667            validation 0.5602\n",
      "\n",
      "step: 109650 training 0.55            validation 0.5592\n",
      "\n",
      "step: 109700 training 0.533333            validation 0.5596\n",
      "\n",
      "step: 109750 training 0.55            validation 0.5566\n",
      "\n",
      "step: 109800 training 0.633333            validation 0.5592\n",
      "\n",
      "step: 109850 training 0.55            validation 0.5586\n",
      "\n",
      "step: 109900 training 0.7            validation 0.5596\n",
      "\n",
      "step: 109950 training 0.566667            validation 0.5606\n",
      "\n",
      "step: 110000 training 0.533333            validation 0.5582\n",
      "\n",
      "step: 110050 training 0.65            validation 0.5592\n",
      "\n",
      "step: 110100 training 0.466667            validation 0.5592\n",
      "\n",
      "step: 110150 training 0.533333            validation 0.558\n",
      "\n",
      "step: 110200 training 0.65            validation 0.5612\n",
      "\n",
      "step: 110250 training 0.566667            validation 0.5602\n",
      "\n",
      "step: 110300 training 0.516667            validation 0.5594\n",
      "\n",
      "step: 110350 training 0.533333            validation 0.5606\n",
      "\n",
      "step: 110400 training 0.533333            validation 0.5608\n",
      "\n",
      "step: 110450 training 0.566667            validation 0.5606\n",
      "\n",
      "step: 110500 training 0.55            validation 0.559\n",
      "\n",
      "step: 110550 training 0.6            validation 0.56\n",
      "\n",
      "step: 110600 training 0.65            validation 0.5626\n",
      "\n",
      "step: 110650 training 0.55            validation 0.5612\n",
      "\n",
      "step: 110700 training 0.583333            validation 0.5602\n",
      "\n",
      "step: 110750 training 0.616667            validation 0.561\n",
      "\n",
      "step: 110800 training 0.55            validation 0.5602\n",
      "\n",
      "step: 110850 training 0.566667            validation 0.5592\n",
      "\n",
      "step: 110900 training 0.583333            validation 0.5586\n",
      "\n",
      "step: 110950 training 0.533333            validation 0.5604\n",
      "\n",
      "step: 111000 training 0.666667            validation 0.5604\n",
      "\n",
      "step: 111050 training 0.583333            validation 0.5612\n",
      "\n",
      "step: 111100 training 0.533333            validation 0.5588\n",
      "\n",
      "step: 111150 training 0.516667            validation 0.5602\n",
      "\n",
      "step: 111200 training 0.466667            validation 0.5598\n",
      "\n",
      "step: 111250 training 0.6            validation 0.5582\n",
      "\n",
      "step: 111300 training 0.533333            validation 0.5584\n",
      "\n",
      "step: 111350 training 0.533333            validation 0.5602\n",
      "\n",
      "step: 111400 training 0.616667            validation 0.5608\n",
      "\n",
      "step: 111450 training 0.566667            validation 0.5616\n",
      "\n",
      "step: 111500 training 0.6            validation 0.561\n",
      "\n",
      "step: 111550 training 0.666667            validation 0.5608\n",
      "\n",
      "step: 111600 training 0.55            validation 0.5612\n",
      "\n",
      "step: 111650 training 0.65            validation 0.5612\n",
      "\n",
      "step: 111700 training 0.583333            validation 0.5608\n",
      "\n",
      "step: 111750 training 0.583333            validation 0.561\n",
      "\n",
      "step: 111800 training 0.566667            validation 0.5606\n",
      "\n",
      "step: 111850 training 0.616667            validation 0.5582\n",
      "\n",
      "step: 111900 training 0.55            validation 0.5604\n",
      "\n",
      "step: 111950 training 0.516667            validation 0.5602\n",
      "\n",
      "step: 112000 training 0.5            validation 0.562\n",
      "\n",
      "step: 112050 training 0.583333            validation 0.5604\n",
      "\n",
      "step: 112100 training 0.6            validation 0.5616\n",
      "\n",
      "step: 112150 training 0.55            validation 0.559\n",
      "\n",
      "step: 112200 training 0.65            validation 0.5578\n",
      "\n",
      "step: 112250 training 0.616667            validation 0.5612\n",
      "\n",
      "step: 112300 training 0.55            validation 0.5574\n",
      "\n",
      "step: 112350 training 0.6            validation 0.5608\n",
      "\n",
      "step: 112400 training 0.7            validation 0.5606\n",
      "\n",
      "step: 112450 training 0.566667            validation 0.5604\n",
      "\n",
      "step: 112500 training 0.583333            validation 0.5608\n",
      "\n",
      "step: 112550 training 0.466667            validation 0.5598\n",
      "\n",
      "step: 112600 training 0.6            validation 0.5624\n",
      "\n",
      "step: 112650 training 0.633333            validation 0.56\n",
      "\n",
      "step: 112700 training 0.616667            validation 0.561\n",
      "\n",
      "step: 112750 training 0.466667            validation 0.5598\n",
      "\n",
      "step: 112800 training 0.533333            validation 0.5588\n",
      "\n",
      "step: 112850 training 0.65            validation 0.562\n",
      "\n",
      "step: 112900 training 0.5            validation 0.5608\n",
      "\n",
      "step: 112950 training 0.516667            validation 0.56\n",
      "\n",
      "step: 113000 training 0.6            validation 0.56\n",
      "\n",
      "step: 113050 training 0.6            validation 0.5608\n",
      "\n",
      "step: 113100 training 0.533333            validation 0.5592\n",
      "\n",
      "step: 113150 training 0.533333            validation 0.5618\n",
      "\n",
      "step: 113200 training 0.666667            validation 0.5606\n",
      "\n",
      "step: 113250 training 0.583333            validation 0.5606\n",
      "\n",
      "step: 113300 training 0.583333            validation 0.5598\n",
      "\n",
      "step: 113350 training 0.566667            validation 0.5592\n",
      "\n",
      "step: 113400 training 0.566667            validation 0.56\n",
      "\n",
      "step: 113450 training 0.566667            validation 0.5604\n",
      "\n",
      "step: 113500 training 0.683333            validation 0.563\n",
      "\n",
      "step: 113550 training 0.583333            validation 0.5596\n",
      "\n",
      "step: 113600 training 0.516667            validation 0.5618\n",
      "\n",
      "step: 113650 training 0.55            validation 0.56\n",
      "\n",
      "step: 113700 training 0.45            validation 0.5584\n",
      "\n",
      "step: 113750 training 0.55            validation 0.5598\n",
      "\n",
      "step: 113800 training 0.583333            validation 0.557\n",
      "\n",
      "step: 113850 training 0.5            validation 0.5606\n",
      "\n",
      "step: 113900 training 0.533333            validation 0.5594\n",
      "\n",
      "step: 113950 training 0.583333            validation 0.5602\n",
      "\n",
      "step: 114000 training 0.65            validation 0.5628\n",
      "\n",
      "step: 114050 training 0.616667            validation 0.5604\n",
      "\n",
      "step: 114100 training 0.583333            validation 0.5616\n",
      "\n",
      "step: 114150 training 0.616667            validation 0.5614\n",
      "\n",
      "step: 114200 training 0.633333            validation 0.5608\n",
      "\n",
      "step: 114250 training 0.633333            validation 0.5584\n",
      "\n",
      "step: 114300 training 0.516667            validation 0.5606\n",
      "\n",
      "step: 114350 training 0.583333            validation 0.5606\n",
      "\n",
      "step: 114400 training 0.4            validation 0.5614\n",
      "\n",
      "step: 114450 training 0.483333            validation 0.562\n",
      "\n",
      "step: 114500 training 0.616667            validation 0.5606\n",
      "\n",
      "step: 114550 training 0.516667            validation 0.5604\n",
      "\n",
      "step: 114600 training 0.6            validation 0.5604\n",
      "\n",
      "step: 114650 training 0.55            validation 0.5602\n",
      "\n",
      "step: 114700 training 0.533333            validation 0.56\n",
      "\n",
      "step: 114750 training 0.466667            validation 0.559\n",
      "\n",
      "step: 114800 training 0.533333            validation 0.5588\n",
      "\n",
      "step: 114850 training 0.616667            validation 0.559\n",
      "\n",
      "step: 114900 training 0.683333            validation 0.56\n",
      "\n",
      "step: 114950 training 0.533333            validation 0.5632\n",
      "\n",
      "step: 115000 training 0.566667            validation 0.5596\n",
      "\n",
      "step: 115050 training 0.583333            validation 0.5592\n",
      "\n",
      "step: 115100 training 0.533333            validation 0.561\n",
      "\n",
      "step: 115150 training 0.616667            validation 0.5594\n",
      "\n",
      "step: 115200 training 0.583333            validation 0.5598\n",
      "\n",
      "step: 115250 training 0.6            validation 0.5596\n",
      "\n",
      "step: 115300 training 0.616667            validation 0.5608\n",
      "\n",
      "step: 115350 training 0.55            validation 0.5602\n",
      "\n",
      "step: 115400 training 0.65            validation 0.5604\n",
      "\n",
      "step: 115450 training 0.6            validation 0.5586\n",
      "\n",
      "step: 115500 training 0.6            validation 0.5616\n",
      "\n",
      "step: 115550 training 0.55            validation 0.5606\n",
      "\n",
      "step: 115600 training 0.483333            validation 0.5594\n",
      "\n",
      "step: 115650 training 0.6            validation 0.5582\n",
      "\n",
      "step: 115700 training 0.6            validation 0.559\n",
      "\n",
      "step: 115750 training 0.55            validation 0.56\n",
      "\n",
      "step: 115800 training 0.55            validation 0.5594\n",
      "\n",
      "step: 115850 training 0.583333            validation 0.5604\n",
      "\n",
      "step: 115900 training 0.533333            validation 0.5598\n",
      "\n",
      "step: 115950 training 0.533333            validation 0.5602\n",
      "\n",
      "step: 116000 training 0.583333            validation 0.5608\n",
      "\n",
      "step: 116050 training 0.65            validation 0.5604\n",
      "\n",
      "step: 116100 training 0.533333            validation 0.559\n",
      "\n",
      "step: 116150 training 0.566667            validation 0.5594\n",
      "\n",
      "step: 116200 training 0.566667            validation 0.5598\n",
      "\n",
      "step: 116250 training 0.516667            validation 0.5584\n",
      "\n",
      "step: 116300 training 0.616667            validation 0.5576\n",
      "\n",
      "step: 116350 training 0.616667            validation 0.5596\n",
      "\n",
      "step: 116400 training 0.55            validation 0.5596\n",
      "\n",
      "step: 116450 training 0.583333            validation 0.5596\n",
      "\n",
      "step: 116500 training 0.566667            validation 0.5592\n",
      "\n",
      "step: 116550 training 0.45            validation 0.5592\n",
      "\n",
      "step: 116600 training 0.55            validation 0.5584\n",
      "\n",
      "step: 116650 training 0.583333            validation 0.559\n",
      "\n",
      "step: 116700 training 0.583333            validation 0.5598\n",
      "\n",
      "step: 116750 training 0.583333            validation 0.56\n",
      "\n",
      "step: 116800 training 0.566667            validation 0.5606\n",
      "\n",
      "step: 116850 training 0.666667            validation 0.5594\n",
      "\n",
      "step: 116900 training 0.55            validation 0.5592\n",
      "\n",
      "step: 116950 training 0.7            validation 0.5584\n",
      "\n",
      "step: 117000 training 0.566667            validation 0.5598\n",
      "\n",
      "step: 117050 training 0.583333            validation 0.5612\n",
      "\n",
      "step: 117100 training 0.516667            validation 0.561\n",
      "\n",
      "step: 117150 training 0.483333            validation 0.5608\n",
      "\n",
      "step: 117200 training 0.516667            validation 0.559\n",
      "\n",
      "step: 117250 training 0.533333            validation 0.5586\n",
      "\n",
      "step: 117300 training 0.616667            validation 0.5598\n",
      "\n",
      "step: 117350 training 0.6            validation 0.5594\n",
      "\n",
      "step: 117400 training 0.6            validation 0.5596\n",
      "\n",
      "step: 117450 training 0.583333            validation 0.5586\n",
      "\n",
      "step: 117500 training 0.65            validation 0.5624\n",
      "\n",
      "step: 117550 training 0.6            validation 0.5596\n",
      "\n",
      "step: 117600 training 0.55            validation 0.5582\n",
      "\n",
      "step: 117650 training 0.616667            validation 0.56\n",
      "\n",
      "step: 117700 training 0.533333            validation 0.5602\n",
      "\n",
      "step: 117750 training 0.566667            validation 0.5612\n",
      "\n",
      "step: 117800 training 0.666667            validation 0.5604\n",
      "\n",
      "step: 117850 training 0.683333            validation 0.5592\n",
      "\n",
      "step: 117900 training 0.6            validation 0.5596\n",
      "\n",
      "step: 117950 training 0.5            validation 0.5592\n",
      "\n",
      "step: 118000 training 0.633333            validation 0.5598\n",
      "\n",
      "step: 118050 training 0.616667            validation 0.5588\n",
      "\n",
      "step: 118100 training 0.716667            validation 0.5574\n",
      "\n",
      "step: 118150 training 0.7            validation 0.5594\n",
      "\n",
      "step: 118200 training 0.566667            validation 0.558\n",
      "\n",
      "step: 118250 training 0.566667            validation 0.562\n",
      "\n",
      "step: 118300 training 0.583333            validation 0.5582\n",
      "\n",
      "step: 118350 training 0.666667            validation 0.5602\n",
      "\n",
      "step: 118400 training 0.616667            validation 0.559\n",
      "\n",
      "step: 118450 training 0.633333            validation 0.5586\n",
      "\n",
      "step: 118500 training 0.666667            validation 0.5598\n",
      "\n",
      "step: 118550 training 0.65            validation 0.5586\n",
      "\n",
      "step: 118600 training 0.583333            validation 0.5598\n",
      "\n",
      "step: 118650 training 0.566667            validation 0.5598\n",
      "\n",
      "step: 118700 training 0.55            validation 0.558\n",
      "\n",
      "step: 118750 training 0.583333            validation 0.5622\n",
      "\n",
      "step: 118800 training 0.583333            validation 0.5602\n",
      "\n",
      "step: 118850 training 0.516667            validation 0.5588\n",
      "\n",
      "step: 118900 training 0.6            validation 0.56\n",
      "\n",
      "step: 118950 training 0.533333            validation 0.5598\n",
      "\n",
      "step: 119000 training 0.583333            validation 0.5592\n",
      "\n",
      "step: 119050 training 0.483333            validation 0.5604\n",
      "\n",
      "step: 119100 training 0.533333            validation 0.5614\n",
      "\n",
      "step: 119150 training 0.533333            validation 0.5612\n",
      "\n",
      "step: 119200 training 0.5            validation 0.5594\n",
      "\n",
      "step: 119250 training 0.566667            validation 0.5596\n",
      "\n",
      "step: 119300 training 0.7            validation 0.5598\n",
      "\n",
      "step: 119350 training 0.55            validation 0.5598\n",
      "\n",
      "step: 119400 training 0.6            validation 0.5586\n",
      "\n",
      "step: 119450 training 0.616667            validation 0.5608\n",
      "\n",
      "step: 119500 training 0.633333            validation 0.561\n",
      "\n",
      "step: 119550 training 0.516667            validation 0.5574\n",
      "\n",
      "step: 119600 training 0.5            validation 0.5608\n",
      "\n",
      "step: 119650 training 0.516667            validation 0.5596\n",
      "\n",
      "step: 119700 training 0.533333            validation 0.5602\n",
      "\n",
      "step: 119750 training 0.533333            validation 0.56\n",
      "\n",
      "step: 119800 training 0.55            validation 0.5596\n",
      "\n",
      "step: 119850 training 0.55            validation 0.56\n",
      "\n",
      "step: 119900 training 0.6            validation 0.56\n",
      "\n",
      "step: 119950 training 0.583333            validation 0.5616\n",
      "\n",
      "step: 120000 training 0.633333            validation 0.5614\n",
      "\n",
      "step: 120050 training 0.65            validation 0.5618\n",
      "\n",
      "step: 120100 training 0.683333            validation 0.5608\n",
      "\n",
      "step: 120150 training 0.533333            validation 0.5602\n",
      "\n",
      "step: 120200 training 0.583333            validation 0.561\n",
      "\n",
      "step: 120250 training 0.65            validation 0.5594\n",
      "\n",
      "step: 120300 training 0.516667            validation 0.5598\n",
      "\n",
      "step: 120350 training 0.566667            validation 0.5612\n",
      "\n",
      "step: 120400 training 0.583333            validation 0.56\n",
      "\n",
      "step: 120450 training 0.633333            validation 0.5602\n",
      "\n",
      "step: 120500 training 0.683333            validation 0.561\n",
      "\n",
      "step: 120550 training 0.533333            validation 0.5598\n",
      "\n",
      "step: 120600 training 0.616667            validation 0.5576\n",
      "\n",
      "step: 120650 training 0.533333            validation 0.5596\n",
      "\n",
      "step: 120700 training 0.666667            validation 0.5612\n",
      "\n",
      "step: 120750 training 0.533333            validation 0.5596\n",
      "\n",
      "step: 120800 training 0.566667            validation 0.5592\n",
      "\n",
      "step: 120850 training 0.533333            validation 0.5584\n",
      "\n",
      "step: 120900 training 0.583333            validation 0.5594\n",
      "\n",
      "step: 120950 training 0.533333            validation 0.5602\n",
      "\n",
      "step: 121000 training 0.616667            validation 0.5612\n",
      "\n",
      "step: 121050 training 0.616667            validation 0.5598\n",
      "\n",
      "step: 121100 training 0.55            validation 0.5586\n",
      "\n",
      "step: 121150 training 0.483333            validation 0.5592\n",
      "\n",
      "step: 121200 training 0.583333            validation 0.5608\n",
      "\n",
      "step: 121250 training 0.65            validation 0.5598\n",
      "\n",
      "step: 121300 training 0.566667            validation 0.5606\n",
      "\n",
      "step: 121350 training 0.65            validation 0.5612\n",
      "\n",
      "step: 121400 training 0.6            validation 0.5604\n",
      "\n",
      "step: 121450 training 0.65            validation 0.5594\n",
      "\n",
      "step: 121500 training 0.566667            validation 0.5594\n",
      "\n",
      "step: 121550 training 0.516667            validation 0.5604\n",
      "\n",
      "step: 121600 training 0.566667            validation 0.5612\n",
      "\n",
      "step: 121650 training 0.583333            validation 0.5588\n",
      "\n",
      "step: 121700 training 0.65            validation 0.5608\n",
      "\n",
      "step: 121750 training 0.65            validation 0.5612\n",
      "\n",
      "step: 121800 training 0.633333            validation 0.5596\n",
      "\n",
      "step: 121850 training 0.6            validation 0.5602\n",
      "\n",
      "step: 121900 training 0.666667            validation 0.5596\n",
      "\n",
      "step: 121950 training 0.35            validation 0.5594\n",
      "\n",
      "step: 122000 training 0.55            validation 0.5598\n",
      "\n",
      "step: 122050 training 0.516667            validation 0.5608\n",
      "\n",
      "step: 122100 training 0.6            validation 0.5606\n",
      "\n",
      "step: 122150 training 0.566667            validation 0.5594\n",
      "\n",
      "step: 122200 training 0.416667            validation 0.5612\n",
      "\n",
      "step: 122250 training 0.616667            validation 0.5608\n",
      "\n",
      "step: 122300 training 0.533333            validation 0.5616\n",
      "\n",
      "step: 122350 training 0.566667            validation 0.5632\n",
      "\n",
      "step: 122400 training 0.583333            validation 0.5604\n",
      "\n",
      "step: 122450 training 0.55            validation 0.5606\n",
      "\n",
      "step: 122500 training 0.7            validation 0.5592\n",
      "\n",
      "step: 122550 training 0.6            validation 0.5598\n",
      "\n",
      "step: 122600 training 0.633333            validation 0.5614\n",
      "\n",
      "step: 122650 training 0.516667            validation 0.5602\n",
      "\n",
      "step: 122700 training 0.483333            validation 0.561\n",
      "\n",
      "step: 122750 training 0.55            validation 0.561\n",
      "\n",
      "step: 122800 training 0.516667            validation 0.5602\n",
      "\n",
      "step: 122850 training 0.45            validation 0.5594\n",
      "\n",
      "step: 122900 training 0.633333            validation 0.5618\n",
      "\n",
      "step: 122950 training 0.5            validation 0.558\n",
      "\n",
      "step: 123000 training 0.65            validation 0.5598\n",
      "\n",
      "step: 123050 training 0.683333            validation 0.5588\n",
      "\n",
      "step: 123100 training 0.533333            validation 0.5612\n",
      "\n",
      "step: 123150 training 0.633333            validation 0.5624\n",
      "\n",
      "step: 123200 training 0.45            validation 0.5596\n",
      "\n",
      "step: 123250 training 0.55            validation 0.558\n",
      "\n",
      "step: 123300 training 0.666667            validation 0.5626\n",
      "\n",
      "step: 123350 training 0.633333            validation 0.5584\n",
      "\n",
      "step: 123400 training 0.683333            validation 0.5602\n",
      "\n",
      "step: 123450 training 0.466667            validation 0.5622\n",
      "\n",
      "step: 123500 training 0.5            validation 0.5614\n",
      "\n",
      "step: 123550 training 0.583333            validation 0.561\n",
      "\n",
      "step: 123600 training 0.616667            validation 0.5604\n",
      "\n",
      "step: 123650 training 0.683333            validation 0.56\n",
      "\n",
      "step: 123700 training 0.533333            validation 0.5606\n",
      "\n",
      "step: 123750 training 0.65            validation 0.5602\n",
      "\n",
      "step: 123800 training 0.483333            validation 0.5618\n",
      "\n",
      "step: 123850 training 0.483333            validation 0.5606\n",
      "\n",
      "step: 123900 training 0.616667            validation 0.559\n",
      "\n",
      "step: 123950 training 0.566667            validation 0.5596\n",
      "\n",
      "step: 124000 training 0.483333            validation 0.5596\n",
      "\n",
      "step: 124050 training 0.466667            validation 0.5584\n",
      "\n",
      "step: 124100 training 0.483333            validation 0.561\n",
      "\n",
      "step: 124150 training 0.533333            validation 0.5594\n",
      "\n",
      "step: 124200 training 0.566667            validation 0.56\n",
      "\n",
      "step: 124250 training 0.633333            validation 0.5602\n",
      "\n",
      "step: 124300 training 0.483333            validation 0.561\n",
      "\n",
      "step: 124350 training 0.466667            validation 0.5618\n",
      "\n",
      "step: 124400 training 0.566667            validation 0.5616\n",
      "\n",
      "step: 124450 training 0.666667            validation 0.5604\n",
      "\n",
      "step: 124500 training 0.65            validation 0.5598\n",
      "\n",
      "step: 124550 training 0.6            validation 0.5614\n",
      "\n",
      "step: 124600 training 0.6            validation 0.5614\n",
      "\n",
      "step: 124650 training 0.466667            validation 0.5604\n",
      "\n",
      "step: 124700 training 0.6            validation 0.5608\n",
      "\n",
      "step: 124750 training 0.533333            validation 0.5608\n",
      "\n",
      "step: 124800 training 0.433333            validation 0.5614\n",
      "\n",
      "step: 124850 training 0.55            validation 0.5598\n",
      "\n",
      "step: 124900 training 0.55            validation 0.559\n",
      "\n",
      "step: 124950 training 0.516667            validation 0.5598\n",
      "\n",
      "step: 125000 training 0.616667            validation 0.5598\n",
      "\n",
      "step: 125050 training 0.65            validation 0.5584\n",
      "\n",
      "step: 125100 training 0.516667            validation 0.5598\n",
      "\n",
      "step: 125150 training 0.566667            validation 0.5604\n",
      "\n",
      "step: 125200 training 0.5            validation 0.5608\n",
      "\n",
      "step: 125250 training 0.566667            validation 0.5618\n",
      "\n",
      "step: 125300 training 0.533333            validation 0.5604\n",
      "\n",
      "step: 125350 training 0.583333            validation 0.5616\n",
      "\n",
      "step: 125400 training 0.533333            validation 0.5588\n",
      "\n",
      "step: 125450 training 0.6            validation 0.5612\n",
      "\n",
      "step: 125500 training 0.683333            validation 0.5614\n",
      "\n",
      "step: 125550 training 0.583333            validation 0.5604\n",
      "\n",
      "step: 125600 training 0.466667            validation 0.5608\n",
      "\n",
      "step: 125650 training 0.5            validation 0.5614\n",
      "\n",
      "step: 125700 training 0.6            validation 0.5602\n",
      "\n",
      "step: 125750 training 0.633333            validation 0.5608\n",
      "\n",
      "step: 125800 training 0.566667            validation 0.5616\n",
      "\n",
      "step: 125850 training 0.6            validation 0.5616\n",
      "\n",
      "step: 125900 training 0.516667            validation 0.5592\n",
      "\n",
      "step: 125950 training 0.533333            validation 0.5584\n",
      "\n",
      "step: 126000 training 0.533333            validation 0.5624\n",
      "\n",
      "step: 126050 training 0.55            validation 0.5584\n",
      "\n",
      "step: 126100 training 0.45            validation 0.5602\n",
      "\n",
      "step: 126150 training 0.683333            validation 0.5612\n",
      "\n",
      "step: 126200 training 0.616667            validation 0.5596\n",
      "\n",
      "step: 126250 training 0.616667            validation 0.5608\n",
      "\n",
      "step: 126300 training 0.716667            validation 0.5606\n",
      "\n",
      "step: 126350 training 0.6            validation 0.56\n",
      "\n",
      "step: 126400 training 0.65            validation 0.561\n",
      "\n",
      "step: 126450 training 0.533333            validation 0.5598\n",
      "\n",
      "step: 126500 training 0.533333            validation 0.561\n",
      "\n",
      "step: 126550 training 0.5            validation 0.5628\n",
      "\n",
      "step: 126600 training 0.5            validation 0.56\n",
      "\n",
      "step: 126650 training 0.566667            validation 0.56\n",
      "\n",
      "step: 126700 training 0.466667            validation 0.561\n",
      "\n",
      "step: 126750 training 0.55            validation 0.56\n",
      "\n",
      "step: 126800 training 0.55            validation 0.56\n",
      "\n",
      "step: 126850 training 0.483333            validation 0.5604\n",
      "\n",
      "step: 126900 training 0.516667            validation 0.5602\n",
      "\n",
      "step: 126950 training 0.55            validation 0.5614\n",
      "\n",
      "step: 127000 training 0.516667            validation 0.5616\n",
      "\n",
      "step: 127050 training 0.5            validation 0.5614\n",
      "\n",
      "step: 127100 training 0.55            validation 0.5602\n",
      "\n",
      "step: 127150 training 0.566667            validation 0.561\n",
      "\n",
      "step: 127200 training 0.583333            validation 0.5612\n",
      "\n",
      "step: 127250 training 0.633333            validation 0.5616\n",
      "\n",
      "step: 127300 training 0.55            validation 0.5606\n",
      "\n",
      "step: 127350 training 0.516667            validation 0.5602\n",
      "\n",
      "step: 127400 training 0.5            validation 0.5586\n",
      "\n",
      "step: 127450 training 0.683333            validation 0.56\n",
      "\n",
      "step: 127500 training 0.533333            validation 0.5594\n",
      "\n",
      "step: 127550 training 0.483333            validation 0.5604\n",
      "\n",
      "step: 127600 training 0.516667            validation 0.5602\n",
      "\n",
      "step: 127650 training 0.516667            validation 0.5602\n",
      "\n",
      "step: 127700 training 0.55            validation 0.5608\n",
      "\n",
      "step: 127750 training 0.583333            validation 0.56\n",
      "\n",
      "step: 127800 training 0.55            validation 0.5604\n",
      "\n",
      "step: 127850 training 0.55            validation 0.5602\n",
      "\n",
      "step: 127900 training 0.6            validation 0.56\n",
      "\n",
      "step: 127950 training 0.716667            validation 0.5602\n",
      "\n",
      "step: 128000 training 0.516667            validation 0.5586\n",
      "\n",
      "step: 128050 training 0.733333            validation 0.5602\n",
      "\n",
      "step: 128100 training 0.616667            validation 0.5572\n",
      "\n",
      "step: 128150 training 0.616667            validation 0.5596\n",
      "\n",
      "step: 128200 training 0.65            validation 0.5598\n",
      "\n",
      "step: 128250 training 0.616667            validation 0.5582\n",
      "\n",
      "step: 128300 training 0.583333            validation 0.5588\n",
      "\n",
      "step: 128350 training 0.6            validation 0.5582\n",
      "\n",
      "step: 128400 training 0.65            validation 0.5594\n",
      "\n",
      "step: 128450 training 0.483333            validation 0.5592\n",
      "\n",
      "step: 128500 training 0.583333            validation 0.5598\n",
      "\n",
      "step: 128550 training 0.65            validation 0.5608\n",
      "\n",
      "step: 128600 training 0.433333            validation 0.5568\n",
      "\n",
      "step: 128650 training 0.616667            validation 0.5614\n",
      "\n",
      "step: 128700 training 0.516667            validation 0.5614\n",
      "\n",
      "step: 128750 training 0.566667            validation 0.5604\n",
      "\n",
      "step: 128800 training 0.633333            validation 0.5602\n",
      "\n",
      "step: 128850 training 0.65            validation 0.5588\n",
      "\n",
      "step: 128900 training 0.633333            validation 0.5592\n",
      "\n",
      "step: 128950 training 0.6            validation 0.5598\n",
      "\n",
      "step: 129000 training 0.583333            validation 0.5618\n",
      "\n",
      "step: 129050 training 0.6            validation 0.5598\n",
      "\n",
      "step: 129100 training 0.566667            validation 0.5582\n",
      "\n",
      "step: 129150 training 0.583333            validation 0.5598\n",
      "\n",
      "step: 129200 training 0.5            validation 0.5602\n",
      "\n",
      "step: 129250 training 0.6            validation 0.5586\n",
      "\n",
      "step: 129300 training 0.516667            validation 0.5598\n",
      "\n",
      "step: 129350 training 0.45            validation 0.5598\n",
      "\n",
      "step: 129400 training 0.6            validation 0.562\n",
      "\n",
      "step: 129450 training 0.6            validation 0.5604\n",
      "\n",
      "step: 129500 training 0.55            validation 0.5596\n",
      "\n",
      "step: 129550 training 0.6            validation 0.5592\n",
      "\n",
      "step: 129600 training 0.45            validation 0.559\n",
      "\n",
      "step: 129650 training 0.566667            validation 0.5608\n",
      "\n",
      "step: 129700 training 0.583333            validation 0.5592\n",
      "\n",
      "step: 129750 training 0.483333            validation 0.5612\n",
      "\n",
      "step: 129800 training 0.416667            validation 0.559\n",
      "\n",
      "step: 129850 training 0.55            validation 0.5606\n",
      "\n",
      "step: 129900 training 0.583333            validation 0.5606\n",
      "\n",
      "step: 129950 training 0.533333            validation 0.5616\n",
      "\n",
      "step: 130000 training 0.483333            validation 0.5584\n",
      "\n",
      "step: 130050 training 0.6            validation 0.5582\n",
      "\n",
      "step: 130100 training 0.533333            validation 0.5598\n",
      "\n",
      "step: 130150 training 0.55            validation 0.5604\n",
      "\n",
      "step: 130200 training 0.633333            validation 0.5598\n",
      "\n",
      "step: 130250 training 0.616667            validation 0.5598\n",
      "\n",
      "step: 130300 training 0.583333            validation 0.5608\n",
      "\n",
      "step: 130350 training 0.616667            validation 0.5584\n",
      "\n",
      "step: 130400 training 0.566667            validation 0.5606\n",
      "\n",
      "step: 130450 training 0.583333            validation 0.5616\n",
      "\n",
      "step: 130500 training 0.6            validation 0.56\n",
      "\n",
      "step: 130550 training 0.55            validation 0.5602\n",
      "\n",
      "step: 130600 training 0.55            validation 0.559\n",
      "\n",
      "step: 130650 training 0.583333            validation 0.5616\n",
      "\n",
      "step: 130700 training 0.6            validation 0.5596\n",
      "\n",
      "step: 130750 training 0.533333            validation 0.5602\n",
      "\n",
      "step: 130800 training 0.6            validation 0.5602\n",
      "\n",
      "step: 130850 training 0.533333            validation 0.561\n",
      "\n",
      "step: 130900 training 0.6            validation 0.5614\n",
      "\n",
      "step: 130950 training 0.733333            validation 0.5616\n",
      "\n",
      "step: 131000 training 0.616667            validation 0.5626\n",
      "\n",
      "step: 131050 training 0.583333            validation 0.5598\n",
      "\n",
      "step: 131100 training 0.566667            validation 0.5594\n",
      "\n",
      "step: 131150 training 0.583333            validation 0.5598\n",
      "\n",
      "step: 131200 training 0.583333            validation 0.5622\n",
      "\n",
      "step: 131250 training 0.5            validation 0.5616\n",
      "\n",
      "step: 131300 training 0.6            validation 0.5612\n",
      "\n",
      "step: 131350 training 0.5            validation 0.5612\n",
      "\n",
      "step: 131400 training 0.55            validation 0.5604\n",
      "\n",
      "step: 131450 training 0.616667            validation 0.5588\n",
      "\n",
      "step: 131500 training 0.65            validation 0.5614\n",
      "\n",
      "step: 131550 training 0.516667            validation 0.5602\n",
      "\n",
      "step: 131600 training 0.45            validation 0.5592\n",
      "\n",
      "step: 131650 training 0.616667            validation 0.5588\n",
      "\n",
      "step: 131700 training 0.616667            validation 0.5594\n",
      "\n",
      "step: 131750 training 0.65            validation 0.5602\n",
      "\n",
      "step: 131800 training 0.566667            validation 0.5578\n",
      "\n",
      "step: 131850 training 0.65            validation 0.5604\n",
      "\n",
      "step: 131900 training 0.616667            validation 0.5602\n",
      "\n",
      "step: 131950 training 0.45            validation 0.5568\n",
      "\n",
      "step: 132000 training 0.533333            validation 0.5618\n",
      "\n",
      "step: 132050 training 0.533333            validation 0.5604\n",
      "\n",
      "step: 132100 training 0.733333            validation 0.5604\n",
      "\n",
      "step: 132150 training 0.65            validation 0.5596\n",
      "\n",
      "step: 132200 training 0.6            validation 0.558\n",
      "\n",
      "step: 132250 training 0.633333            validation 0.558\n",
      "\n",
      "step: 132300 training 0.583333            validation 0.5586\n",
      "\n",
      "step: 132350 training 0.516667            validation 0.5562\n",
      "\n",
      "step: 132400 training 0.566667            validation 0.5606\n",
      "\n",
      "step: 132450 training 0.55            validation 0.56\n",
      "\n",
      "step: 132500 training 0.683333            validation 0.5602\n",
      "\n",
      "step: 132550 training 0.483333            validation 0.5596\n",
      "\n",
      "step: 132600 training 0.666667            validation 0.5594\n",
      "\n",
      "step: 132650 training 0.6            validation 0.5594\n",
      "\n",
      "step: 132700 training 0.566667            validation 0.56\n",
      "\n",
      "step: 132750 training 0.566667            validation 0.561\n",
      "\n",
      "step: 132800 training 0.566667            validation 0.56\n",
      "\n",
      "step: 132850 training 0.533333            validation 0.5592\n",
      "\n",
      "step: 132900 training 0.566667            validation 0.5608\n",
      "\n",
      "step: 132950 training 0.566667            validation 0.5604\n",
      "\n",
      "step: 133000 training 0.616667            validation 0.56\n",
      "\n",
      "step: 133050 training 0.6            validation 0.559\n",
      "\n",
      "step: 133100 training 0.516667            validation 0.559\n",
      "\n",
      "step: 133150 training 0.633333            validation 0.5594\n",
      "\n",
      "step: 133200 training 0.583333            validation 0.5594\n",
      "\n",
      "step: 133250 training 0.533333            validation 0.5596\n",
      "\n",
      "step: 133300 training 0.616667            validation 0.5602\n",
      "\n",
      "step: 133350 training 0.65            validation 0.5602\n",
      "\n",
      "step: 133400 training 0.633333            validation 0.5612\n",
      "\n",
      "step: 133450 training 0.65            validation 0.562\n",
      "\n",
      "step: 133500 training 0.666667            validation 0.5594\n",
      "\n",
      "step: 133550 training 0.6            validation 0.5604\n",
      "\n",
      "step: 133600 training 0.5            validation 0.5586\n",
      "\n",
      "step: 133650 training 0.7            validation 0.5618\n",
      "\n",
      "step: 133700 training 0.55            validation 0.5608\n",
      "\n",
      "step: 133750 training 0.6            validation 0.5624\n",
      "\n",
      "step: 133800 training 0.583333            validation 0.56\n",
      "\n",
      "step: 133850 training 0.6            validation 0.559\n",
      "\n",
      "step: 133900 training 0.583333            validation 0.5592\n",
      "\n",
      "step: 133950 training 0.583333            validation 0.5626\n",
      "\n",
      "step: 134000 training 0.55            validation 0.5594\n",
      "\n",
      "step: 134050 training 0.566667            validation 0.5608\n",
      "\n",
      "step: 134100 training 0.583333            validation 0.5592\n",
      "\n",
      "step: 134150 training 0.65            validation 0.562\n",
      "\n",
      "step: 134200 training 0.616667            validation 0.561\n",
      "\n",
      "step: 134250 training 0.566667            validation 0.559\n",
      "\n",
      "step: 134300 training 0.583333            validation 0.5584\n",
      "\n",
      "step: 134350 training 0.583333            validation 0.561\n",
      "\n",
      "step: 134400 training 0.55            validation 0.5596\n",
      "\n",
      "step: 134450 training 0.5            validation 0.5584\n",
      "\n",
      "step: 134500 training 0.583333            validation 0.559\n",
      "\n",
      "step: 134550 training 0.583333            validation 0.5608\n",
      "\n",
      "step: 134600 training 0.566667            validation 0.5604\n",
      "\n",
      "step: 134650 training 0.55            validation 0.5616\n",
      "\n",
      "step: 134700 training 0.583333            validation 0.5598\n",
      "\n",
      "step: 134750 training 0.633333            validation 0.5602\n",
      "\n",
      "step: 134800 training 0.683333            validation 0.561\n",
      "\n",
      "step: 134850 training 0.55            validation 0.5594\n",
      "\n",
      "step: 134900 training 0.616667            validation 0.5608\n",
      "\n",
      "step: 134950 training 0.483333            validation 0.5612\n",
      "\n",
      "step: 135000 training 0.566667            validation 0.5598\n",
      "\n",
      "step: 135050 training 0.566667            validation 0.56\n",
      "\n",
      "step: 135100 training 0.6            validation 0.5604\n",
      "\n",
      "step: 135150 training 0.666667            validation 0.5606\n",
      "\n",
      "step: 135200 training 0.566667            validation 0.5614\n",
      "\n",
      "step: 135250 training 0.6            validation 0.5588\n",
      "\n",
      "step: 135300 training 0.483333            validation 0.5596\n",
      "\n",
      "step: 135350 training 0.516667            validation 0.5582\n",
      "\n",
      "step: 135400 training 0.616667            validation 0.5608\n",
      "\n",
      "step: 135450 training 0.583333            validation 0.5604\n",
      "\n",
      "step: 135500 training 0.583333            validation 0.56\n",
      "\n",
      "step: 135550 training 0.466667            validation 0.5586\n",
      "\n",
      "step: 135600 training 0.516667            validation 0.5596\n",
      "\n",
      "step: 135650 training 0.583333            validation 0.5618\n",
      "\n",
      "step: 135700 training 0.516667            validation 0.5612\n",
      "\n",
      "step: 135750 training 0.533333            validation 0.5604\n",
      "\n",
      "step: 135800 training 0.633333            validation 0.5602\n",
      "\n",
      "step: 135850 training 0.616667            validation 0.5592\n",
      "\n",
      "step: 135900 training 0.533333            validation 0.5608\n",
      "\n",
      "step: 135950 training 0.683333            validation 0.5578\n",
      "\n",
      "step: 136000 training 0.616667            validation 0.561\n",
      "\n",
      "step: 136050 training 0.633333            validation 0.558\n",
      "\n",
      "step: 136100 training 0.633333            validation 0.5596\n",
      "\n",
      "step: 136150 training 0.533333            validation 0.5626\n",
      "\n",
      "step: 136200 training 0.65            validation 0.5616\n",
      "\n",
      "step: 136250 training 0.633333            validation 0.5606\n",
      "\n",
      "step: 136300 training 0.616667            validation 0.5606\n",
      "\n",
      "step: 136350 training 0.583333            validation 0.559\n",
      "\n",
      "step: 136400 training 0.433333            validation 0.5594\n",
      "\n",
      "step: 136450 training 0.616667            validation 0.5608\n",
      "\n",
      "step: 136500 training 0.416667            validation 0.5586\n",
      "\n",
      "step: 136550 training 0.583333            validation 0.559\n",
      "\n",
      "step: 136600 training 0.683333            validation 0.5606\n",
      "\n",
      "step: 136650 training 0.5            validation 0.5596\n",
      "\n",
      "step: 136700 training 0.5            validation 0.5602\n",
      "\n",
      "step: 136750 training 0.616667            validation 0.5606\n",
      "\n",
      "step: 136800 training 0.5            validation 0.56\n",
      "\n",
      "step: 136850 training 0.516667            validation 0.56\n",
      "\n",
      "step: 136900 training 0.7            validation 0.561\n",
      "\n",
      "step: 136950 training 0.616667            validation 0.5612\n",
      "\n",
      "step: 137000 training 0.566667            validation 0.5596\n",
      "\n",
      "step: 137050 training 0.483333            validation 0.5616\n",
      "\n",
      "step: 137100 training 0.7            validation 0.5606\n",
      "\n",
      "step: 137150 training 0.566667            validation 0.5598\n",
      "\n",
      "step: 137200 training 0.583333            validation 0.5616\n",
      "\n",
      "step: 137250 training 0.65            validation 0.561\n",
      "\n",
      "step: 137300 training 0.566667            validation 0.5584\n",
      "\n",
      "step: 137350 training 0.533333            validation 0.5602\n",
      "\n",
      "step: 137400 training 0.616667            validation 0.5616\n",
      "\n",
      "step: 137450 training 0.566667            validation 0.5596\n",
      "\n",
      "step: 137500 training 0.4            validation 0.5592\n",
      "\n",
      "step: 137550 training 0.633333            validation 0.5594\n",
      "\n",
      "step: 137600 training 0.616667            validation 0.5598\n",
      "\n",
      "step: 137650 training 0.566667            validation 0.5622\n",
      "\n",
      "step: 137700 training 0.666667            validation 0.5612\n",
      "\n",
      "step: 137750 training 0.6            validation 0.5552\n",
      "\n",
      "step: 137800 training 0.616667            validation 0.56\n",
      "\n",
      "step: 137850 training 0.7            validation 0.5602\n",
      "\n",
      "step: 137900 training 0.6            validation 0.5608\n",
      "\n",
      "step: 137950 training 0.516667            validation 0.5592\n",
      "\n",
      "step: 138000 training 0.6            validation 0.5606\n",
      "\n",
      "step: 138050 training 0.633333            validation 0.5604\n",
      "\n",
      "step: 138100 training 0.583333            validation 0.561\n",
      "\n",
      "step: 138150 training 0.583333            validation 0.5596\n",
      "\n",
      "step: 138200 training 0.583333            validation 0.5592\n",
      "\n",
      "step: 138250 training 0.55            validation 0.5614\n",
      "\n",
      "step: 138300 training 0.533333            validation 0.5594\n",
      "\n",
      "step: 138350 training 0.516667            validation 0.5592\n",
      "\n",
      "step: 138400 training 0.516667            validation 0.561\n",
      "\n",
      "step: 138450 training 0.583333            validation 0.5606\n",
      "\n",
      "step: 138500 training 0.483333            validation 0.5586\n",
      "\n",
      "step: 138550 training 0.516667            validation 0.561\n",
      "\n",
      "step: 138600 training 0.533333            validation 0.5614\n",
      "\n",
      "step: 138650 training 0.5            validation 0.5608\n",
      "\n",
      "step: 138700 training 0.433333            validation 0.561\n",
      "\n",
      "step: 138750 training 0.533333            validation 0.5602\n",
      "\n",
      "step: 138800 training 0.55            validation 0.56\n",
      "\n",
      "step: 138850 training 0.65            validation 0.5606\n",
      "\n",
      "step: 138900 training 0.616667            validation 0.5608\n",
      "\n",
      "step: 138950 training 0.566667            validation 0.5606\n",
      "\n",
      "step: 139000 training 0.666667            validation 0.5602\n",
      "\n",
      "step: 139050 training 0.466667            validation 0.5606\n",
      "\n",
      "step: 139100 training 0.633333            validation 0.5602\n",
      "\n",
      "step: 139150 training 0.566667            validation 0.5616\n",
      "\n",
      "step: 139200 training 0.616667            validation 0.5608\n",
      "\n",
      "step: 139250 training 0.433333            validation 0.5618\n",
      "\n",
      "step: 139300 training 0.666667            validation 0.5604\n",
      "\n",
      "step: 139350 training 0.566667            validation 0.5594\n",
      "\n",
      "step: 139400 training 0.483333            validation 0.5572\n",
      "\n",
      "step: 139450 training 0.566667            validation 0.5596\n",
      "\n",
      "step: 139500 training 0.5            validation 0.5612\n",
      "\n",
      "step: 139550 training 0.65            validation 0.5612\n",
      "\n",
      "step: 139600 training 0.533333            validation 0.5616\n",
      "\n",
      "step: 139650 training 0.55            validation 0.5606\n",
      "\n",
      "step: 139700 training 0.6            validation 0.5624\n",
      "\n",
      "step: 139750 training 0.5            validation 0.56\n",
      "\n",
      "step: 139800 training 0.5            validation 0.561\n",
      "\n",
      "step: 139850 training 0.716667            validation 0.5626\n",
      "\n",
      "step: 139900 training 0.533333            validation 0.5604\n",
      "\n",
      "step: 139950 training 0.583333            validation 0.5584\n",
      "\n",
      "step: 140000 training 0.616667            validation 0.5602\n",
      "\n",
      "step: 140050 training 0.55            validation 0.5586\n",
      "\n",
      "step: 140100 training 0.7            validation 0.5604\n",
      "\n",
      "step: 140150 training 0.533333            validation 0.5614\n",
      "\n",
      "step: 140200 training 0.466667            validation 0.56\n",
      "\n",
      "step: 140250 training 0.616667            validation 0.5612\n",
      "\n",
      "step: 140300 training 0.466667            validation 0.5598\n",
      "\n",
      "step: 140350 training 0.6            validation 0.5608\n",
      "\n",
      "step: 140400 training 0.533333            validation 0.5596\n",
      "\n",
      "step: 140450 training 0.566667            validation 0.5588\n",
      "\n",
      "step: 140500 training 0.616667            validation 0.56\n",
      "\n",
      "step: 140550 training 0.616667            validation 0.5594\n",
      "\n",
      "step: 140600 training 0.55            validation 0.56\n",
      "\n",
      "step: 140650 training 0.516667            validation 0.5598\n",
      "\n",
      "step: 140700 training 0.6            validation 0.5612\n",
      "\n",
      "step: 140750 training 0.533333            validation 0.5604\n",
      "\n",
      "step: 140800 training 0.533333            validation 0.5612\n",
      "\n",
      "step: 140850 training 0.583333            validation 0.5602\n",
      "\n",
      "step: 140900 training 0.65            validation 0.5614\n",
      "\n",
      "step: 140950 training 0.566667            validation 0.5598\n",
      "\n",
      "step: 141000 training 0.4            validation 0.5598\n",
      "\n",
      "step: 141050 training 0.55            validation 0.558\n",
      "\n",
      "step: 141100 training 0.616667            validation 0.5596\n",
      "\n",
      "step: 141150 training 0.566667            validation 0.5594\n",
      "\n",
      "step: 141200 training 0.55            validation 0.5606\n",
      "\n",
      "step: 141250 training 0.533333            validation 0.5592\n",
      "\n",
      "step: 141300 training 0.566667            validation 0.5614\n",
      "\n",
      "step: 141350 training 0.683333            validation 0.5606\n",
      "\n",
      "step: 141400 training 0.666667            validation 0.5598\n",
      "\n",
      "step: 141450 training 0.433333            validation 0.5582\n",
      "\n",
      "step: 141500 training 0.516667            validation 0.5582\n",
      "\n",
      "step: 141550 training 0.483333            validation 0.5598\n",
      "\n",
      "step: 141600 training 0.683333            validation 0.56\n",
      "\n",
      "step: 141650 training 0.566667            validation 0.5608\n",
      "\n",
      "step: 141700 training 0.55            validation 0.5598\n",
      "\n",
      "step: 141750 training 0.566667            validation 0.5618\n",
      "\n",
      "step: 141800 training 0.55            validation 0.5602\n",
      "\n",
      "step: 141850 training 0.55            validation 0.5602\n",
      "\n",
      "step: 141900 training 0.516667            validation 0.5628\n",
      "\n",
      "step: 141950 training 0.55            validation 0.5596\n",
      "\n",
      "step: 142000 training 0.583333            validation 0.5606\n",
      "\n",
      "step: 142050 training 0.55            validation 0.5594\n",
      "\n",
      "step: 142100 training 0.483333            validation 0.5594\n",
      "\n",
      "step: 142150 training 0.666667            validation 0.5628\n",
      "\n",
      "step: 142200 training 0.633333            validation 0.5604\n",
      "\n",
      "step: 142250 training 0.616667            validation 0.56\n",
      "\n",
      "step: 142300 training 0.616667            validation 0.56\n",
      "\n",
      "step: 142350 training 0.566667            validation 0.5606\n",
      "\n",
      "step: 142400 training 0.55            validation 0.5606\n",
      "\n",
      "step: 142450 training 0.633333            validation 0.5618\n",
      "\n",
      "step: 142500 training 0.583333            validation 0.5608\n",
      "\n",
      "step: 142550 training 0.7            validation 0.56\n",
      "\n",
      "step: 142600 training 0.666667            validation 0.5594\n",
      "\n",
      "step: 142650 training 0.616667            validation 0.5608\n",
      "\n",
      "step: 142700 training 0.55            validation 0.5624\n",
      "\n",
      "step: 142750 training 0.533333            validation 0.5612\n",
      "\n",
      "step: 142800 training 0.516667            validation 0.5622\n",
      "\n",
      "step: 142850 training 0.6            validation 0.5564\n",
      "\n",
      "step: 142900 training 0.45            validation 0.5596\n",
      "\n",
      "step: 142950 training 0.55            validation 0.559\n",
      "\n",
      "step: 143000 training 0.616667            validation 0.5584\n",
      "\n",
      "step: 143050 training 0.6            validation 0.5612\n",
      "\n",
      "step: 143100 training 0.6            validation 0.5612\n",
      "\n",
      "step: 143150 training 0.55            validation 0.5606\n",
      "\n",
      "step: 143200 training 0.5            validation 0.559\n",
      "\n",
      "step: 143250 training 0.666667            validation 0.5622\n",
      "\n",
      "step: 143300 training 0.683333            validation 0.5592\n",
      "\n",
      "step: 143350 training 0.566667            validation 0.5598\n",
      "\n",
      "step: 143400 training 0.516667            validation 0.5602\n",
      "\n",
      "step: 143450 training 0.5            validation 0.5592\n",
      "\n",
      "step: 143500 training 0.466667            validation 0.561\n",
      "\n",
      "step: 143550 training 0.616667            validation 0.559\n",
      "\n",
      "step: 143600 training 0.55            validation 0.559\n",
      "\n",
      "step: 143650 training 0.566667            validation 0.56\n",
      "\n",
      "step: 143700 training 0.516667            validation 0.5612\n",
      "\n",
      "step: 143750 training 0.583333            validation 0.5602\n",
      "\n",
      "step: 143800 training 0.55            validation 0.558\n",
      "\n",
      "step: 143850 training 0.583333            validation 0.5612\n",
      "\n",
      "step: 143900 training 0.55            validation 0.56\n",
      "\n",
      "step: 143950 training 0.6            validation 0.558\n",
      "\n",
      "step: 144000 training 0.583333            validation 0.5618\n",
      "\n",
      "step: 144050 training 0.533333            validation 0.5602\n",
      "\n",
      "step: 144100 training 0.616667            validation 0.5598\n",
      "\n",
      "step: 144150 training 0.55            validation 0.561\n",
      "\n",
      "step: 144200 training 0.55            validation 0.5616\n",
      "\n",
      "step: 144250 training 0.6            validation 0.5604\n",
      "\n",
      "step: 144300 training 0.583333            validation 0.5584\n",
      "\n",
      "step: 144350 training 0.616667            validation 0.559\n",
      "\n",
      "step: 144400 training 0.516667            validation 0.5604\n",
      "\n",
      "step: 144450 training 0.633333            validation 0.5614\n",
      "\n",
      "step: 144500 training 0.583333            validation 0.5608\n",
      "\n",
      "step: 144550 training 0.5            validation 0.5608\n",
      "\n",
      "step: 144600 training 0.533333            validation 0.561\n",
      "\n",
      "step: 144650 training 0.7            validation 0.559\n",
      "\n",
      "step: 144700 training 0.65            validation 0.5624\n",
      "\n",
      "step: 144750 training 0.583333            validation 0.5606\n",
      "\n",
      "step: 144800 training 0.6            validation 0.5592\n",
      "\n",
      "step: 144850 training 0.616667            validation 0.5598\n",
      "\n",
      "step: 144900 training 0.633333            validation 0.5596\n",
      "\n",
      "step: 144950 training 0.5            validation 0.5592\n",
      "\n",
      "step: 145000 training 0.583333            validation 0.5582\n",
      "\n",
      "step: 145050 training 0.533333            validation 0.557\n",
      "\n",
      "step: 145100 training 0.6            validation 0.5588\n",
      "\n",
      "step: 145150 training 0.466667            validation 0.5574\n",
      "\n",
      "step: 145200 training 0.6            validation 0.562\n",
      "\n",
      "step: 145250 training 0.533333            validation 0.5596\n",
      "\n",
      "step: 145300 training 0.533333            validation 0.5582\n",
      "\n",
      "step: 145350 training 0.483333            validation 0.5596\n",
      "\n",
      "step: 145400 training 0.6            validation 0.558\n",
      "\n",
      "step: 145450 training 0.7            validation 0.5596\n",
      "\n",
      "step: 145500 training 0.533333            validation 0.5612\n",
      "\n",
      "step: 145550 training 0.6            validation 0.5582\n",
      "\n",
      "step: 145600 training 0.533333            validation 0.56\n",
      "\n",
      "step: 145650 training 0.516667            validation 0.561\n",
      "\n",
      "step: 145700 training 0.566667            validation 0.5608\n",
      "\n",
      "step: 145750 training 0.65            validation 0.5604\n",
      "\n",
      "step: 145800 training 0.633333            validation 0.5594\n",
      "\n",
      "step: 145850 training 0.566667            validation 0.5592\n",
      "\n",
      "step: 145900 training 0.7            validation 0.5608\n",
      "\n",
      "step: 145950 training 0.5            validation 0.5602\n",
      "\n",
      "step: 146000 training 0.483333            validation 0.5592\n",
      "\n",
      "step: 146050 training 0.5            validation 0.5602\n",
      "\n",
      "step: 146100 training 0.5            validation 0.5588\n",
      "\n",
      "step: 146150 training 0.55            validation 0.5576\n",
      "\n",
      "step: 146200 training 0.583333            validation 0.56\n",
      "\n",
      "step: 146250 training 0.483333            validation 0.561\n",
      "\n",
      "step: 146300 training 0.583333            validation 0.5592\n",
      "\n",
      "step: 146350 training 0.516667            validation 0.5598\n",
      "\n",
      "step: 146400 training 0.616667            validation 0.5606\n",
      "\n",
      "step: 146450 training 0.666667            validation 0.561\n",
      "\n",
      "step: 146500 training 0.483333            validation 0.5614\n",
      "\n",
      "step: 146550 training 0.683333            validation 0.5614\n",
      "\n",
      "step: 146600 training 0.566667            validation 0.56\n",
      "\n",
      "step: 146650 training 0.65            validation 0.5584\n",
      "\n",
      "step: 146700 training 0.6            validation 0.5592\n",
      "\n",
      "step: 146750 training 0.533333            validation 0.5626\n",
      "\n",
      "step: 146800 training 0.633333            validation 0.5612\n",
      "\n",
      "step: 146850 training 0.533333            validation 0.5594\n",
      "\n",
      "step: 146900 training 0.533333            validation 0.5622\n",
      "\n",
      "step: 146950 training 0.65            validation 0.5604\n",
      "\n",
      "step: 147000 training 0.516667            validation 0.559\n",
      "\n",
      "step: 147050 training 0.616667            validation 0.5604\n",
      "\n",
      "step: 147100 training 0.5            validation 0.5592\n",
      "\n",
      "step: 147150 training 0.466667            validation 0.559\n",
      "\n",
      "step: 147200 training 0.6            validation 0.563\n",
      "\n",
      "step: 147250 training 0.533333            validation 0.5614\n",
      "\n",
      "step: 147300 training 0.55            validation 0.5608\n",
      "\n",
      "step: 147350 training 0.616667            validation 0.5596\n",
      "\n",
      "step: 147400 training 0.583333            validation 0.5612\n",
      "\n",
      "step: 147450 training 0.55            validation 0.5602\n",
      "\n",
      "step: 147500 training 0.5            validation 0.562\n",
      "\n",
      "step: 147550 training 0.533333            validation 0.5608\n",
      "\n",
      "step: 147600 training 0.65            validation 0.56\n",
      "\n",
      "step: 147650 training 0.533333            validation 0.5602\n",
      "\n",
      "step: 147700 training 0.5            validation 0.5604\n",
      "\n",
      "step: 147750 training 0.533333            validation 0.5596\n",
      "\n",
      "step: 147800 training 0.65            validation 0.5618\n",
      "\n",
      "step: 147850 training 0.55            validation 0.5614\n",
      "\n",
      "step: 147900 training 0.583333            validation 0.5596\n",
      "\n",
      "step: 147950 training 0.583333            validation 0.561\n",
      "\n",
      "step: 148000 training 0.5            validation 0.5604\n",
      "\n",
      "step: 148050 training 0.55            validation 0.561\n",
      "\n",
      "step: 148100 training 0.533333            validation 0.56\n",
      "\n",
      "step: 148150 training 0.633333            validation 0.5586\n",
      "\n",
      "step: 148200 training 0.566667            validation 0.5584\n",
      "\n",
      "step: 148250 training 0.55            validation 0.5612\n",
      "\n",
      "step: 148300 training 0.583333            validation 0.5598\n",
      "\n",
      "step: 148350 training 0.483333            validation 0.5612\n",
      "\n",
      "step: 148400 training 0.5            validation 0.56\n",
      "\n",
      "step: 148450 training 0.65            validation 0.5588\n",
      "\n",
      "step: 148500 training 0.516667            validation 0.5594\n",
      "\n",
      "step: 148550 training 0.466667            validation 0.5598\n",
      "\n",
      "step: 148600 training 0.566667            validation 0.5588\n",
      "\n",
      "step: 148650 training 0.7            validation 0.5602\n",
      "\n",
      "step: 148700 training 0.466667            validation 0.5556\n",
      "\n",
      "step: 148750 training 0.616667            validation 0.559\n",
      "\n",
      "step: 148800 training 0.6            validation 0.561\n",
      "\n",
      "step: 148850 training 0.6            validation 0.5598\n",
      "\n",
      "step: 148900 training 0.566667            validation 0.5598\n",
      "\n",
      "step: 148950 training 0.683333            validation 0.558\n",
      "\n",
      "step: 149000 training 0.55            validation 0.5592\n",
      "\n",
      "step: 149050 training 0.55            validation 0.5598\n",
      "\n",
      "step: 149100 training 0.516667            validation 0.5602\n",
      "\n",
      "step: 149150 training 0.6            validation 0.5602\n",
      "\n",
      "step: 149200 training 0.5            validation 0.5584\n",
      "\n",
      "step: 149250 training 0.55            validation 0.5596\n",
      "\n",
      "step: 149300 training 0.55            validation 0.5604\n",
      "\n",
      "step: 149350 training 0.55            validation 0.5594\n",
      "\n",
      "step: 149400 training 0.616667            validation 0.561\n",
      "\n",
      "step: 149450 training 0.6            validation 0.559\n",
      "\n",
      "step: 149500 training 0.5            validation 0.5598\n",
      "\n",
      "step: 149550 training 0.55            validation 0.5608\n",
      "\n",
      "step: 149600 training 0.566667            validation 0.5606\n",
      "\n",
      "step: 149650 training 0.6            validation 0.56\n",
      "\n",
      "step: 149700 training 0.583333            validation 0.5604\n",
      "\n",
      "step: 149750 training 0.666667            validation 0.5592\n",
      "\n",
      "step: 149800 training 0.533333            validation 0.5592\n",
      "\n",
      "step: 149850 training 0.533333            validation 0.5596\n",
      "\n",
      "step: 149900 training 0.566667            validation 0.5606\n",
      "\n",
      "step: 149950 training 0.55            validation 0.5598\n",
      "\n",
      "step: 150000 training 0.583333            validation 0.56\n",
      "\n",
      "step: 150050 training 0.583333            validation 0.5602\n",
      "\n",
      "step: 150100 training 0.55            validation 0.5586\n",
      "\n",
      "step: 150150 training 0.533333            validation 0.5588\n",
      "\n",
      "step: 150200 training 0.6            validation 0.5592\n",
      "\n",
      "step: 150250 training 0.5            validation 0.5582\n",
      "\n",
      "step: 150300 training 0.516667            validation 0.5602\n",
      "\n",
      "step: 150350 training 0.566667            validation 0.5608\n",
      "\n",
      "step: 150400 training 0.666667            validation 0.56\n",
      "\n",
      "step: 150450 training 0.65            validation 0.5614\n",
      "\n",
      "step: 150500 training 0.55            validation 0.561\n",
      "\n",
      "step: 150550 training 0.5            validation 0.5606\n",
      "\n",
      "step: 150600 training 0.7            validation 0.5582\n",
      "\n",
      "step: 150650 training 0.483333            validation 0.561\n",
      "\n",
      "step: 150700 training 0.566667            validation 0.5608\n",
      "\n",
      "step: 150750 training 0.583333            validation 0.5608\n",
      "\n",
      "step: 150800 training 0.583333            validation 0.5598\n",
      "\n",
      "step: 150850 training 0.5            validation 0.5594\n",
      "\n",
      "step: 150900 training 0.683333            validation 0.5578\n",
      "\n",
      "step: 150950 training 0.583333            validation 0.5598\n",
      "\n",
      "step: 151000 training 0.583333            validation 0.5594\n",
      "\n",
      "step: 151050 training 0.683333            validation 0.5596\n",
      "\n",
      "step: 151100 training 0.666667            validation 0.5604\n",
      "\n",
      "step: 151150 training 0.55            validation 0.5606\n",
      "\n",
      "step: 151200 training 0.583333            validation 0.5592\n",
      "\n",
      "step: 151250 training 0.65            validation 0.559\n",
      "\n",
      "step: 151300 training 0.5            validation 0.561\n",
      "\n",
      "step: 151350 training 0.65            validation 0.5584\n",
      "\n",
      "step: 151400 training 0.616667            validation 0.5584\n",
      "\n",
      "step: 151450 training 0.65            validation 0.5602\n",
      "\n",
      "step: 151500 training 0.533333            validation 0.5592\n",
      "\n",
      "step: 151550 training 0.666667            validation 0.5616\n",
      "\n",
      "step: 151600 training 0.483333            validation 0.5598\n",
      "\n",
      "step: 151650 training 0.616667            validation 0.56\n",
      "\n",
      "step: 151700 training 0.533333            validation 0.5592\n",
      "\n",
      "step: 151750 training 0.516667            validation 0.561\n",
      "\n",
      "step: 151800 training 0.65            validation 0.5616\n",
      "\n",
      "step: 151850 training 0.633333            validation 0.5608\n",
      "\n",
      "step: 151900 training 0.583333            validation 0.56\n",
      "\n",
      "step: 151950 training 0.55            validation 0.562\n",
      "\n",
      "step: 152000 training 0.516667            validation 0.5596\n",
      "\n",
      "step: 152050 training 0.55            validation 0.5612\n",
      "\n",
      "step: 152100 training 0.55            validation 0.5598\n",
      "\n",
      "step: 152150 training 0.666667            validation 0.5608\n",
      "\n",
      "step: 152200 training 0.616667            validation 0.5624\n",
      "\n",
      "step: 152250 training 0.5            validation 0.5614\n",
      "\n",
      "step: 152300 training 0.55            validation 0.5608\n",
      "\n",
      "step: 152350 training 0.583333            validation 0.5614\n",
      "\n",
      "step: 152400 training 0.566667            validation 0.5614\n",
      "\n",
      "step: 152450 training 0.566667            validation 0.5602\n",
      "\n",
      "step: 152500 training 0.5            validation 0.5614\n",
      "\n",
      "step: 152550 training 0.566667            validation 0.5614\n",
      "\n",
      "step: 152600 training 0.65            validation 0.5614\n",
      "\n",
      "step: 152650 training 0.566667            validation 0.5594\n",
      "\n",
      "step: 152700 training 0.666667            validation 0.5614\n",
      "\n",
      "step: 152750 training 0.633333            validation 0.56\n",
      "\n",
      "step: 152800 training 0.55            validation 0.56\n",
      "\n",
      "step: 152850 training 0.6            validation 0.561\n",
      "\n",
      "step: 152900 training 0.5            validation 0.5588\n",
      "\n",
      "step: 152950 training 0.533333            validation 0.5598\n",
      "\n",
      "step: 153000 training 0.566667            validation 0.56\n",
      "\n",
      "step: 153050 training 0.55            validation 0.561\n",
      "\n",
      "step: 153100 training 0.483333            validation 0.5604\n",
      "\n",
      "step: 153150 training 0.633333            validation 0.5596\n",
      "\n",
      "step: 153200 training 0.616667            validation 0.561\n",
      "\n",
      "step: 153250 training 0.483333            validation 0.56\n",
      "\n",
      "step: 153300 training 0.583333            validation 0.5588\n",
      "\n",
      "step: 153350 training 0.583333            validation 0.5592\n",
      "\n",
      "step: 153400 training 0.616667            validation 0.5616\n",
      "\n",
      "step: 153450 training 0.533333            validation 0.561\n",
      "\n",
      "step: 153500 training 0.433333            validation 0.5596\n",
      "\n",
      "step: 153550 training 0.683333            validation 0.5624\n",
      "\n",
      "step: 153600 training 0.6            validation 0.559\n",
      "\n",
      "step: 153650 training 0.583333            validation 0.5586\n",
      "\n",
      "step: 153700 training 0.583333            validation 0.5592\n",
      "\n",
      "step: 153750 training 0.7            validation 0.5612\n",
      "\n",
      "step: 153800 training 0.483333            validation 0.5612\n",
      "\n",
      "step: 153850 training 0.616667            validation 0.5602\n",
      "\n",
      "step: 153900 training 0.65            validation 0.5602\n",
      "\n",
      "step: 153950 training 0.6            validation 0.5598\n",
      "\n",
      "step: 154000 training 0.633333            validation 0.5586\n",
      "\n",
      "step: 154050 training 0.583333            validation 0.5592\n",
      "\n",
      "step: 154100 training 0.6            validation 0.5612\n",
      "\n",
      "step: 154150 training 0.583333            validation 0.5614\n",
      "\n",
      "step: 154200 training 0.5            validation 0.5604\n",
      "\n",
      "step: 154250 training 0.633333            validation 0.5602\n",
      "\n",
      "step: 154300 training 0.566667            validation 0.5604\n",
      "\n",
      "step: 154350 training 0.566667            validation 0.5588\n",
      "\n",
      "step: 154400 training 0.466667            validation 0.5598\n",
      "\n",
      "step: 154450 training 0.583333            validation 0.5606\n",
      "\n",
      "step: 154500 training 0.583333            validation 0.5578\n",
      "\n",
      "step: 154550 training 0.4            validation 0.5614\n",
      "\n",
      "step: 154600 training 0.616667            validation 0.5602\n",
      "\n",
      "step: 154650 training 0.516667            validation 0.5592\n",
      "\n",
      "step: 154700 training 0.6            validation 0.5606\n",
      "\n",
      "step: 154750 training 0.566667            validation 0.5588\n",
      "\n",
      "step: 154800 training 0.633333            validation 0.561\n",
      "\n",
      "step: 154850 training 0.65            validation 0.5618\n",
      "\n",
      "step: 154900 training 0.533333            validation 0.5602\n",
      "\n",
      "step: 154950 training 0.616667            validation 0.5582\n",
      "\n",
      "step: 155000 training 0.55            validation 0.5588\n",
      "\n",
      "step: 155050 training 0.533333            validation 0.5594\n",
      "\n",
      "step: 155100 training 0.55            validation 0.5592\n",
      "\n",
      "step: 155150 training 0.533333            validation 0.5592\n",
      "\n",
      "step: 155200 training 0.566667            validation 0.5626\n",
      "\n",
      "step: 155250 training 0.55            validation 0.5574\n",
      "\n",
      "step: 155300 training 0.45            validation 0.5604\n",
      "\n",
      "step: 155350 training 0.7            validation 0.56\n",
      "\n",
      "step: 155400 training 0.633333            validation 0.5598\n",
      "\n",
      "step: 155450 training 0.7            validation 0.5592\n",
      "\n",
      "step: 155500 training 0.583333            validation 0.5604\n",
      "\n",
      "step: 155550 training 0.583333            validation 0.5606\n",
      "\n",
      "step: 155600 training 0.65            validation 0.5612\n",
      "\n",
      "step: 155650 training 0.683333            validation 0.5608\n",
      "\n",
      "step: 155700 training 0.6            validation 0.561\n",
      "\n",
      "step: 155750 training 0.55            validation 0.559\n",
      "\n",
      "step: 155800 training 0.55            validation 0.559\n",
      "\n",
      "step: 155850 training 0.566667            validation 0.5566\n",
      "\n",
      "step: 155900 training 0.566667            validation 0.5598\n",
      "\n",
      "step: 155950 training 0.566667            validation 0.5604\n",
      "\n",
      "step: 156000 training 0.583333            validation 0.5614\n",
      "\n",
      "step: 156050 training 0.483333            validation 0.5578\n",
      "\n",
      "step: 156100 training 0.533333            validation 0.5586\n",
      "\n",
      "step: 156150 training 0.666667            validation 0.5606\n",
      "\n",
      "step: 156200 training 0.65            validation 0.5588\n",
      "\n",
      "step: 156250 training 0.55            validation 0.5612\n",
      "\n",
      "step: 156300 training 0.516667            validation 0.5624\n",
      "\n",
      "step: 156350 training 0.616667            validation 0.5588\n",
      "\n",
      "step: 156400 training 0.55            validation 0.5604\n",
      "\n",
      "step: 156450 training 0.616667            validation 0.5608\n",
      "\n",
      "step: 156500 training 0.566667            validation 0.5612\n",
      "\n",
      "step: 156550 training 0.55            validation 0.56\n",
      "\n",
      "step: 156600 training 0.616667            validation 0.5608\n",
      "\n",
      "step: 156650 training 0.55            validation 0.5574\n",
      "\n",
      "step: 156700 training 0.633333            validation 0.5602\n",
      "\n",
      "step: 156750 training 0.683333            validation 0.5608\n",
      "\n",
      "step: 156800 training 0.566667            validation 0.5616\n",
      "\n",
      "step: 156850 training 0.65            validation 0.5596\n",
      "\n",
      "step: 156900 training 0.633333            validation 0.5584\n",
      "\n",
      "step: 156950 training 0.6            validation 0.5586\n",
      "\n",
      "step: 157000 training 0.583333            validation 0.5608\n",
      "\n",
      "step: 157050 training 0.55            validation 0.5598\n",
      "\n",
      "step: 157100 training 0.55            validation 0.5616\n",
      "\n",
      "step: 157150 training 0.616667            validation 0.5602\n",
      "\n",
      "step: 157200 training 0.5            validation 0.5612\n",
      "\n",
      "step: 157250 training 0.633333            validation 0.5634\n",
      "\n",
      "step: 157300 training 0.583333            validation 0.5632\n",
      "\n",
      "step: 157350 training 0.566667            validation 0.5612\n",
      "\n",
      "step: 157400 training 0.6            validation 0.56\n",
      "\n",
      "step: 157450 training 0.6            validation 0.5604\n",
      "\n",
      "step: 157500 training 0.483333            validation 0.561\n",
      "\n",
      "step: 157550 training 0.716667            validation 0.5586\n",
      "\n",
      "step: 157600 training 0.583333            validation 0.5602\n",
      "\n",
      "step: 157650 training 0.5            validation 0.5578\n",
      "\n",
      "step: 157700 training 0.533333            validation 0.5606\n",
      "\n",
      "step: 157750 training 0.583333            validation 0.5584\n",
      "\n",
      "step: 157800 training 0.55            validation 0.5614\n",
      "\n",
      "step: 157850 training 0.55            validation 0.56\n",
      "\n",
      "step: 157900 training 0.45            validation 0.559\n",
      "\n",
      "step: 157950 training 0.55            validation 0.5598\n",
      "\n",
      "step: 158000 training 0.616667            validation 0.5598\n",
      "\n",
      "step: 158050 training 0.633333            validation 0.5596\n",
      "\n",
      "step: 158100 training 0.516667            validation 0.5604\n",
      "\n",
      "step: 158150 training 0.633333            validation 0.5608\n",
      "\n",
      "step: 158200 training 0.65            validation 0.559\n",
      "\n",
      "step: 158250 training 0.6            validation 0.561\n",
      "\n",
      "step: 158300 training 0.583333            validation 0.5598\n",
      "\n",
      "step: 158350 training 0.55            validation 0.5624\n",
      "\n",
      "step: 158400 training 0.583333            validation 0.5596\n",
      "\n",
      "step: 158450 training 0.566667            validation 0.5582\n",
      "\n",
      "step: 158500 training 0.516667            validation 0.5598\n",
      "\n",
      "step: 158550 training 0.616667            validation 0.5612\n",
      "\n",
      "step: 158600 training 0.566667            validation 0.5622\n",
      "\n",
      "step: 158650 training 0.6            validation 0.5592\n",
      "\n",
      "step: 158700 training 0.466667            validation 0.5604\n",
      "\n",
      "step: 158750 training 0.483333            validation 0.5592\n",
      "\n",
      "step: 158800 training 0.566667            validation 0.56\n",
      "\n",
      "step: 158850 training 0.533333            validation 0.56\n",
      "\n",
      "step: 158900 training 0.566667            validation 0.5604\n",
      "\n",
      "step: 158950 training 0.616667            validation 0.5594\n",
      "\n",
      "step: 159000 training 0.583333            validation 0.5608\n",
      "\n",
      "step: 159050 training 0.5            validation 0.5608\n",
      "\n",
      "step: 159100 training 0.516667            validation 0.5608\n",
      "\n",
      "step: 159150 training 0.566667            validation 0.5608\n",
      "\n",
      "step: 159200 training 0.633333            validation 0.5598\n",
      "\n",
      "step: 159250 training 0.566667            validation 0.56\n",
      "\n",
      "step: 159300 training 0.566667            validation 0.5592\n",
      "\n",
      "step: 159350 training 0.533333            validation 0.5604\n",
      "\n",
      "step: 159400 training 0.6            validation 0.56\n",
      "\n",
      "step: 159450 training 0.6            validation 0.56\n",
      "\n",
      "step: 159500 training 0.616667            validation 0.5604\n",
      "\n",
      "step: 159550 training 0.55            validation 0.5618\n",
      "\n",
      "step: 159600 training 0.6            validation 0.5596\n",
      "\n",
      "step: 159650 training 0.483333            validation 0.5608\n",
      "\n",
      "step: 159700 training 0.533333            validation 0.5608\n",
      "\n",
      "step: 159750 training 0.65            validation 0.5592\n",
      "\n",
      "step: 159800 training 0.616667            validation 0.559\n",
      "\n",
      "step: 159850 training 0.583333            validation 0.561\n",
      "\n",
      "step: 159900 training 0.566667            validation 0.561\n",
      "\n",
      "step: 159950 training 0.416667            validation 0.5614\n",
      "\n",
      "step: 160000 training 0.6            validation 0.5602\n",
      "\n",
      "step: 160050 training 0.566667            validation 0.5592\n",
      "\n",
      "step: 160100 training 0.566667            validation 0.5614\n",
      "\n",
      "step: 160150 training 0.633333            validation 0.559\n",
      "\n",
      "step: 160200 training 0.633333            validation 0.5592\n",
      "\n",
      "step: 160250 training 0.6            validation 0.5606\n",
      "\n",
      "step: 160300 training 0.55            validation 0.5582\n",
      "\n",
      "step: 160350 training 0.6            validation 0.5584\n",
      "\n",
      "step: 160400 training 0.583333            validation 0.5592\n",
      "\n",
      "step: 160450 training 0.516667            validation 0.5598\n",
      "\n",
      "step: 160500 training 0.583333            validation 0.5586\n",
      "\n",
      "step: 160550 training 0.583333            validation 0.5594\n",
      "\n",
      "step: 160600 training 0.633333            validation 0.5602\n",
      "\n",
      "step: 160650 training 0.516667            validation 0.5594\n",
      "\n",
      "step: 160700 training 0.666667            validation 0.56\n",
      "\n",
      "step: 160750 training 0.616667            validation 0.5592\n",
      "\n",
      "step: 160800 training 0.65            validation 0.5604\n",
      "\n",
      "step: 160850 training 0.583333            validation 0.5592\n",
      "\n",
      "step: 160900 training 0.6            validation 0.559\n",
      "\n",
      "step: 160950 training 0.55            validation 0.5596\n",
      "\n",
      "step: 161000 training 0.566667            validation 0.5604\n",
      "\n",
      "step: 161050 training 0.533333            validation 0.5596\n",
      "\n",
      "step: 161100 training 0.6            validation 0.5592\n",
      "\n",
      "step: 161150 training 0.65            validation 0.5596\n",
      "\n",
      "step: 161200 training 0.65            validation 0.5618\n",
      "\n",
      "step: 161250 training 0.616667            validation 0.5598\n",
      "\n",
      "step: 161300 training 0.516667            validation 0.5602\n",
      "\n",
      "step: 161350 training 0.55            validation 0.5612\n",
      "\n",
      "step: 161400 training 0.583333            validation 0.56\n",
      "\n",
      "step: 161450 training 0.6            validation 0.5602\n",
      "\n",
      "step: 161500 training 0.6            validation 0.5584\n",
      "\n",
      "step: 161550 training 0.583333            validation 0.5616\n",
      "\n",
      "step: 161600 training 0.6            validation 0.5586\n",
      "\n",
      "step: 161650 training 0.516667            validation 0.5588\n",
      "\n",
      "step: 161700 training 0.666667            validation 0.5592\n",
      "\n",
      "step: 161750 training 0.6            validation 0.5588\n",
      "\n",
      "step: 161800 training 0.633333            validation 0.56\n",
      "\n",
      "step: 161850 training 0.583333            validation 0.5584\n",
      "\n",
      "step: 161900 training 0.55            validation 0.5594\n",
      "\n",
      "step: 161950 training 0.7            validation 0.5592\n",
      "\n",
      "step: 162000 training 0.65            validation 0.5598\n",
      "\n",
      "step: 162050 training 0.683333            validation 0.5598\n",
      "\n",
      "step: 162100 training 0.55            validation 0.5612\n",
      "\n",
      "step: 162150 training 0.583333            validation 0.5586\n",
      "\n",
      "step: 162200 training 0.566667            validation 0.5598\n",
      "\n",
      "step: 162250 training 0.55            validation 0.5592\n",
      "\n",
      "step: 162300 training 0.483333            validation 0.56\n",
      "\n",
      "step: 162350 training 0.533333            validation 0.5596\n",
      "\n",
      "step: 162400 training 0.533333            validation 0.5578\n",
      "\n",
      "step: 162450 training 0.583333            validation 0.5598\n",
      "\n",
      "step: 162500 training 0.516667            validation 0.5596\n",
      "\n",
      "step: 162550 training 0.5            validation 0.5594\n",
      "\n",
      "step: 162600 training 0.533333            validation 0.5592\n",
      "\n",
      "step: 162650 training 0.583333            validation 0.5598\n",
      "\n",
      "step: 162700 training 0.6            validation 0.5574\n",
      "\n",
      "step: 162750 training 0.716667            validation 0.56\n",
      "\n",
      "step: 162800 training 0.6            validation 0.5606\n",
      "\n",
      "step: 162850 training 0.583333            validation 0.5598\n",
      "\n",
      "step: 162900 training 0.516667            validation 0.5592\n",
      "\n",
      "step: 162950 training 0.616667            validation 0.5606\n",
      "\n",
      "step: 163000 training 0.466667            validation 0.5598\n",
      "\n",
      "step: 163050 training 0.666667            validation 0.5614\n",
      "\n",
      "step: 163100 training 0.6            validation 0.5586\n",
      "\n",
      "step: 163150 training 0.633333            validation 0.5594\n",
      "\n",
      "step: 163200 training 0.65            validation 0.5574\n",
      "\n",
      "step: 163250 training 0.516667            validation 0.5604\n",
      "\n",
      "step: 163300 training 0.583333            validation 0.56\n",
      "\n",
      "step: 163350 training 0.683333            validation 0.5594\n",
      "\n",
      "step: 163400 training 0.616667            validation 0.5594\n",
      "\n",
      "step: 163450 training 0.566667            validation 0.5592\n",
      "\n",
      "step: 163500 training 0.583333            validation 0.56\n",
      "\n",
      "step: 163550 training 0.483333            validation 0.5582\n",
      "\n",
      "step: 163600 training 0.55            validation 0.5596\n",
      "\n",
      "step: 163650 training 0.666667            validation 0.5588\n",
      "\n",
      "step: 163700 training 0.65            validation 0.5588\n",
      "\n",
      "step: 163750 training 0.666667            validation 0.5598\n",
      "\n",
      "step: 163800 training 0.55            validation 0.56\n",
      "\n",
      "step: 163850 training 0.65            validation 0.5614\n",
      "\n",
      "step: 163900 training 0.666667            validation 0.5594\n",
      "\n",
      "step: 163950 training 0.6            validation 0.5592\n",
      "\n",
      "step: 164000 training 0.616667            validation 0.559\n",
      "\n",
      "step: 164050 training 0.6            validation 0.5606\n",
      "\n",
      "step: 164100 training 0.416667            validation 0.56\n",
      "\n",
      "step: 164150 training 0.6            validation 0.5582\n",
      "\n",
      "step: 164200 training 0.55            validation 0.5602\n",
      "\n",
      "step: 164250 training 0.566667            validation 0.5604\n",
      "\n",
      "step: 164300 training 0.65            validation 0.559\n",
      "\n",
      "step: 164350 training 0.433333            validation 0.5594\n",
      "\n",
      "step: 164400 training 0.433333            validation 0.5596\n",
      "\n",
      "step: 164450 training 0.533333            validation 0.5602\n",
      "\n",
      "step: 164500 training 0.616667            validation 0.5604\n",
      "\n",
      "step: 164550 training 0.7            validation 0.559\n",
      "\n",
      "step: 164600 training 0.55            validation 0.5584\n",
      "\n",
      "step: 164650 training 0.533333            validation 0.5596\n",
      "\n",
      "step: 164700 training 0.6            validation 0.5598\n",
      "\n",
      "step: 164750 training 0.65            validation 0.5592\n",
      "\n",
      "step: 164800 training 0.55            validation 0.559\n",
      "\n",
      "step: 164850 training 0.566667            validation 0.5594\n",
      "\n",
      "step: 164900 training 0.533333            validation 0.5586\n",
      "\n",
      "step: 164950 training 0.433333            validation 0.5598\n",
      "\n",
      "step: 165000 training 0.55            validation 0.5598\n",
      "\n",
      "step: 165050 training 0.683333            validation 0.5604\n",
      "\n",
      "step: 165100 training 0.616667            validation 0.56\n",
      "\n",
      "step: 165150 training 0.433333            validation 0.5602\n",
      "\n",
      "step: 165200 training 0.583333            validation 0.5606\n",
      "\n",
      "step: 165250 training 0.633333            validation 0.5612\n",
      "\n",
      "step: 165300 training 0.566667            validation 0.5604\n",
      "\n",
      "step: 165350 training 0.55            validation 0.5598\n",
      "\n",
      "step: 165400 training 0.583333            validation 0.559\n",
      "\n",
      "step: 165450 training 0.516667            validation 0.5592\n",
      "\n",
      "step: 165500 training 0.616667            validation 0.558\n",
      "\n",
      "step: 165550 training 0.516667            validation 0.5578\n",
      "\n",
      "step: 165600 training 0.616667            validation 0.559\n",
      "\n",
      "step: 165650 training 0.516667            validation 0.559\n",
      "\n",
      "step: 165700 training 0.583333            validation 0.5578\n",
      "\n",
      "step: 165750 training 0.583333            validation 0.5598\n",
      "\n",
      "step: 165800 training 0.666667            validation 0.558\n",
      "\n",
      "step: 165850 training 0.583333            validation 0.5592\n",
      "\n",
      "step: 165900 training 0.566667            validation 0.5596\n",
      "\n",
      "step: 165950 training 0.45            validation 0.5592\n",
      "\n",
      "step: 166000 training 0.6            validation 0.5584\n",
      "\n",
      "step: 166050 training 0.666667            validation 0.5586\n",
      "\n",
      "step: 166100 training 0.6            validation 0.559\n",
      "\n",
      "step: 166150 training 0.65            validation 0.5586\n",
      "\n",
      "step: 166200 training 0.566667            validation 0.5588\n",
      "\n",
      "step: 166250 training 0.583333            validation 0.558\n",
      "\n",
      "step: 166300 training 0.6            validation 0.559\n",
      "\n",
      "step: 166350 training 0.6            validation 0.5616\n",
      "\n",
      "step: 166400 training 0.6            validation 0.5584\n",
      "\n",
      "step: 166450 training 0.566667            validation 0.5606\n",
      "\n",
      "step: 166500 training 0.466667            validation 0.5592\n",
      "\n",
      "step: 166550 training 0.633333            validation 0.5584\n",
      "\n",
      "step: 166600 training 0.533333            validation 0.56\n",
      "\n",
      "step: 166650 training 0.6            validation 0.5586\n",
      "\n",
      "step: 166700 training 0.5            validation 0.5584\n",
      "\n",
      "step: 166750 training 0.566667            validation 0.5582\n",
      "\n",
      "step: 166800 training 0.55            validation 0.5598\n",
      "\n",
      "step: 166850 training 0.7            validation 0.5586\n",
      "\n",
      "step: 166900 training 0.683333            validation 0.5574\n",
      "\n",
      "step: 166950 training 0.666667            validation 0.5604\n",
      "\n",
      "step: 167000 training 0.483333            validation 0.559\n",
      "\n",
      "step: 167050 training 0.583333            validation 0.5596\n",
      "\n",
      "step: 167100 training 0.616667            validation 0.5604\n",
      "\n",
      "step: 167150 training 0.533333            validation 0.5606\n",
      "\n",
      "step: 167200 training 0.483333            validation 0.5596\n",
      "\n",
      "step: 167250 training 0.6            validation 0.5584\n",
      "\n",
      "step: 167300 training 0.466667            validation 0.5596\n",
      "\n",
      "step: 167350 training 0.55            validation 0.5586\n",
      "\n",
      "step: 167400 training 0.45            validation 0.558\n",
      "\n",
      "step: 167450 training 0.583333            validation 0.561\n",
      "\n",
      "step: 167500 training 0.6            validation 0.5596\n",
      "\n",
      "step: 167550 training 0.616667            validation 0.5608\n",
      "\n",
      "step: 167600 training 0.5            validation 0.5598\n",
      "\n",
      "step: 167650 training 0.516667            validation 0.56\n",
      "\n",
      "step: 167700 training 0.633333            validation 0.5588\n",
      "\n",
      "step: 167750 training 0.533333            validation 0.5588\n",
      "\n",
      "step: 167800 training 0.683333            validation 0.5594\n",
      "\n",
      "step: 167850 training 0.6            validation 0.5622\n",
      "\n",
      "step: 167900 training 0.466667            validation 0.5594\n",
      "\n",
      "step: 167950 training 0.516667            validation 0.5604\n",
      "\n",
      "step: 168000 training 0.616667            validation 0.56\n",
      "\n",
      "step: 168050 training 0.6            validation 0.56\n",
      "\n",
      "step: 168100 training 0.583333            validation 0.5606\n",
      "\n",
      "step: 168150 training 0.583333            validation 0.56\n",
      "\n",
      "step: 168200 training 0.5            validation 0.5604\n",
      "\n",
      "step: 168250 training 0.483333            validation 0.5606\n",
      "\n",
      "step: 168300 training 0.65            validation 0.5606\n",
      "\n",
      "step: 168350 training 0.516667            validation 0.5598\n",
      "\n",
      "step: 168400 training 0.566667            validation 0.5588\n",
      "\n",
      "step: 168450 training 0.533333            validation 0.5578\n",
      "\n",
      "step: 168500 training 0.45            validation 0.5592\n",
      "\n",
      "step: 168550 training 0.55            validation 0.5596\n",
      "\n",
      "step: 168600 training 0.55            validation 0.5596\n",
      "\n",
      "step: 168650 training 0.633333            validation 0.5604\n",
      "\n",
      "step: 168700 training 0.5            validation 0.5596\n",
      "\n",
      "step: 168750 training 0.55            validation 0.5606\n",
      "\n",
      "step: 168800 training 0.65            validation 0.5608\n",
      "\n",
      "step: 168850 training 0.616667            validation 0.558\n",
      "\n",
      "step: 168900 training 0.533333            validation 0.5598\n",
      "\n",
      "step: 168950 training 0.55            validation 0.5592\n",
      "\n",
      "step: 169000 training 0.5            validation 0.558\n",
      "\n",
      "step: 169050 training 0.55            validation 0.5588\n",
      "\n",
      "step: 169100 training 0.533333            validation 0.5598\n",
      "\n",
      "step: 169150 training 0.7            validation 0.56\n",
      "\n",
      "step: 169200 training 0.533333            validation 0.56\n",
      "\n",
      "step: 169250 training 0.616667            validation 0.559\n",
      "\n",
      "step: 169300 training 0.65            validation 0.5606\n",
      "\n",
      "step: 169350 training 0.533333            validation 0.5602\n",
      "\n",
      "step: 169400 training 0.55            validation 0.561\n",
      "\n",
      "step: 169450 training 0.583333            validation 0.5604\n",
      "\n",
      "step: 169500 training 0.65            validation 0.5602\n",
      "\n",
      "step: 169550 training 0.583333            validation 0.5612\n",
      "\n",
      "step: 169600 training 0.616667            validation 0.5602\n",
      "\n",
      "step: 169650 training 0.616667            validation 0.559\n",
      "\n",
      "step: 169700 training 0.583333            validation 0.5598\n",
      "\n",
      "step: 169750 training 0.616667            validation 0.5588\n",
      "\n",
      "step: 169800 training 0.516667            validation 0.5594\n",
      "\n",
      "step: 169850 training 0.516667            validation 0.5586\n",
      "\n",
      "step: 169900 training 0.566667            validation 0.5596\n",
      "\n",
      "step: 169950 training 0.533333            validation 0.5598\n",
      "\n",
      "step: 170000 training 0.7            validation 0.559\n",
      "\n",
      "step: 170050 training 0.6            validation 0.5606\n",
      "\n",
      "step: 170100 training 0.466667            validation 0.5576\n",
      "\n",
      "step: 170150 training 0.616667            validation 0.5574\n",
      "\n",
      "step: 170200 training 0.616667            validation 0.5598\n",
      "\n",
      "step: 170250 training 0.633333            validation 0.558\n",
      "\n",
      "step: 170300 training 0.616667            validation 0.5604\n",
      "\n",
      "step: 170350 training 0.633333            validation 0.5602\n",
      "\n",
      "step: 170400 training 0.55            validation 0.5616\n",
      "\n",
      "step: 170450 training 0.616667            validation 0.5596\n",
      "\n",
      "step: 170500 training 0.533333            validation 0.5598\n",
      "\n",
      "step: 170550 training 0.616667            validation 0.5598\n",
      "\n",
      "step: 170600 training 0.5            validation 0.5604\n",
      "\n",
      "step: 170650 training 0.466667            validation 0.5598\n",
      "\n",
      "step: 170700 training 0.683333            validation 0.5596\n",
      "\n",
      "step: 170750 training 0.633333            validation 0.5602\n",
      "\n",
      "step: 170800 training 0.6            validation 0.561\n",
      "\n",
      "step: 170850 training 0.55            validation 0.5614\n",
      "\n",
      "step: 170900 training 0.65            validation 0.5598\n",
      "\n",
      "step: 170950 training 0.516667            validation 0.5596\n",
      "\n",
      "step: 171000 training 0.6            validation 0.56\n",
      "\n",
      "step: 171050 training 0.616667            validation 0.5592\n",
      "\n",
      "step: 171100 training 0.45            validation 0.5594\n",
      "\n",
      "step: 171150 training 0.566667            validation 0.5594\n",
      "\n",
      "step: 171200 training 0.5            validation 0.5592\n",
      "\n",
      "step: 171250 training 0.616667            validation 0.5596\n",
      "\n",
      "step: 171300 training 0.65            validation 0.5594\n",
      "\n",
      "step: 171350 training 0.633333            validation 0.559\n",
      "\n",
      "step: 171400 training 0.616667            validation 0.56\n",
      "\n",
      "step: 171450 training 0.466667            validation 0.5586\n",
      "\n",
      "step: 171500 training 0.583333            validation 0.5604\n",
      "\n",
      "step: 171550 training 0.55            validation 0.5606\n",
      "\n",
      "step: 171600 training 0.616667            validation 0.5604\n",
      "\n",
      "step: 171650 training 0.666667            validation 0.5594\n",
      "\n",
      "step: 171700 training 0.55            validation 0.5584\n",
      "\n",
      "step: 171750 training 0.616667            validation 0.56\n",
      "\n",
      "step: 171800 training 0.6            validation 0.5606\n",
      "\n",
      "step: 171850 training 0.583333            validation 0.56\n",
      "\n",
      "step: 171900 training 0.6            validation 0.5598\n",
      "\n",
      "step: 171950 training 0.516667            validation 0.5588\n",
      "\n",
      "step: 172000 training 0.55            validation 0.5592\n",
      "\n",
      "step: 172050 training 0.516667            validation 0.5604\n",
      "\n",
      "step: 172100 training 0.683333            validation 0.56\n",
      "\n",
      "step: 172150 training 0.6            validation 0.5594\n",
      "\n",
      "step: 172200 training 0.616667            validation 0.5574\n",
      "\n",
      "step: 172250 training 0.666667            validation 0.5606\n",
      "\n",
      "step: 172300 training 0.65            validation 0.5576\n",
      "\n",
      "step: 172350 training 0.6            validation 0.56\n",
      "\n",
      "step: 172400 training 0.6            validation 0.5608\n",
      "\n",
      "step: 172450 training 0.616667            validation 0.5578\n",
      "\n",
      "step: 172500 training 0.516667            validation 0.5584\n",
      "\n",
      "step: 172550 training 0.65            validation 0.5604\n",
      "\n",
      "step: 172600 training 0.55            validation 0.5594\n",
      "\n",
      "step: 172650 training 0.583333            validation 0.5596\n",
      "\n",
      "step: 172700 training 0.533333            validation 0.5608\n",
      "\n",
      "step: 172750 training 0.483333            validation 0.5592\n",
      "\n",
      "step: 172800 training 0.533333            validation 0.5596\n",
      "\n",
      "step: 172850 training 0.583333            validation 0.5608\n",
      "\n",
      "step: 172900 training 0.5            validation 0.5612\n",
      "\n",
      "step: 172950 training 0.65            validation 0.5594\n",
      "\n",
      "step: 173000 training 0.5            validation 0.559\n",
      "\n",
      "step: 173050 training 0.616667            validation 0.561\n",
      "\n",
      "step: 173100 training 0.616667            validation 0.56\n",
      "\n",
      "step: 173150 training 0.583333            validation 0.5598\n",
      "\n",
      "step: 173200 training 0.633333            validation 0.5588\n",
      "\n",
      "step: 173250 training 0.55            validation 0.5594\n",
      "\n",
      "step: 173300 training 0.6            validation 0.5596\n",
      "\n",
      "step: 173350 training 0.6            validation 0.5596\n",
      "\n",
      "step: 173400 training 0.433333            validation 0.5594\n",
      "\n",
      "step: 173450 training 0.6            validation 0.5598\n",
      "\n",
      "step: 173500 training 0.633333            validation 0.56\n",
      "\n",
      "step: 173550 training 0.55            validation 0.5582\n",
      "\n",
      "step: 173600 training 0.516667            validation 0.5594\n",
      "\n",
      "step: 173650 training 0.466667            validation 0.5592\n",
      "\n",
      "step: 173700 training 0.616667            validation 0.5576\n",
      "\n",
      "step: 173750 training 0.65            validation 0.5576\n",
      "\n",
      "step: 173800 training 0.55            validation 0.5594\n",
      "\n",
      "step: 173850 training 0.566667            validation 0.5594\n",
      "\n",
      "step: 173900 training 0.583333            validation 0.5594\n",
      "\n",
      "step: 173950 training 0.633333            validation 0.5594\n",
      "\n",
      "step: 174000 training 0.6            validation 0.5598\n",
      "\n",
      "step: 174050 training 0.6            validation 0.5594\n",
      "\n",
      "step: 174100 training 0.6            validation 0.561\n",
      "\n",
      "step: 174150 training 0.6            validation 0.5578\n",
      "\n",
      "step: 174200 training 0.516667            validation 0.559\n",
      "\n",
      "step: 174250 training 0.633333            validation 0.5592\n",
      "\n",
      "step: 174300 training 0.7            validation 0.5596\n",
      "\n",
      "step: 174350 training 0.516667            validation 0.5602\n",
      "\n",
      "step: 174400 training 0.6            validation 0.5594\n",
      "\n",
      "step: 174450 training 0.533333            validation 0.5602\n",
      "\n",
      "step: 174500 training 0.533333            validation 0.5594\n",
      "\n",
      "step: 174550 training 0.616667            validation 0.559\n",
      "\n",
      "step: 174600 training 0.516667            validation 0.5596\n",
      "\n",
      "step: 174650 training 0.55            validation 0.5572\n",
      "\n",
      "step: 174700 training 0.616667            validation 0.5602\n",
      "\n",
      "step: 174750 training 0.516667            validation 0.5582\n",
      "\n",
      "step: 174800 training 0.55            validation 0.5588\n",
      "\n",
      "step: 174850 training 0.5            validation 0.5602\n",
      "\n",
      "step: 174900 training 0.483333            validation 0.5588\n",
      "\n",
      "step: 174950 training 0.566667            validation 0.5592\n",
      "\n",
      "step: 175000 training 0.483333            validation 0.5602\n",
      "\n",
      "step: 175050 training 0.666667            validation 0.5592\n",
      "\n",
      "step: 175100 training 0.583333            validation 0.5592\n",
      "\n",
      "step: 175150 training 0.5            validation 0.5588\n",
      "\n",
      "step: 175200 training 0.55            validation 0.5602\n",
      "\n",
      "step: 175250 training 0.616667            validation 0.5588\n",
      "\n",
      "step: 175300 training 0.5            validation 0.5586\n",
      "\n",
      "step: 175350 training 0.466667            validation 0.5596\n",
      "\n",
      "step: 175400 training 0.516667            validation 0.5592\n",
      "\n",
      "step: 175450 training 0.566667            validation 0.5584\n",
      "\n",
      "step: 175500 training 0.7            validation 0.5586\n",
      "\n",
      "step: 175550 training 0.633333            validation 0.561\n",
      "\n",
      "step: 175600 training 0.616667            validation 0.559\n",
      "\n",
      "step: 175650 training 0.583333            validation 0.5588\n",
      "\n",
      "step: 175700 training 0.633333            validation 0.5592\n",
      "\n",
      "step: 175750 training 0.55            validation 0.5584\n",
      "\n",
      "step: 175800 training 0.616667            validation 0.5596\n",
      "\n",
      "step: 175850 training 0.616667            validation 0.5606\n",
      "\n",
      "step: 175900 training 0.5            validation 0.5606\n",
      "\n",
      "step: 175950 training 0.433333            validation 0.5602\n",
      "\n",
      "step: 176000 training 0.566667            validation 0.5602\n",
      "\n",
      "step: 176050 training 0.583333            validation 0.5604\n",
      "\n",
      "step: 176100 training 0.5            validation 0.558\n",
      "\n",
      "step: 176150 training 0.583333            validation 0.5596\n",
      "\n",
      "step: 176200 training 0.65            validation 0.5598\n",
      "\n",
      "step: 176250 training 0.566667            validation 0.5602\n",
      "\n",
      "step: 176300 training 0.583333            validation 0.561\n",
      "\n",
      "step: 176350 training 0.583333            validation 0.5592\n",
      "\n",
      "step: 176400 training 0.583333            validation 0.5592\n",
      "\n",
      "step: 176450 training 0.583333            validation 0.5584\n",
      "\n",
      "step: 176500 training 0.483333            validation 0.5604\n",
      "\n",
      "step: 176550 training 0.533333            validation 0.5578\n",
      "\n",
      "step: 176600 training 0.6            validation 0.5606\n",
      "\n",
      "step: 176650 training 0.65            validation 0.5598\n",
      "\n",
      "step: 176700 training 0.683333            validation 0.56\n",
      "\n",
      "step: 176750 training 0.633333            validation 0.5596\n",
      "\n",
      "step: 176800 training 0.533333            validation 0.56\n",
      "\n",
      "step: 176850 training 0.516667            validation 0.5592\n",
      "\n",
      "step: 176900 training 0.516667            validation 0.5586\n",
      "\n",
      "step: 176950 training 0.583333            validation 0.5594\n",
      "\n",
      "step: 177000 training 0.566667            validation 0.5594\n",
      "\n",
      "step: 177050 training 0.35            validation 0.5596\n",
      "\n",
      "step: 177100 training 0.583333            validation 0.56\n",
      "\n",
      "step: 177150 training 0.65            validation 0.5608\n",
      "\n",
      "step: 177200 training 0.65            validation 0.56\n",
      "\n",
      "step: 177250 training 0.6            validation 0.561\n",
      "\n",
      "step: 177300 training 0.483333            validation 0.5608\n",
      "\n",
      "step: 177350 training 0.483333            validation 0.5606\n",
      "\n",
      "step: 177400 training 0.683333            validation 0.559\n",
      "\n",
      "step: 177450 training 0.666667            validation 0.5606\n",
      "\n",
      "step: 177500 training 0.516667            validation 0.5616\n",
      "\n",
      "step: 177550 training 0.583333            validation 0.5592\n",
      "\n",
      "step: 177600 training 0.6            validation 0.5606\n",
      "\n",
      "step: 177650 training 0.716667            validation 0.5602\n",
      "\n",
      "step: 177700 training 0.333333            validation 0.559\n",
      "\n",
      "step: 177750 training 0.7            validation 0.5594\n",
      "\n",
      "step: 177800 training 0.6            validation 0.5592\n",
      "\n",
      "step: 177850 training 0.55            validation 0.5604\n",
      "\n",
      "step: 177900 training 0.583333            validation 0.562\n",
      "\n",
      "step: 177950 training 0.566667            validation 0.5588\n",
      "\n",
      "step: 178000 training 0.516667            validation 0.5594\n",
      "\n",
      "step: 178050 training 0.566667            validation 0.5594\n",
      "\n",
      "step: 178100 training 0.566667            validation 0.5604\n",
      "\n",
      "step: 178150 training 0.516667            validation 0.5612\n",
      "\n",
      "step: 178200 training 0.516667            validation 0.559\n",
      "\n",
      "step: 178250 training 0.566667            validation 0.5616\n",
      "\n",
      "step: 178300 training 0.65            validation 0.5582\n",
      "\n",
      "step: 178350 training 0.566667            validation 0.5592\n",
      "\n",
      "step: 178400 training 0.616667            validation 0.5604\n",
      "\n",
      "step: 178450 training 0.533333            validation 0.5594\n",
      "\n",
      "step: 178500 training 0.583333            validation 0.5608\n",
      "\n",
      "step: 178550 training 0.633333            validation 0.5582\n",
      "\n",
      "step: 178600 training 0.533333            validation 0.5586\n",
      "\n",
      "step: 178650 training 0.533333            validation 0.559\n",
      "\n",
      "step: 178700 training 0.5            validation 0.561\n",
      "\n",
      "step: 178750 training 0.516667            validation 0.5594\n",
      "\n",
      "step: 178800 training 0.516667            validation 0.5608\n",
      "\n",
      "step: 178850 training 0.516667            validation 0.5594\n",
      "\n",
      "step: 178900 training 0.583333            validation 0.5598\n",
      "\n",
      "step: 178950 training 0.533333            validation 0.56\n",
      "\n",
      "step: 179000 training 0.516667            validation 0.56\n",
      "\n",
      "step: 179050 training 0.55            validation 0.5606\n",
      "\n",
      "step: 179100 training 0.666667            validation 0.5616\n",
      "\n",
      "step: 179150 training 0.55            validation 0.56\n",
      "\n",
      "step: 179200 training 0.633333            validation 0.5592\n",
      "\n",
      "step: 179250 training 0.55            validation 0.5604\n",
      "\n",
      "step: 179300 training 0.583333            validation 0.5606\n",
      "\n",
      "step: 179350 training 0.483333            validation 0.5602\n",
      "\n",
      "step: 179400 training 0.55            validation 0.5588\n",
      "\n",
      "step: 179450 training 0.666667            validation 0.5592\n",
      "\n",
      "step: 179500 training 0.533333            validation 0.559\n",
      "\n",
      "step: 179550 training 0.616667            validation 0.5614\n",
      "\n",
      "step: 179600 training 0.566667            validation 0.5592\n",
      "\n",
      "step: 179650 training 0.533333            validation 0.5582\n",
      "\n",
      "step: 179700 training 0.616667            validation 0.5594\n",
      "\n",
      "step: 179750 training 0.6            validation 0.561\n",
      "\n",
      "step: 179800 training 0.55            validation 0.5594\n",
      "\n",
      "step: 179850 training 0.5            validation 0.5582\n",
      "\n",
      "step: 179900 training 0.683333            validation 0.5594\n",
      "\n",
      "step: 179950 training 0.566667            validation 0.5602\n",
      "\n",
      "step: 180000 training 0.566667            validation 0.5598\n",
      "\n",
      "step: 180050 training 0.483333            validation 0.5588\n",
      "\n",
      "step: 180100 training 0.633333            validation 0.5598\n",
      "\n",
      "step: 180150 training 0.55            validation 0.5584\n",
      "\n",
      "step: 180200 training 0.633333            validation 0.5598\n",
      "\n",
      "step: 180250 training 0.583333            validation 0.559\n",
      "\n",
      "step: 180300 training 0.7            validation 0.5616\n",
      "\n",
      "step: 180350 training 0.616667            validation 0.557\n",
      "\n",
      "step: 180400 training 0.55            validation 0.56\n",
      "\n",
      "step: 180450 training 0.55            validation 0.5606\n",
      "\n",
      "step: 180500 training 0.45            validation 0.5586\n",
      "\n",
      "step: 180550 training 0.633333            validation 0.5612\n",
      "\n",
      "step: 180600 training 0.666667            validation 0.5594\n",
      "\n",
      "step: 180650 training 0.6            validation 0.56\n",
      "\n",
      "step: 180700 training 0.483333            validation 0.5588\n",
      "\n",
      "step: 180750 training 0.6            validation 0.559\n",
      "\n",
      "step: 180800 training 0.633333            validation 0.5586\n",
      "\n",
      "step: 180850 training 0.55            validation 0.5612\n",
      "\n",
      "step: 180900 training 0.583333            validation 0.5594\n",
      "\n",
      "step: 180950 training 0.5            validation 0.5582\n",
      "\n",
      "step: 181000 training 0.516667            validation 0.5594\n",
      "\n",
      "step: 181050 training 0.466667            validation 0.56\n",
      "\n",
      "step: 181100 training 0.583333            validation 0.5578\n",
      "\n",
      "step: 181150 training 0.55            validation 0.5598\n",
      "\n",
      "step: 181200 training 0.65            validation 0.5606\n",
      "\n",
      "step: 181250 training 0.65            validation 0.5596\n",
      "\n",
      "step: 181300 training 0.566667            validation 0.5594\n",
      "\n",
      "step: 181350 training 0.566667            validation 0.5618\n",
      "\n",
      "step: 181400 training 0.633333            validation 0.5612\n",
      "\n",
      "step: 181450 training 0.55            validation 0.5596\n",
      "\n",
      "step: 181500 training 0.65            validation 0.5584\n",
      "\n",
      "step: 181550 training 0.633333            validation 0.5598\n",
      "\n",
      "step: 181600 training 0.533333            validation 0.5582\n",
      "\n",
      "step: 181650 training 0.55            validation 0.5594\n",
      "\n",
      "step: 181700 training 0.55            validation 0.5588\n",
      "\n",
      "step: 181750 training 0.55            validation 0.5598\n",
      "\n",
      "step: 181800 training 0.516667            validation 0.5604\n",
      "\n",
      "step: 181850 training 0.583333            validation 0.5594\n",
      "\n",
      "step: 181900 training 0.533333            validation 0.559\n",
      "\n",
      "step: 181950 training 0.45            validation 0.5602\n",
      "\n",
      "step: 182000 training 0.466667            validation 0.5598\n",
      "\n",
      "step: 182050 training 0.45            validation 0.5608\n",
      "\n",
      "step: 182100 training 0.65            validation 0.5592\n",
      "\n",
      "step: 182150 training 0.566667            validation 0.5592\n",
      "\n",
      "step: 182200 training 0.483333            validation 0.5586\n",
      "\n",
      "step: 182250 training 0.5            validation 0.5582\n",
      "\n",
      "step: 182300 training 0.516667            validation 0.5614\n",
      "\n",
      "step: 182350 training 0.566667            validation 0.5592\n",
      "\n",
      "step: 182400 training 0.516667            validation 0.5602\n",
      "\n",
      "step: 182450 training 0.683333            validation 0.5588\n",
      "\n",
      "step: 182500 training 0.466667            validation 0.56\n",
      "\n",
      "step: 182550 training 0.566667            validation 0.561\n",
      "\n",
      "step: 182600 training 0.533333            validation 0.5608\n",
      "\n",
      "step: 182650 training 0.55            validation 0.5614\n",
      "\n",
      "step: 182700 training 0.533333            validation 0.5604\n",
      "\n",
      "step: 182750 training 0.5            validation 0.5606\n",
      "\n",
      "step: 182800 training 0.533333            validation 0.5618\n",
      "\n",
      "step: 182850 training 0.566667            validation 0.5602\n",
      "\n",
      "step: 182900 training 0.533333            validation 0.5584\n",
      "\n",
      "step: 182950 training 0.6            validation 0.56\n",
      "\n",
      "step: 183000 training 0.533333            validation 0.5588\n",
      "\n",
      "step: 183050 training 0.583333            validation 0.56\n",
      "\n",
      "step: 183100 training 0.633333            validation 0.5598\n",
      "\n",
      "step: 183150 training 0.566667            validation 0.5598\n",
      "\n",
      "step: 183200 training 0.6            validation 0.5594\n",
      "\n",
      "step: 183250 training 0.533333            validation 0.5596\n",
      "\n",
      "step: 183300 training 0.633333            validation 0.5586\n",
      "\n",
      "step: 183350 training 0.616667            validation 0.559\n",
      "\n",
      "step: 183400 training 0.533333            validation 0.56\n",
      "\n",
      "step: 183450 training 0.6            validation 0.5606\n",
      "\n",
      "step: 183500 training 0.533333            validation 0.5602\n",
      "\n",
      "step: 183550 training 0.533333            validation 0.5618\n",
      "\n",
      "step: 183600 training 0.65            validation 0.5596\n",
      "\n",
      "step: 183650 training 0.616667            validation 0.5604\n",
      "\n",
      "step: 183700 training 0.633333            validation 0.56\n",
      "\n",
      "step: 183750 training 0.633333            validation 0.5614\n",
      "\n",
      "step: 183800 training 0.65            validation 0.5608\n",
      "\n",
      "step: 183850 training 0.383333            validation 0.5586\n",
      "\n",
      "step: 183900 training 0.516667            validation 0.5596\n",
      "\n",
      "step: 183950 training 0.666667            validation 0.5596\n",
      "\n",
      "step: 184000 training 0.6            validation 0.5588\n",
      "\n",
      "step: 184050 training 0.616667            validation 0.5582\n",
      "\n",
      "step: 184100 training 0.566667            validation 0.5608\n",
      "\n",
      "step: 184150 training 0.6            validation 0.5586\n",
      "\n",
      "step: 184200 training 0.666667            validation 0.5608\n",
      "\n",
      "step: 184250 training 0.533333            validation 0.56\n",
      "\n",
      "step: 184300 training 0.6            validation 0.5594\n",
      "\n",
      "step: 184350 training 0.55            validation 0.56\n",
      "\n",
      "step: 184400 training 0.583333            validation 0.5606\n",
      "\n",
      "step: 184450 training 0.483333            validation 0.5612\n",
      "\n",
      "step: 184500 training 0.633333            validation 0.5634\n",
      "\n",
      "step: 184550 training 0.566667            validation 0.5572\n",
      "\n",
      "step: 184600 training 0.5            validation 0.559\n",
      "\n",
      "step: 184650 training 0.416667            validation 0.562\n",
      "\n",
      "step: 184700 training 0.566667            validation 0.56\n",
      "\n",
      "step: 184750 training 0.616667            validation 0.5576\n",
      "\n",
      "step: 184800 training 0.533333            validation 0.5586\n",
      "\n",
      "step: 184850 training 0.5            validation 0.5608\n",
      "\n",
      "step: 184900 training 0.583333            validation 0.5586\n",
      "\n",
      "step: 184950 training 0.6            validation 0.5616\n",
      "\n",
      "step: 185000 training 0.616667            validation 0.562\n",
      "\n",
      "step: 185050 training 0.533333            validation 0.5586\n",
      "\n",
      "step: 185100 training 0.616667            validation 0.5576\n",
      "\n",
      "step: 185150 training 0.683333            validation 0.559\n",
      "\n",
      "step: 185200 training 0.516667            validation 0.5592\n",
      "\n",
      "step: 185250 training 0.583333            validation 0.5622\n",
      "\n",
      "step: 185300 training 0.583333            validation 0.5604\n",
      "\n",
      "step: 185350 training 0.55            validation 0.5598\n",
      "\n",
      "step: 185400 training 0.616667            validation 0.5604\n",
      "\n",
      "step: 185450 training 0.566667            validation 0.5582\n",
      "\n",
      "step: 185500 training 0.5            validation 0.5582\n",
      "\n",
      "step: 185550 training 0.483333            validation 0.5592\n",
      "\n",
      "step: 185600 training 0.55            validation 0.5608\n",
      "\n",
      "step: 185650 training 0.516667            validation 0.5596\n",
      "\n",
      "step: 185700 training 0.466667            validation 0.5592\n",
      "\n",
      "step: 185750 training 0.633333            validation 0.5592\n",
      "\n",
      "step: 185800 training 0.6            validation 0.5592\n",
      "\n",
      "step: 185850 training 0.583333            validation 0.5598\n",
      "\n",
      "step: 185900 training 0.683333            validation 0.5606\n",
      "\n",
      "step: 185950 training 0.583333            validation 0.5608\n",
      "\n",
      "step: 186000 training 0.7            validation 0.5602\n",
      "\n",
      "step: 186050 training 0.55            validation 0.5582\n",
      "\n",
      "step: 186100 training 0.566667            validation 0.5594\n",
      "\n",
      "step: 186150 training 0.583333            validation 0.5604\n",
      "\n",
      "step: 186200 training 0.516667            validation 0.56\n",
      "\n",
      "step: 186250 training 0.566667            validation 0.56\n",
      "\n",
      "step: 186300 training 0.5            validation 0.5586\n",
      "\n",
      "step: 186350 training 0.55            validation 0.56\n",
      "\n",
      "step: 186400 training 0.483333            validation 0.5606\n",
      "\n",
      "step: 186450 training 0.55            validation 0.5592\n",
      "\n",
      "step: 186500 training 0.533333            validation 0.5604\n",
      "\n",
      "step: 186550 training 0.583333            validation 0.559\n",
      "\n",
      "step: 186600 training 0.616667            validation 0.5616\n",
      "\n",
      "step: 186650 training 0.55            validation 0.559\n",
      "\n",
      "step: 186700 training 0.6            validation 0.5594\n",
      "\n",
      "step: 186750 training 0.583333            validation 0.5586\n",
      "\n",
      "step: 186800 training 0.566667            validation 0.5582\n",
      "\n",
      "step: 186850 training 0.633333            validation 0.5604\n",
      "\n",
      "step: 186900 training 0.366667            validation 0.5594\n",
      "\n",
      "step: 186950 training 0.55            validation 0.5602\n",
      "\n",
      "step: 187000 training 0.55            validation 0.559\n",
      "\n",
      "step: 187050 training 0.533333            validation 0.5592\n",
      "\n",
      "step: 187100 training 0.516667            validation 0.559\n",
      "\n",
      "step: 187150 training 0.533333            validation 0.561\n",
      "\n",
      "step: 187200 training 0.65            validation 0.5598\n",
      "\n",
      "step: 187250 training 0.55            validation 0.5596\n",
      "\n",
      "step: 187300 training 0.65            validation 0.5586\n",
      "\n",
      "step: 187350 training 0.566667            validation 0.5604\n",
      "\n",
      "step: 187400 training 0.5            validation 0.5598\n",
      "\n",
      "step: 187450 training 0.45            validation 0.5602\n",
      "\n",
      "step: 187500 training 0.5            validation 0.56\n",
      "\n",
      "step: 187550 training 0.583333            validation 0.559\n",
      "\n",
      "step: 187600 training 0.666667            validation 0.5596\n",
      "\n",
      "step: 187650 training 0.583333            validation 0.5568\n",
      "\n",
      "step: 187700 training 0.616667            validation 0.5596\n",
      "\n",
      "step: 187750 training 0.616667            validation 0.5558\n",
      "\n",
      "step: 187800 training 0.666667            validation 0.561\n",
      "\n",
      "step: 187850 training 0.7            validation 0.5576\n",
      "\n",
      "step: 187900 training 0.516667            validation 0.561\n",
      "\n",
      "step: 187950 training 0.55            validation 0.5616\n",
      "\n",
      "step: 188000 training 0.616667            validation 0.5584\n",
      "\n",
      "step: 188050 training 0.683333            validation 0.5598\n",
      "\n",
      "step: 188100 training 0.55            validation 0.5592\n",
      "\n",
      "step: 188150 training 0.516667            validation 0.5592\n",
      "\n",
      "step: 188200 training 0.516667            validation 0.5594\n",
      "\n",
      "step: 188250 training 0.6            validation 0.5594\n",
      "\n",
      "step: 188300 training 0.583333            validation 0.5602\n",
      "\n",
      "step: 188350 training 0.6            validation 0.5606\n",
      "\n",
      "step: 188400 training 0.566667            validation 0.5584\n",
      "\n",
      "step: 188450 training 0.55            validation 0.5582\n",
      "\n",
      "step: 188500 training 0.633333            validation 0.5604\n",
      "\n",
      "step: 188550 training 0.566667            validation 0.5598\n",
      "\n",
      "step: 188600 training 0.583333            validation 0.5598\n",
      "\n",
      "step: 188650 training 0.5            validation 0.5584\n",
      "\n",
      "step: 188700 training 0.55            validation 0.5612\n",
      "\n",
      "step: 188750 training 0.65            validation 0.5606\n",
      "\n",
      "step: 188800 training 0.5            validation 0.5588\n",
      "\n",
      "step: 188850 training 0.616667            validation 0.56\n",
      "\n",
      "step: 188900 training 0.416667            validation 0.5572\n",
      "\n",
      "step: 188950 training 0.65            validation 0.559\n",
      "\n",
      "step: 189000 training 0.516667            validation 0.5592\n",
      "\n",
      "step: 189050 training 0.566667            validation 0.56\n",
      "\n",
      "step: 189100 training 0.616667            validation 0.5596\n",
      "\n",
      "step: 189150 training 0.583333            validation 0.5606\n",
      "\n",
      "step: 189200 training 0.65            validation 0.5602\n",
      "\n",
      "step: 189250 training 0.65            validation 0.559\n",
      "\n",
      "step: 189300 training 0.533333            validation 0.5588\n",
      "\n",
      "step: 189350 training 0.566667            validation 0.5598\n",
      "\n",
      "step: 189400 training 0.566667            validation 0.5612\n",
      "\n",
      "step: 189450 training 0.6            validation 0.56\n",
      "\n",
      "step: 189500 training 0.716667            validation 0.5606\n",
      "\n",
      "step: 189550 training 0.616667            validation 0.5598\n",
      "\n",
      "step: 189600 training 0.583333            validation 0.5602\n",
      "\n",
      "step: 189650 training 0.516667            validation 0.5584\n",
      "\n",
      "step: 189700 training 0.616667            validation 0.5592\n",
      "\n",
      "step: 189750 training 0.716667            validation 0.5596\n",
      "\n",
      "step: 189800 training 0.583333            validation 0.5592\n",
      "\n",
      "step: 189850 training 0.483333            validation 0.558\n",
      "\n",
      "step: 189900 training 0.566667            validation 0.5596\n",
      "\n",
      "step: 189950 training 0.533333            validation 0.5626\n",
      "\n",
      "step: 190000 training 0.433333            validation 0.559\n",
      "\n",
      "step: 190050 training 0.633333            validation 0.56\n",
      "\n",
      "step: 190100 training 0.6            validation 0.559\n",
      "\n",
      "step: 190150 training 0.566667            validation 0.5604\n",
      "\n",
      "step: 190200 training 0.566667            validation 0.5586\n",
      "\n",
      "step: 190250 training 0.583333            validation 0.5604\n",
      "\n",
      "step: 190300 training 0.616667            validation 0.5592\n",
      "\n",
      "step: 190350 training 0.566667            validation 0.5598\n",
      "\n",
      "step: 190400 training 0.466667            validation 0.559\n",
      "\n",
      "step: 190450 training 0.533333            validation 0.5608\n",
      "\n",
      "step: 190500 training 0.533333            validation 0.5616\n",
      "\n",
      "step: 190550 training 0.566667            validation 0.5584\n",
      "\n",
      "step: 190600 training 0.65            validation 0.56\n",
      "\n",
      "step: 190650 training 0.616667            validation 0.5606\n",
      "\n",
      "step: 190700 training 0.633333            validation 0.5614\n",
      "\n",
      "step: 190750 training 0.583333            validation 0.5602\n",
      "\n",
      "step: 190800 training 0.65            validation 0.5596\n",
      "\n",
      "step: 190850 training 0.516667            validation 0.56\n",
      "\n",
      "step: 190900 training 0.6            validation 0.56\n",
      "\n",
      "step: 190950 training 0.666667            validation 0.5596\n",
      "\n",
      "step: 191000 training 0.616667            validation 0.5604\n",
      "\n",
      "step: 191050 training 0.6            validation 0.5594\n",
      "\n",
      "step: 191100 training 0.583333            validation 0.5604\n",
      "\n",
      "step: 191150 training 0.683333            validation 0.5596\n",
      "\n",
      "step: 191200 training 0.566667            validation 0.5598\n",
      "\n",
      "step: 191250 training 0.633333            validation 0.5582\n",
      "\n",
      "step: 191300 training 0.533333            validation 0.5594\n",
      "\n",
      "step: 191350 training 0.683333            validation 0.561\n",
      "\n",
      "step: 191400 training 0.6            validation 0.5586\n",
      "\n",
      "step: 191450 training 0.55            validation 0.5612\n",
      "\n",
      "step: 191500 training 0.55            validation 0.5586\n",
      "\n",
      "step: 191550 training 0.666667            validation 0.5586\n",
      "\n",
      "step: 191600 training 0.666667            validation 0.5598\n",
      "\n",
      "step: 191650 training 0.65            validation 0.5566\n",
      "\n",
      "step: 191700 training 0.55            validation 0.5566\n",
      "\n",
      "step: 191750 training 0.6            validation 0.5578\n",
      "\n",
      "step: 191800 training 0.566667            validation 0.56\n",
      "\n",
      "step: 191850 training 0.633333            validation 0.5608\n",
      "\n",
      "step: 191900 training 0.55            validation 0.5598\n",
      "\n",
      "step: 191950 training 0.583333            validation 0.5604\n",
      "\n",
      "step: 192000 training 0.5            validation 0.5586\n",
      "\n",
      "step: 192050 training 0.5            validation 0.5602\n",
      "\n",
      "step: 192100 training 0.583333            validation 0.5588\n",
      "\n",
      "step: 192150 training 0.533333            validation 0.5596\n",
      "\n",
      "step: 192200 training 0.633333            validation 0.5608\n",
      "\n",
      "step: 192250 training 0.566667            validation 0.56\n",
      "\n",
      "step: 192300 training 0.633333            validation 0.5592\n",
      "\n",
      "step: 192350 training 0.566667            validation 0.5598\n",
      "\n",
      "step: 192400 training 0.533333            validation 0.5592\n",
      "\n",
      "step: 192450 training 0.55            validation 0.559\n",
      "\n",
      "step: 192500 training 0.55            validation 0.5594\n",
      "\n",
      "step: 192550 training 0.666667            validation 0.5602\n",
      "\n",
      "step: 192600 training 0.633333            validation 0.5584\n",
      "\n",
      "step: 192650 training 0.55            validation 0.5578\n",
      "\n",
      "step: 192700 training 0.55            validation 0.5586\n",
      "\n",
      "step: 192750 training 0.6            validation 0.5598\n",
      "\n",
      "step: 192800 training 0.516667            validation 0.5596\n",
      "\n",
      "step: 192850 training 0.616667            validation 0.5584\n",
      "\n",
      "step: 192900 training 0.666667            validation 0.5584\n",
      "\n",
      "step: 192950 training 0.583333            validation 0.5584\n",
      "\n",
      "step: 193000 training 0.55            validation 0.5588\n",
      "\n",
      "step: 193050 training 0.616667            validation 0.5606\n",
      "\n",
      "step: 193100 training 0.7            validation 0.5576\n",
      "\n",
      "step: 193150 training 0.6            validation 0.559\n",
      "\n",
      "step: 193200 training 0.516667            validation 0.559\n",
      "\n",
      "step: 193250 training 0.5            validation 0.5588\n",
      "\n",
      "step: 193300 training 0.583333            validation 0.5592\n",
      "\n",
      "step: 193350 training 0.6            validation 0.5576\n",
      "\n",
      "step: 193400 training 0.7            validation 0.558\n",
      "\n",
      "step: 193450 training 0.616667            validation 0.5588\n",
      "\n",
      "step: 193500 training 0.55            validation 0.5594\n",
      "\n",
      "step: 193550 training 0.566667            validation 0.558\n",
      "\n",
      "step: 193600 training 0.566667            validation 0.5586\n",
      "\n",
      "step: 193650 training 0.55            validation 0.5592\n",
      "\n",
      "step: 193700 training 0.583333            validation 0.5578\n",
      "\n",
      "step: 193750 training 0.55            validation 0.559\n",
      "\n",
      "step: 193800 training 0.55            validation 0.5604\n",
      "\n",
      "step: 193850 training 0.6            validation 0.5598\n",
      "\n",
      "step: 193900 training 0.65            validation 0.5608\n",
      "\n",
      "step: 193950 training 0.6            validation 0.5582\n",
      "\n",
      "step: 194000 training 0.566667            validation 0.5574\n",
      "\n",
      "step: 194050 training 0.6            validation 0.5602\n",
      "\n",
      "step: 194100 training 0.55            validation 0.5598\n",
      "\n",
      "step: 194150 training 0.616667            validation 0.5598\n",
      "\n",
      "step: 194200 training 0.566667            validation 0.5604\n",
      "\n",
      "step: 194250 training 0.55            validation 0.5592\n",
      "\n",
      "step: 194300 training 0.583333            validation 0.5586\n",
      "\n",
      "step: 194350 training 0.516667            validation 0.5602\n",
      "\n",
      "step: 194400 training 0.533333            validation 0.559\n",
      "\n",
      "step: 194450 training 0.666667            validation 0.558\n",
      "\n",
      "step: 194500 training 0.566667            validation 0.5606\n",
      "\n",
      "step: 194550 training 0.616667            validation 0.56\n",
      "\n",
      "step: 194600 training 0.6            validation 0.5596\n",
      "\n",
      "step: 194650 training 0.616667            validation 0.5594\n",
      "\n",
      "step: 194700 training 0.55            validation 0.5574\n",
      "\n",
      "step: 194750 training 0.366667            validation 0.5602\n",
      "\n",
      "step: 194800 training 0.65            validation 0.5608\n",
      "\n",
      "step: 194850 training 0.566667            validation 0.5598\n",
      "\n",
      "step: 194900 training 0.566667            validation 0.5588\n",
      "\n",
      "step: 194950 training 0.4            validation 0.5612\n",
      "\n",
      "step: 195000 training 0.683333            validation 0.5602\n",
      "\n",
      "step: 195050 training 0.45            validation 0.5602\n",
      "\n",
      "step: 195100 training 0.6            validation 0.56\n",
      "\n",
      "step: 195150 training 0.616667            validation 0.5586\n",
      "\n",
      "step: 195200 training 0.566667            validation 0.5594\n",
      "\n",
      "step: 195250 training 0.533333            validation 0.5596\n",
      "\n",
      "step: 195300 training 0.55            validation 0.5596\n",
      "\n",
      "step: 195350 training 0.566667            validation 0.5606\n",
      "\n",
      "step: 195400 training 0.616667            validation 0.5586\n",
      "\n",
      "step: 195450 training 0.533333            validation 0.5592\n",
      "\n",
      "step: 195500 training 0.683333            validation 0.5602\n",
      "\n",
      "step: 195550 training 0.616667            validation 0.5606\n",
      "\n",
      "step: 195600 training 0.566667            validation 0.5576\n",
      "\n",
      "step: 195650 training 0.533333            validation 0.5584\n",
      "\n",
      "step: 195700 training 0.566667            validation 0.5584\n",
      "\n",
      "step: 195750 training 0.55            validation 0.5578\n",
      "\n",
      "step: 195800 training 0.616667            validation 0.5576\n",
      "\n",
      "step: 195850 training 0.533333            validation 0.558\n",
      "\n",
      "step: 195900 training 0.65            validation 0.559\n",
      "\n",
      "step: 195950 training 0.666667            validation 0.559\n",
      "\n",
      "step: 196000 training 0.516667            validation 0.5602\n",
      "\n",
      "step: 196050 training 0.666667            validation 0.5586\n",
      "\n",
      "step: 196100 training 0.433333            validation 0.5592\n",
      "\n",
      "step: 196150 training 0.483333            validation 0.5574\n",
      "\n",
      "step: 196200 training 0.5            validation 0.5568\n",
      "\n",
      "step: 196250 training 0.65            validation 0.559\n",
      "\n",
      "step: 196300 training 0.633333            validation 0.5598\n",
      "\n",
      "step: 196350 training 0.65            validation 0.5596\n",
      "\n",
      "step: 196400 training 0.583333            validation 0.5578\n",
      "\n",
      "step: 196450 training 0.633333            validation 0.5576\n",
      "\n",
      "step: 196500 training 0.616667            validation 0.5584\n",
      "\n",
      "step: 196550 training 0.633333            validation 0.5586\n",
      "\n",
      "step: 196600 training 0.583333            validation 0.56\n",
      "\n",
      "step: 196650 training 0.6            validation 0.5592\n",
      "\n",
      "step: 196700 training 0.566667            validation 0.5596\n",
      "\n",
      "step: 196750 training 0.666667            validation 0.5572\n",
      "\n",
      "step: 196800 training 0.683333            validation 0.5578\n",
      "\n",
      "step: 196850 training 0.45            validation 0.5562\n",
      "\n",
      "step: 196900 training 0.616667            validation 0.5572\n",
      "\n",
      "step: 196950 training 0.533333            validation 0.5578\n",
      "\n",
      "step: 197000 training 0.583333            validation 0.5594\n",
      "\n",
      "step: 197050 training 0.55            validation 0.5586\n",
      "\n",
      "step: 197100 training 0.55            validation 0.5606\n",
      "\n",
      "step: 197150 training 0.633333            validation 0.5596\n",
      "\n",
      "step: 197200 training 0.616667            validation 0.557\n",
      "\n",
      "step: 197250 training 0.616667            validation 0.5588\n",
      "\n",
      "step: 197300 training 0.5            validation 0.5588\n",
      "\n",
      "step: 197350 training 0.633333            validation 0.5576\n",
      "\n",
      "step: 197400 training 0.633333            validation 0.5588\n",
      "\n",
      "step: 197450 training 0.616667            validation 0.5596\n",
      "\n",
      "step: 197500 training 0.6            validation 0.5588\n",
      "\n",
      "step: 197550 training 0.616667            validation 0.5582\n",
      "\n",
      "step: 197600 training 0.566667            validation 0.5586\n",
      "\n",
      "step: 197650 training 0.716667            validation 0.5602\n",
      "\n",
      "step: 197700 training 0.6            validation 0.5594\n",
      "\n",
      "step: 197750 training 0.533333            validation 0.56\n",
      "\n",
      "step: 197800 training 0.6            validation 0.5592\n",
      "\n",
      "step: 197850 training 0.566667            validation 0.558\n",
      "\n",
      "step: 197900 training 0.566667            validation 0.5602\n",
      "\n",
      "step: 197950 training 0.666667            validation 0.56\n",
      "\n",
      "step: 198000 training 0.7            validation 0.5588\n",
      "\n",
      "step: 198050 training 0.633333            validation 0.5604\n",
      "\n",
      "step: 198100 training 0.65            validation 0.56\n",
      "\n",
      "step: 198150 training 0.55            validation 0.558\n",
      "\n",
      "step: 198200 training 0.533333            validation 0.559\n",
      "\n",
      "step: 198250 training 0.566667            validation 0.5602\n",
      "\n",
      "step: 198300 training 0.616667            validation 0.5602\n",
      "\n",
      "step: 198350 training 0.65            validation 0.5604\n",
      "\n",
      "step: 198400 training 0.516667            validation 0.5612\n",
      "\n",
      "step: 198450 training 0.666667            validation 0.5592\n",
      "\n",
      "step: 198500 training 0.5            validation 0.5586\n",
      "\n",
      "step: 198550 training 0.583333            validation 0.5584\n",
      "\n",
      "step: 198600 training 0.616667            validation 0.559\n",
      "\n",
      "step: 198650 training 0.516667            validation 0.5598\n",
      "\n",
      "step: 198700 training 0.533333            validation 0.5592\n",
      "\n",
      "step: 198750 training 0.65            validation 0.5592\n",
      "\n",
      "step: 198800 training 0.533333            validation 0.5564\n",
      "\n",
      "step: 198850 training 0.633333            validation 0.5576\n",
      "\n",
      "step: 198900 training 0.516667            validation 0.559\n",
      "\n",
      "step: 198950 training 0.533333            validation 0.5594\n",
      "\n",
      "step: 199000 training 0.633333            validation 0.5584\n",
      "\n",
      "step: 199050 training 0.5            validation 0.5586\n",
      "\n",
      "step: 199100 training 0.633333            validation 0.5594\n",
      "\n",
      "step: 199150 training 0.516667            validation 0.5588\n",
      "\n",
      "step: 199200 training 0.55            validation 0.558\n",
      "\n",
      "step: 199250 training 0.65            validation 0.5584\n",
      "\n",
      "step: 199300 training 0.55            validation 0.5594\n",
      "\n",
      "step: 199350 training 0.6            validation 0.5582\n",
      "\n",
      "step: 199400 training 0.633333            validation 0.5592\n",
      "\n",
      "step: 199450 training 0.633333            validation 0.5576\n",
      "\n",
      "step: 199500 training 0.583333            validation 0.5584\n",
      "\n",
      "step: 199550 training 0.5            validation 0.5608\n",
      "\n",
      "step: 199600 training 0.616667            validation 0.5582\n",
      "\n",
      "step: 199650 training 0.583333            validation 0.5594\n",
      "\n",
      "step: 199700 training 0.683333            validation 0.5592\n",
      "\n",
      "step: 199750 training 0.583333            validation 0.5588\n",
      "\n",
      "step: 199800 training 0.616667            validation 0.5588\n",
      "\n",
      "step: 199850 training 0.6            validation 0.5596\n",
      "\n",
      "step: 199900 training 0.55            validation 0.5586\n",
      "\n",
      "step: 199950 training 0.55            validation 0.5584\n",
      "\n",
      "test accuracy :  0.5665\n",
      "final output  [[ -4.66546059 -45.38803482  -9.86992836 ...,  11.809165   -22.91637421\n",
      "  -22.00495911]\n",
      " [ -5.84102249 -25.49025345  13.77784634 ..., -48.35094452 -21.40270233\n",
      "  -30.43401527]\n",
      " [-20.37877655   8.50870323   0.90474069 ...,  -3.12181878 -11.96413994\n",
      "  -12.26283073]\n",
      " ..., \n",
      " [-29.61696243 -37.07679367 -19.86618233 ...,  -5.4974947  -28.90658951\n",
      "  -19.82593918]\n",
      " [-17.09613228 -12.3439188  -19.28388023 ..., -14.99829865 -19.41233253\n",
      "  -24.75294495]\n",
      " [-17.7267952  -54.15087128 -14.62193108 ..., -28.67934799 -26.78003883\n",
      "  -40.36273956]]\n",
      "The time taken by Training:  270.281634092\n"
     ]
    }
   ],
   "source": [
    "acc,zs,acc_val , zs_val,w1_mean_list =[],[],[],[],[]\n",
    "start_time=time.time()\n",
    "for i in range(200000):\n",
    "\n",
    "    batch_xs , batch_ys =next_batch( 60 , train_img , train_lab) \n",
    "    sess.run( train_step , feed_dict ={ x_: batch_xs , y_ :batch_ys })\n",
    "    if i%50 is 0:\n",
    "        train_res = sess.run([accuracy , z1 ] , feed_dict = {x_:batch_xs, y_ : batch_ys})\n",
    "        val_res   = sess.run([accuracy , z1 ] , feed_dict = {x_:val_img, y_ : val_lab})\n",
    "        mean   = sess.run(mean_w1 , feed_dict = {x_:val_img, y_ : val_lab})\n",
    "        \n",
    "        print 'step:',i, 'training',train_res[0],'           validation' , val_res[0] \n",
    "        acc.append(train_res[0])\n",
    "        #print np.shape(train_res[1])\n",
    "        #print np.mean(train_res[1])\n",
    "        zs.append(np.mean(train_res[1] , axis=0))\n",
    "        w1_mean_list.append(mean)\n",
    "        print \n",
    "        acc_val.append(val_res[0])\n",
    "        zs_val.append(np.mean(val_res[1] , axis=0))            \n",
    "end_time=time.time()\n",
    "zs , val_zs , acc, acc_val = np.array(zs) , np.array(zs_val) , np.array(acc) , np.array(acc_val)\n",
    "#when we test , through using above 4 parameter we get more higher accuracy \n",
    "test_res = sess.run([accuracy , z1 ] , feed_dict = {x_:test_img, y_ : test_lab})\n",
    "print 'test accuracy : ' , test_res[0] \n",
    "print 'final output ' , test_res[1]\n",
    "print 'The time taken by Training: ',end_time - start_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-4f26426dc82a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1_mean_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mw1_mean_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3159\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3160\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3161\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3162\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3163\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwashold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.pyc\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1817\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1818\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1819\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1820\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/axes/_axes.pyc\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1383\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must have same first dimension\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y can be no greater than 2-D\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgsAAAFkCAYAAACuFXjcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLrEAAHSJBQCgSywAAF1iAQDo+v95F8OJyG8KGwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f93cc2d6910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print len(w1_mean_list)\n",
    "plt.plot(range(0,100000,50) , w1_mean_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print len(w1_mean_list)\n",
    "plt.plot(range(0,200000,50) , w1_mean_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
